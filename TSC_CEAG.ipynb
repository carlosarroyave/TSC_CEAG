{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, ReLU, GlobalAveragePooling1D, Dense, Dropout, Flatten, Add,  Input, MaxPooling1D, concatenate, LSTM \n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características (X):\n",
      "     0     1     2     3     4     5     6     7     8     9    ...   278  \\\n",
      "0  12.0  18.0  11.0  11.0  19.0  17.0   4.0   6.0   8.0  12.0  ...  10.0   \n",
      "1  12.0   9.0  11.0   7.0  12.0  14.0  10.0  10.0  10.0   6.0  ...   4.0   \n",
      "2   8.0   5.0  10.0  11.0   9.0  10.0   7.0  18.0  11.0   8.0  ...  13.0   \n",
      "3  16.0  15.0  13.0  14.0   8.0  16.0  14.0   9.0   9.0   8.0  ...  12.0   \n",
      "4   8.0   6.0   5.0  11.0   7.0   4.0  10.0   8.0   8.0   4.0  ...  19.0   \n",
      "\n",
      "    279   280   281   282  283   284   285   286   287  \n",
      "0   9.0  11.0   8.0   4.0  7.0   3.0   6.0   3.0   6.0  \n",
      "1   7.0   9.0  11.0   6.0  9.0   7.0  10.0   4.0   9.0  \n",
      "2   7.0   6.0   7.0   1.0  2.0   6.0   7.0   8.0   6.0  \n",
      "3  11.0   6.0   3.0  11.0  9.0   2.0   6.0   6.0   3.0  \n",
      "4  13.0  15.0  17.0  10.0  8.0  12.0  16.0  15.0  13.0  \n",
      "\n",
      "[5 rows x 288 columns]\n",
      "Etiquetas (y):\n",
      "     Etiqueta_1  Etiqueta_2  Etiqueta_3  Etiqueta_4  Etiqueta_5  Etiqueta_6  \\\n",
      "0         True       False       False       False       False       False   \n",
      "1         True       False       False       False       False       False   \n",
      "2         True       False       False       False       False       False   \n",
      "3         True       False       False       False       False       False   \n",
      "4         True       False       False       False       False       False   \n",
      "..         ...         ...         ...         ...         ...         ...   \n",
      "62       False       False       False       False       False       False   \n",
      "63       False       False       False       False       False       False   \n",
      "64       False       False       False       False       False       False   \n",
      "65       False       False       False       False       False       False   \n",
      "66       False       False       False       False       False       False   \n",
      "\n",
      "    Etiqueta_7  \n",
      "0        False  \n",
      "1        False  \n",
      "2        False  \n",
      "3        False  \n",
      "4        False  \n",
      "..         ...  \n",
      "62        True  \n",
      "63        True  \n",
      "64        True  \n",
      "65        True  \n",
      "66        True  \n",
      "\n",
      "[67 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_ts_file(file_path):\n",
    "    \"\"\"\n",
    "    Función para cargar archivos .ts y separar características y etiquetas.\n",
    "    Asume que las características están separadas por comas y las etiquetas están separadas por dos puntos (:).\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    # Leer el archivo línea por línea\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Separar características y etiquetas usando \":\"\n",
    "            line_split = line.strip().split(':')\n",
    "            # Verificar si la línea tiene características y una etiqueta\n",
    "            if len(line_split) == 2:\n",
    "                # Las características están antes del \":\"\n",
    "                features.append([float(val) for val in line_split[0].split(',')])\n",
    "                # La etiqueta está después del \":\" (solo una columna, un valor)\n",
    "                label = int(line_split[1].strip())  # Se elimina cualquier espacio adicional\n",
    "                labels.append(label)\n",
    "    # Convertir a DataFrame para las características y convertir las etiquetas en array\n",
    "    X = pd.DataFrame(features)\n",
    "    y = pd.DataFrame(labels, columns=['Etiqueta'])\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# Ruta del archivo\n",
    "file_path = 'I:/Maestria/IA/Proyecto/Proyecto/Dataset/ElectricDeviceDetection/ElectricDeviceDetection_TRAIN.ts'\n",
    "#'I:/Maestria/IA/Proyecto/Proyecto/Dataset/FaultDetectionA/FaultDetectionA_TRAIN.ts'\n",
    "#'I:/Maestria/IA/Proyecto/Proyecto/Dataset/FaultDetectionB/FaultDetectionB_TRAIN.ts'\n",
    "#'I:/Maestria/IA/Proyecto/Proyecto/Dataset/FordA/FordA_TRAIN.ts'\n",
    "#'I:/Maestria/IA/Proyecto/Proyecto/Dataset/FordB/FordB_TRAIN.ts'\n",
    "#'I:/Maestria/IA/Proyecto/Proyecto/Dataset/FreezerRegularTrain/FreezerRegularTrain_TRAIN.ts'\n",
    "#'I:/Maestria/IA/Proyecto/Proyecto/Dataset/FreezerSmallTrain/FreezerSmallTrain_TRAIN.ts'\n",
    "#'I:/Maestria/IA/Proyecto/Proyecto/Dataset/KeplerLightCurves/KeplerLightCurves_TRAIN.ts'\n",
    "#'I:/Maestria/IA/Proyecto/Proyecto/Dataset/StarLightCurves/StarLightCurves_TRAIN.ts'\n",
    "#'I:/Maestria/IA/Proyecto/Proyecto/Dataset/Wafer/Wafer_TRAIN.ts'\n",
    "\n",
    "# Cargar los datos\n",
    "X_train, y_train = load_ts_file(file_path)\n",
    "\n",
    "file_path = 'I:/Maestria/IA/Proyecto/Proyecto/Dataset/ElectricDeviceDetection/ElectricDeviceDetection_TEST.ts'\n",
    "#'I:/Maestria/IA/Proyecto/Proyecto/Dataset/FaultDetectionA/FaultDetectionA_TEST.ts'\n",
    "#'I:/Maestria/IA/Proyecto/Proyecto/Dataset/FaultDetectionB/FaultDetectionB_TEST.ts'\n",
    "#'I:/Maestria/IA/Proyecto/Proyecto/Dataset/FordA/FordA_TEST.ts'\n",
    "#'I:/Maestria/IA/Proyecto/Proyecto/Dataset/FordB/FordB_TEST.ts'\n",
    "#'I:/Maestria/IA/Proyecto/Proyecto/Dataset/FreezerRegularTrain/FreezerRegularTrain_TEST.ts'\n",
    "#'I:/Maestria/IA/Proyecto/Proyecto/Dataset/FreezerSmallTrain/FreezerSmallTrain_TEST.ts'\n",
    "#'I:/Maestria/IA/Proyecto/Proyecto/Dataset/KeplerLightCurves/KeplerLightCurves_TEST.ts'\n",
    "#'I:/Maestria/IA/Proyecto/Proyecto/Dataset/StarLightCurves/StarLightCurves_TEST.ts'\n",
    "#'I:/Maestria/IA/Proyecto/Proyecto/Dataset/Wafer/Wafer_TEST.ts'\n",
    "\n",
    "# Cargar los datos\n",
    "X_test, y_test = load_ts_file(file_path)\n",
    "\n",
    "y_train = pd.get_dummies(y_train, columns=['Etiqueta'])\n",
    "y_test = pd.get_dummies(y_test, columns=['Etiqueta'])\n",
    "# Mostrar algunas filas de los datos cargados\n",
    "print(\"Características (X):\\n\", X_train.head())\n",
    "print(\"Etiquetas (y):\\n\", y_train)\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "X_train = np.expand_dims(X_train, axis=1)  # Agregar una dimensión para pasos temporales si no existen\n",
    "X_test = np.expand_dims(X_test, axis=1)    # Lo mismo para el conjunto de prueba\n",
    "\n",
    "y_train = pd.DataFrame(y_train).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiperparametros generales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epochs = 400\n",
    "batch_size = 32\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el número de neuronas en función de la longitud de la serie temporal y el número de capas ocultas\n",
    "def create_mlp(input_shape, num_classes, num_layers=3):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=input_shape[1], input_shape=input_shape, activation='relu'))\n",
    "    for i in range(num_layers):\n",
    "        neurons = input_shape[1] * (num_layers - i)\n",
    "        model.add(Dense(units=neurons, activation='relu'))\n",
    "        model.add(Dropout(0.3 / (2 ** i)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar el input_shape correctamente\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])  # Usar solo dos dimensiones\n",
    "print(input_shape[1])\n",
    "num_classes = y_train.shape[1]\n",
    "model = create_mlp(input_shape, num_classes, num_layers=3)\n",
    "model.summary()\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9),\n",
    "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callback para reducir el learning rate en plateau\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-5)\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(X_train, y_train, epochs=epochs, validation_split=0.2, verbose=2,\n",
    "                    callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para crear el modelo FCN\n",
    "def create_fcn_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Primera capa convolucional\n",
    "    model.add(Conv1D(filters=128, kernel_size=8, padding='same', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "\n",
    "    # Segunda capa convolucional\n",
    "    model.add(Conv1D(filters=256, kernel_size=5, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "\n",
    "    # Tercera capa convolucional\n",
    "    model.add(Conv1D(filters=128, kernel_size=3, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "\n",
    "    # Capa de Global Average Pooling\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "\n",
    "    # Capa de salida (softmax)\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "input_shape = (X_train.shape[1], X_train.shape[2])  # Dimensiones de entrada de la serie temporal\n",
    "num_classes = y_train.shape[1]  # Número de clases (asumiendo one-hot encoding)\n",
    "model = create_fcn_model(input_shape, num_classes)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9),\n",
    "loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Reducir la tasa de aprendizaje cuando el progreso sea lento\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-5)\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=2, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# Mostrar el resumen de la arquitectura del modelo\n",
    "\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def residual_block(x, filters, kernel_size=3):\n",
    "    # Primera convolución\n",
    "    conv1 = Conv1D(filters=filters, kernel_size=kernel_size, padding='same', kernel_regularizer=l2(0.01))(x)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = ReLU()(conv1)\n",
    "\n",
    "    # Segunda convolución\n",
    "    conv2 = Conv1D(filters=filters, kernel_size=kernel_size, padding='same', kernel_regularizer=l2(0.01))(conv1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = ReLU()(conv2)\n",
    "\n",
    "    # Tercera convolución\n",
    "    conv3 = Conv1D(filters=filters, kernel_size=kernel_size, padding='same', kernel_regularizer=l2(0.01))(conv2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "\n",
    "    # Proyección para hacer coincidir las dimensiones de entrada y salida\n",
    "    shortcut = Conv1D(filters=filters, kernel_size=1, padding='same', kernel_regularizer=l2(0.01))(x)\n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "    # Agregar la conexión residual (entrada proyectada)\n",
    "    output = Add()([shortcut, conv3])\n",
    "    output = ReLU()(output)\n",
    "\n",
    "    return output\n",
    "\n",
    "# Función para crear el modelo ResNet\n",
    "def create_resnet_model(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Primer bloque residual\n",
    "    x = residual_block(inputs, filters=64)\n",
    "\n",
    "    # Segundo bloque residual\n",
    "    x = residual_block(x, filters=128)\n",
    "\n",
    "    # Tercer bloque residual\n",
    "    x = residual_block(x, filters=128)\n",
    "\n",
    "    # Capa de Global Average Pooling\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "    # Capa de salida (softmax)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Definir el modelo\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    # Compilar el modelo\n",
    "    \n",
    "\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Crear el modelo ResNet\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])  # Dimensión de entrada\n",
    "num_classes = y_train.shape[1]  # Número de clases (asumiendo que y_train es one-hot encoded)\n",
    "model = create_resnet_model(input_shape, num_classes)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-5)\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=2, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# Mostrar el resumen de la arquitectura del modelo\n",
    "\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IncepctionFCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Función para crear un bloque de Inception\n",
    "def inception_block(input_tensor, filters):\n",
    "    # Convolución 1x1\n",
    "    conv1 = Conv1D(filters=filters, kernel_size=1, padding='same', activation=None)(input_tensor)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = ReLU()(conv1)\n",
    "\n",
    "    # Convolución 10x1\n",
    "    conv10 = Conv1D(filters=filters, kernel_size=10, padding='same', activation=None)(conv1)\n",
    "    conv10 = BatchNormalization()(conv10)\n",
    "    conv10 = ReLU()(conv10)\n",
    "\n",
    "    # Convolución 20x1\n",
    "    conv20 = Conv1D(filters=filters, kernel_size=20, padding='same', activation=None)(conv10)\n",
    "    conv20 = BatchNormalization()(conv20)\n",
    "    conv20 = ReLU()(conv20)\n",
    "\n",
    "    # MaxPooling seguido de convolución 1x1\n",
    "    pool = MaxPooling1D(pool_size=3, strides=1, padding='same')(input_tensor)\n",
    "    pool_conv = Conv1D(filters=filters, kernel_size=1, padding='same', activation=None)(pool)\n",
    "    pool_conv = BatchNormalization()(pool_conv)\n",
    "    pool_conv = ReLU()(pool_conv)\n",
    "\n",
    "    # Concatenación de las salidas\n",
    "    output = concatenate([conv1, conv10, conv20, pool_conv], axis=-1)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# FCN block basado en las imágenes proporcionadas\n",
    "def fcn_block(input_tensor):\n",
    "    # Seis capas de convolución, cada una con tamaño de filtro 128 y diferentes tamaños de kernel\n",
    "    x = Conv1D(filters=128, kernel_size=1, padding='same')(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = Conv1D(filters=128, kernel_size=3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = Conv1D(filters=128, kernel_size=5, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = Conv1D(filters=128, kernel_size=5, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = Conv1D(filters=128, kernel_size=3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = Conv1D(filters=128, kernel_size=1, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "# Creación del modelo InceptionFCN\n",
    "def create_inceptionfcn_model(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Módulo Inception (dos bloques como se indica en la descripción)\n",
    "    x = inception_block(inputs, filters=64)\n",
    "    x = inception_block(x, filters=64)\n",
    "\n",
    "    # Módulo FCN (Shortcut module)\n",
    "    fcn_output = fcn_block(inputs)\n",
    "\n",
    "    # Concatenar la salida del módulo Inception y el FCN (shortcut module)\n",
    "    combined = concatenate([x, fcn_output])\n",
    "\n",
    "    # Global Average Pooling seguido de Dropout\n",
    "    combined = GlobalAveragePooling1D()(combined)\n",
    "    combined = Dropout(0.5)(combined)\n",
    "    \n",
    "    # Capa de salida softmax\n",
    "    outputs = Dense(num_classes, activation='softmax')(combined)\n",
    "    \n",
    "    # Definir el modelo\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Mostrar resumen del modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])   # Ajustar a la dimensión de tus datos\n",
    "num_classes = y_train.shape[1]      # Ajustar al número de clases en tu dataset\n",
    "\n",
    "model = create_inceptionfcn_model(input_shape, num_classes)\n",
    "\n",
    "# Compilar el modelo con Adam y una tasa de aprendizaje de 1e-3\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks para Early Stopping y reducción de la tasa de aprendizaje\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-5)\n",
    "\n",
    "# Entrenamiento (X_train y y_train deben estar preparados previamente)\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=2, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S2swa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Definir el Encoder-Decoder LSTM\n",
    "\n",
    "def encoder_decoder_lstm(input_shape, n_units=15, target_length=15, dropout_rate=0.3, l2_reg=1e-3):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    # Tres capas LSTM con Batch Normalization, Regularización L2 y Dropout (Encoder)\n",
    "    for _ in range(2):\n",
    "        x = LSTM(n_units, return_sequences=True, kernel_regularizer=l2(l2_reg))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "    encoder_output, state_h, state_c = LSTM(n_units, return_sequences=True, return_state=True, kernel_regularizer=l2(l2_reg))(x)\n",
    "    encoder_states = [state_h, state_c]\n",
    "    \n",
    "    # Longitud de salida fija L (Decoder)\n",
    "    decoder_lstm_layer = LSTM(n_units, return_sequences=True, return_state=True, kernel_regularizer=l2(l2_reg))\n",
    "    decoder_outputs, _, _ = decoder_lstm_layer(encoder_output, initial_state=encoder_states)\n",
    "    # Dos capas LSTM con Batch Normalization y Dropout\n",
    "    for _ in range(1):\n",
    "        decoder_outputs = LSTM(n_units, return_sequences=True, kernel_regularizer=l2(l2_reg))(decoder_outputs)\n",
    "        decoder_outputs = BatchNormalization()(decoder_outputs)\n",
    "        decoder_outputs = Dropout(dropout_rate)(decoder_outputs)\n",
    "    \n",
    "    return inputs, decoder_outputs\n",
    "\n",
    "# Definir el modelo S2SwA\n",
    "def create_s2swa_model(input_shape, target_length, n_units=15, fc_units=400, num_classes=10, dropout_rate=0.3, l2_reg=1e-3):\n",
    "    # Encoder-Decoder\n",
    "    inputs, decoder_outputs = encoder_decoder_lstm(input_shape, n_units, target_length, dropout_rate, l2_reg)\n",
    "    \n",
    "    # Capa totalmente conectada\n",
    "    fc = Dense(fc_units, activation='relu', kernel_regularizer=l2(l2_reg))(decoder_outputs)\n",
    "    fc = Dropout(0.5)(fc)\n",
    "    \n",
    "    # Aplanar antes de la capa de salida\n",
    "    fc = Flatten()(fc)\n",
    "    \n",
    "    # Capa de salida\n",
    "    outputs = Dense(num_classes, activation='softmax')(fc)\n",
    "    \n",
    "    # Definir el modelo completo\n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    # Compilar el modelo con SGD y momentum\n",
    "    \n",
    "    \n",
    "    return model\n",
    "\n",
    "# Mostrar el resumen del modelo\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Crear el modelo\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])  # Ajustar al tamaño de entrada de tus datos\n",
    "target_length = 15     # Longitud fija para la secuencia de salida (L)\n",
    "num_classes = y_train.shape[1]       # Número de clases en el dataset\n",
    "model = create_s2swa_model(input_shape, target_length, n_units=15, num_classes=num_classes, dropout_rate=0.3, l2_reg=1e-3)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Callbacks para Early Stopping y reducción de la tasa de aprendizaje\n",
    "# Callbacks para Early Stopping y reducción de la tasa de aprendizaje\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-5)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "# X_train y y_train del mismo conjunto usado en los modelos anteriores\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=2, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONV-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "class Model_CONV_LSTM(Model):\n",
    "    def __init__(self, num_n_deep=[64, 64, 512, 264, 6], drop_out=[0.3, 0.3], **kwargs):\n",
    "        super(Pasos_Desbaste, self).__init__()\n",
    "\n",
    "        self.num_classes = num_n_deep[-1]  # Asumimos que la última posición de num_n_deep indica el número de clases\n",
    "        self.num_n_deep = num_n_deep\n",
    "        self.drop_out = drop_out\n",
    "\n",
    "        # Inicialización de capas en el constructor\n",
    "        # Capas Conv1D con diferentes filtros\n",
    "        self.Pred_Layer1_conv1 = layers.Conv1D(filters=64, kernel_size=32, padding='same', activation='relu')\n",
    "        self.Pred_Layer1_BatchNorm = layers.BatchNormalization()  # BatchNormalization después de la capa Conv1D\n",
    "        self.Pred_Layer2_conv2 = layers.Conv1D(filters=32, kernel_size=16, padding='same', activation='relu')\n",
    "        self.Pred_Layer2_BatchNorm = layers.BatchNormalization()\n",
    "        self.Pred_Layer3_conv3 = layers.Conv1D(filters=16, kernel_size=8, padding='same', activation='relu')\n",
    "        self.Pred_Layer3_BatchNorm = layers.BatchNormalization()\n",
    "        self.Pred_Layer4_maxpool = layers.MaxPooling1D(pool_size=2)\n",
    "\n",
    "        # Aumentar el número de capas LSTM\n",
    "        self.Pred_Layer5_LSTM = layers.LSTM(units=self.num_n_deep[1], return_sequences=True, dropout=0.3, kernel_regularizer=tf.keras.regularizers.L2(0.007))\n",
    "        self.Pred_Layer5_LayerNorm = layers.LayerNormalization()  # LayerNormalization después de LSTM\n",
    "        self.Pred_Layer6_LSTM = layers.LSTM(units=self.num_n_deep[1], return_sequences=True, dropout=0.3, kernel_regularizer=tf.keras.regularizers.L2(0.007))\n",
    "        self.Pred_Layer6_LayerNorm = layers.LayerNormalization()  # LayerNormalization después de LSTM\n",
    "        self.Pred_Layer7_LSTM = layers.LSTM(units=self.num_n_deep[1], return_sequences=True, dropout=0.4, kernel_regularizer=tf.keras.regularizers.L2(0.007))\n",
    "        self.Pred_Layer7_LayerNorm = layers.LayerNormalization()  # LayerNormalization después de LSTM\n",
    "        self.Pred_Layer8_LSTM = layers.LSTM(units=self.num_n_deep[1], return_sequences=True, dropout=0.4, kernel_regularizer=tf.keras.regularizers.L2(0.007))\n",
    "        self.Pred_Layer8_LayerNorm = layers.LayerNormalization()  # LayerNormalization después de LSTM\n",
    "\n",
    "        # Reducir el número de capas de Atención\n",
    "        self.Attention_Layer1 = layers.Attention()  # Primera capa de atención\n",
    "\n",
    "        self.Pred_GlobalPool = layers.GlobalAveragePooling1D()\n",
    "        self.Pred_Layer10_Dense = layers.Dense(units=self.num_n_deep[2], activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.007))\n",
    "        self.Pred_Layer10_BatchNorm = layers.BatchNormalization()  # BatchNormalization después de Dense\n",
    "        self.Pred_Layer11_Dropout = layers.Dropout(rate=self.drop_out[0])\n",
    "        self.Pred_Layer12_Dense = layers.Dense(units=self.num_n_deep[3], activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.007))\n",
    "        self.Pred_Layer12_BatchNorm = layers.BatchNormalization()  # BatchNormalization después de Dense\n",
    "        self.Pred_Layer13_Dropout = layers.Dropout(rate=self.drop_out[1])\n",
    "        self.Pred_Layer14_Dense = layers.Dense(units=self.num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs, out_before=0, pas_bef=False):\n",
    "        # Capas Conv1D con diferentes filtros\n",
    "        x1 = self.Pred_Layer1_conv1(inputs)\n",
    "        x1 = self.Pred_Layer1_BatchNorm(x1)\n",
    "        x2 = self.Pred_Layer2_conv2(inputs)\n",
    "        x2 = self.Pred_Layer2_BatchNorm(x2)\n",
    "        x3 = self.Pred_Layer3_conv3(inputs)\n",
    "        x3 = self.Pred_Layer3_BatchNorm(x3)\n",
    "\n",
    "        # Concatenar salidas de capas Conv1D\n",
    "        x = layers.Concatenate()([x1, x2, x3])\n",
    "\n",
    "        # Capas LSTM\n",
    "        x_lstm1 = self.Pred_Layer5_LSTM(x)\n",
    "        x_lstm1 = self.Pred_Layer5_LayerNorm(x_lstm1)\n",
    "        x_lstm2 = self.Pred_Layer6_LSTM(x_lstm1)\n",
    "        x_lstm2 = self.Pred_Layer6_LayerNorm(x_lstm2)\n",
    "        x_lstm3 = self.Pred_Layer7_LSTM(x_lstm2)\n",
    "        x_lstm3 = self.Pred_Layer7_LayerNorm(x_lstm3)\n",
    "        x_lstm4 = self.Pred_Layer8_LSTM(x_lstm3)\n",
    "        x_lstm4 = self.Pred_Layer8_LayerNorm(x_lstm4)\n",
    "\n",
    "        # Concatenar salidas de capas LSTM\n",
    "        x = layers.Concatenate()([x_lstm1, x_lstm2, x_lstm3, x_lstm4])\n",
    "\n",
    "        # Aplicar atención\n",
    "        x = self.Attention_Layer1([x, x])\n",
    "\n",
    "        # GlobalAveragePooling1D antes de las capas densas\n",
    "        x = self.Pred_GlobalPool(x)\n",
    "\n",
    "        # Capas densas\n",
    "        x = self.Pred_Layer10_Dense(x)\n",
    "        x = self.Pred_Layer10_BatchNorm(x)\n",
    "        x = self.Pred_Layer11_Dropout(x)\n",
    "        x = self.Pred_Layer12_Dense(x)\n",
    "        x = self.Pred_Layer12_BatchNorm(x)\n",
    "        x = self.Pred_Layer13_Dropout(x)\n",
    "        if pas_bef:\n",
    "            x = layers.Concatenate()([x, out_before])\n",
    "        x = self.Pred_Layer14_Dense(x)\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Crear y compilar el modelo\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])  # Ajustar al tamaño de entrada de tus datos\n",
    "num_classes = y_train.shape[1]  # Número de clases en los datos de entrenamiento\n",
    "model = Model_CONV_LSTM(num_n_deep=[64, 64, 512, 264, num_classes])\n",
    "model.build((None, *input_shape))\n",
    "# Mostrar el resumen del modelo\n",
    "model.summary()\n",
    "# Compilar el modelo con Adam\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks para Early Stopping y reducción de la tasa de aprendizaje\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6)\n",
    "\n",
    "# Callback para el planificador de tasa de aprendizaje\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "learning_rate_scheduler = LearningRateScheduler(scheduler)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=2,\n",
    "                    callbacks=[early_stopping, reduce_lr, learning_rate_scheduler])\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cearr\\AppData\\Local\\Temp\\ipykernel_5904\\1296174688.py:126: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, pd.DataFrame([{\n"
     ]
    }
   ],
   "source": [
    "def load_ts_file(file_path):\n",
    "    \"\"\"\n",
    "    Función para cargar archivos .ts y separar características y etiquetas.\n",
    "    Asume que las características están separadas por comas y las etiquetas están separadas por dos puntos (:).\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    # Leer el archivo línea por línea\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Separar características y etiquetas usando \":\"\n",
    "            line_split = line.strip().split(':')\n",
    "            # Verificar si la línea tiene características y una etiqueta\n",
    "            if len(line_split) == 2:\n",
    "                # Las características están antes del \":\"\n",
    "                features.append([float(val) for val in line_split[0].split(',')])\n",
    "                # La etiqueta está después del \":\" (solo una columna, un valor)\n",
    "                label = int(line_split[1].strip())  # Se elimina cualquier espacio adicional\n",
    "                labels.append(label)\n",
    "    # Convertir a DataFrame para las características y convertir las etiquetas en array\n",
    "    X = pd.DataFrame(features)\n",
    "    y = pd.DataFrame(labels, columns=['Etiqueta'])\n",
    "\n",
    "    return X, y\n",
    "# Callbacks comunes\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6)\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "learning_rate_scheduler = LearningRateScheduler(scheduler)\n",
    "\n",
    "# Definir los modelos disponibles\n",
    "model_functions = {\n",
    "    'MLP': create_mlp,\n",
    "    'FCN': create_fcn_model,\n",
    "    'ResNet': create_resnet_model,\n",
    "    'InceptionFCN': create_inceptionfcn_model,\n",
    "    'Seq2SeqwA': create_s2swa_model,\n",
    "    'CONV_LSTM': lambda input_shape, num_classes: Model_CONV_LSTM(num_n_deep=[64, 64, 512, 264, num_classes])\n",
    "}\n",
    "\n",
    "# Definir los datasets disponibles\n",
    "file_paths_train = [\n",
    "    'I:/Maestria/IA/Proyecto/Proyecto/Dataset/ElectricDeviceDetection/ElectricDeviceDetection_TRAIN.ts',\n",
    "    'I:/Maestria/IA/Proyecto/Proyecto/Dataset/FaultDetectionA/FaultDetectionA_TRAIN.ts',\n",
    "    'I:/Maestria/IA/Proyecto/Proyecto/Dataset/FaultDetectionB/FaultDetectionB_TRAIN.ts'\n",
    "    'I:/Maestria/IA/Proyecto/Proyecto/Dataset/FordA/FordA_TRAIN.ts'\n",
    "    'I:/Maestria/IA/Proyecto/Proyecto/Dataset/FordB/FordB_TRAIN.ts'\n",
    "    'I:/Maestria/IA/Proyecto/Proyecto/Dataset/FreezerRegularTrain/FreezerRegularTrain_TRAIN.ts'\n",
    "    'I:/Maestria/IA/Proyecto/Proyecto/Dataset/FreezerSmallTrain/FreezerSmallTrain_TRAIN.ts'\n",
    "    'I:/Maestria/IA/Proyecto/Proyecto/Dataset/KeplerLightCurves/KeplerLightCurves_TRAIN.ts'\n",
    "    'I:/Maestria/IA/Proyecto/Proyecto/Dataset/StarLightCurves/StarLightCurves_TRAIN.ts'\n",
    "    'I:/Maestria/IA/Proyecto/Proyecto/Dataset/Wafer/Wafer_TRAIN.ts'\n",
    "]\n",
    "\n",
    "file_paths_test = [\n",
    "    'I:/Maestria/IA/Proyecto/Proyecto/Dataset/ElectricDeviceDetection/ElectricDeviceDetection_TEST.ts',\n",
    "    'I:/Maestria/IA/Proyecto/Proyecto/Dataset/FaultDetectionA/FaultDetectionA_TEST.ts',\n",
    "    'I:/Maestria/IA/Proyecto/Proyecto/Dataset/FaultDetectionB/FaultDetectionB_TEST.ts'\n",
    "    'I:/Maestria/IA/Proyecto/Proyecto/Dataset/FordA/FordA_TEST.ts'\n",
    "    'I:/Maestria/IA/Proyecto/Proyecto/Dataset/FordB/FordB_TEST.ts'\n",
    "    'I:/Maestria/IA/Proyecto/Proyecto/Dataset/FreezerRegularTrain/FreezerRegularTrain_TEST.ts'\n",
    "    'I:/Maestria/IA/Proyecto/Proyecto/Dataset/FreezerSmallTrain/FreezerSmallTrain_TEST.ts'\n",
    "    'I:/Maestria/IA/Proyecto/Proyecto/Dataset/KeplerLightCurves/KeplerLightCurves_TEST.ts'\n",
    "    'I:/Maestria/IA/Proyecto/Proyecto/Dataset/StarLightCurves/StarLightCurves_TEST.ts'\n",
    "    'I:/Maestria/IA/Proyecto/Proyecto/Dataset/Wafer/Wafer_TEST.ts'\n",
    "\n",
    "]\n",
    "\n",
    "# Inicializar DataFrame para almacenar resultados\n",
    "results_df = pd.DataFrame(columns=['Model', 'Dataset', 'Accuracy', 'Precision', 'Recall', 'Training Time'])\n",
    "\n",
    "# Bucle a través de cada dataset y cada modelo\n",
    "for train_path, test_path in zip(file_paths_train, file_paths_test):\n",
    "    # Cargar los datos\n",
    "    X_train, y_train = load_ts_file(train_path)\n",
    "    X_test, y_test = load_ts_file(test_path)\n",
    "\n",
    "    # Preprocesamiento de datos\n",
    "    y_train = pd.get_dummies(y_train, columns=['Etiqueta'])\n",
    "    y_test = pd.get_dummies(y_test, columns=['Etiqueta'])\n",
    "    X_train, y_train = shuffle(X_train, y_train)\n",
    "    X_train = np.expand_dims(X_train, axis=1)\n",
    "    X_test = np.expand_dims(X_test, axis=1)\n",
    "\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    num_classes = y_train.shape[1]\n",
    "\n",
    "    for model_name, model_function in model_functions.items():\n",
    "        # Crear el modelo\n",
    "        if model_name == 'CONV_LSTM':\n",
    "            model = model_function(num_n_deep=[64, 64, 512, 264, num_classes])\n",
    "            model.build((None, *input_shape))\n",
    "        if model_name == \"S2SwA\":\n",
    "            model = model_fn(input_shape, target_length = 15, n_units=15, num_classes=num_classes, dropout_rate=0.3, l2_reg=1e-3)\n",
    "\n",
    "        else:\n",
    "            model = model_function(input_shape, num_classes)\n",
    "\n",
    "        # Compilar el modelo\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy', Precision(), Recall()])\n",
    "\n",
    "        # Entrenar el modelo\n",
    "        start_time = time.time()\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_test, y_test),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=[early_stopping, reduce_lr, learning_rate_scheduler],\n",
    "            verbose=0\n",
    "        )\n",
    "        training_time = time.time() - start_time\n",
    "\n",
    "        # Evaluar el modelo\n",
    "        scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "        accuracy = scores[1]\n",
    "        precision = scores[2]\n",
    "        recall = scores[3]\n",
    "\n",
    "        # Almacenar resultados\n",
    "        results_df = pd.concat([results_df, pd.DataFrame([{\n",
    "            'Model': model_name,\n",
    "            'Dataset': train_path.split('/')[-2],  # Extraer nombre del dataset\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'Training Time': training_time\n",
    "        }])], ignore_index=True)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluando modelo: MLP\n",
      "Epoch 1/400\n",
      "2/2 - 2s - loss: 16.0879 - accuracy: 0.1887 - val_loss: 32.4382 - val_accuracy: 0.0714 - lr: 0.0010 - 2s/epoch - 985ms/step\n",
      "Epoch 2/400\n",
      "2/2 - 0s - loss: 15.8921 - accuracy: 0.3019 - val_loss: 12.4943 - val_accuracy: 0.2143 - lr: 0.0010 - 44ms/epoch - 22ms/step\n",
      "Epoch 3/400\n",
      "2/2 - 0s - loss: 9.9697 - accuracy: 0.2264 - val_loss: 4.5003 - val_accuracy: 0.0714 - lr: 0.0010 - 42ms/epoch - 21ms/step\n",
      "Epoch 4/400\n",
      "2/2 - 0s - loss: 5.0359 - accuracy: 0.2642 - val_loss: 2.7707 - val_accuracy: 0.4286 - lr: 0.0010 - 45ms/epoch - 22ms/step\n",
      "Epoch 5/400\n",
      "2/2 - 0s - loss: 2.6008 - accuracy: 0.3962 - val_loss: 3.0291 - val_accuracy: 0.3571 - lr: 0.0010 - 35ms/epoch - 17ms/step\n",
      "Epoch 6/400\n",
      "2/2 - 0s - loss: 2.4451 - accuracy: 0.3585 - val_loss: 1.7903 - val_accuracy: 0.4286 - lr: 0.0010 - 41ms/epoch - 21ms/step\n",
      "Epoch 7/400\n",
      "2/2 - 0s - loss: 1.8704 - accuracy: 0.4340 - val_loss: 1.8123 - val_accuracy: 0.1429 - lr: 0.0010 - 41ms/epoch - 21ms/step\n",
      "Epoch 8/400\n",
      "2/2 - 0s - loss: 1.3725 - accuracy: 0.3774 - val_loss: 2.7043 - val_accuracy: 0.2143 - lr: 0.0010 - 39ms/epoch - 20ms/step\n",
      "Epoch 9/400\n",
      "2/2 - 0s - loss: 1.6969 - accuracy: 0.4340 - val_loss: 1.8467 - val_accuracy: 0.2857 - lr: 0.0010 - 38ms/epoch - 19ms/step\n",
      "Epoch 10/400\n",
      "2/2 - 0s - loss: 1.3188 - accuracy: 0.4528 - val_loss: 1.7483 - val_accuracy: 0.2857 - lr: 0.0010 - 43ms/epoch - 21ms/step\n",
      "Epoch 11/400\n",
      "2/2 - 0s - loss: 1.3395 - accuracy: 0.5660 - val_loss: 1.4871 - val_accuracy: 0.3571 - lr: 9.0484e-04 - 43ms/epoch - 22ms/step\n",
      "Epoch 12/400\n",
      "2/2 - 0s - loss: 1.0888 - accuracy: 0.5849 - val_loss: 1.4242 - val_accuracy: 0.3571 - lr: 8.1873e-04 - 40ms/epoch - 20ms/step\n",
      "Epoch 13/400\n",
      "2/2 - 0s - loss: 0.9645 - accuracy: 0.6792 - val_loss: 1.4075 - val_accuracy: 0.5000 - lr: 7.4082e-04 - 38ms/epoch - 19ms/step\n",
      "Epoch 14/400\n",
      "2/2 - 0s - loss: 0.8694 - accuracy: 0.6226 - val_loss: 1.5077 - val_accuracy: 0.3571 - lr: 6.7032e-04 - 39ms/epoch - 19ms/step\n",
      "Epoch 15/400\n",
      "2/2 - 0s - loss: 0.9405 - accuracy: 0.6604 - val_loss: 1.5811 - val_accuracy: 0.2857 - lr: 6.0653e-04 - 48ms/epoch - 24ms/step\n",
      "Epoch 16/400\n",
      "2/2 - 0s - loss: 0.7785 - accuracy: 0.7736 - val_loss: 1.5586 - val_accuracy: 0.2857 - lr: 5.4881e-04 - 43ms/epoch - 21ms/step\n",
      "Epoch 17/400\n",
      "2/2 - 0s - loss: 0.7982 - accuracy: 0.6792 - val_loss: 1.4573 - val_accuracy: 0.2857 - lr: 4.9659e-04 - 34ms/epoch - 17ms/step\n",
      "Epoch 18/400\n",
      "2/2 - 0s - loss: 0.6902 - accuracy: 0.7358 - val_loss: 1.3941 - val_accuracy: 0.2143 - lr: 4.4933e-04 - 41ms/epoch - 20ms/step\n",
      "Epoch 19/400\n",
      "2/2 - 0s - loss: 0.5937 - accuracy: 0.7736 - val_loss: 1.4045 - val_accuracy: 0.2857 - lr: 4.0657e-04 - 42ms/epoch - 21ms/step\n",
      "Epoch 20/400\n",
      "2/2 - 0s - loss: 0.5385 - accuracy: 0.8491 - val_loss: 1.4143 - val_accuracy: 0.2857 - lr: 3.6788e-04 - 39ms/epoch - 20ms/step\n",
      "Epoch 21/400\n",
      "2/2 - 0s - loss: 0.3848 - accuracy: 0.9434 - val_loss: 1.3942 - val_accuracy: 0.3571 - lr: 3.3287e-04 - 38ms/epoch - 19ms/step\n",
      "Epoch 22/400\n",
      "2/2 - 0s - loss: 0.4756 - accuracy: 0.8302 - val_loss: 1.3863 - val_accuracy: 0.4286 - lr: 3.0119e-04 - 41ms/epoch - 21ms/step\n",
      "Epoch 23/400\n",
      "2/2 - 0s - loss: 0.4290 - accuracy: 0.8868 - val_loss: 1.3906 - val_accuracy: 0.4286 - lr: 2.7253e-04 - 39ms/epoch - 20ms/step\n",
      "Epoch 24/400\n",
      "2/2 - 0s - loss: 0.5549 - accuracy: 0.8302 - val_loss: 1.3761 - val_accuracy: 0.4286 - lr: 2.4660e-04 - 37ms/epoch - 18ms/step\n",
      "Epoch 25/400\n",
      "2/2 - 0s - loss: 0.4968 - accuracy: 0.8679 - val_loss: 1.3452 - val_accuracy: 0.4286 - lr: 2.2313e-04 - 44ms/epoch - 22ms/step\n",
      "Epoch 26/400\n",
      "2/2 - 0s - loss: 0.4001 - accuracy: 0.9057 - val_loss: 1.3228 - val_accuracy: 0.5000 - lr: 2.0190e-04 - 40ms/epoch - 20ms/step\n",
      "Epoch 27/400\n",
      "2/2 - 0s - loss: 0.3950 - accuracy: 0.8679 - val_loss: 1.2844 - val_accuracy: 0.5000 - lr: 1.8268e-04 - 39ms/epoch - 19ms/step\n",
      "Epoch 28/400\n",
      "2/2 - 0s - loss: 0.3136 - accuracy: 0.9245 - val_loss: 1.2579 - val_accuracy: 0.5000 - lr: 1.6530e-04 - 47ms/epoch - 23ms/step\n",
      "Epoch 29/400\n",
      "2/2 - 0s - loss: 0.3182 - accuracy: 0.9245 - val_loss: 1.2496 - val_accuracy: 0.5000 - lr: 1.4957e-04 - 51ms/epoch - 26ms/step\n",
      "Epoch 30/400\n",
      "2/2 - 0s - loss: 0.2907 - accuracy: 0.9623 - val_loss: 1.2683 - val_accuracy: 0.4286 - lr: 1.3534e-04 - 43ms/epoch - 21ms/step\n",
      "Epoch 31/400\n",
      "2/2 - 0s - loss: 0.3278 - accuracy: 0.8868 - val_loss: 1.2935 - val_accuracy: 0.4286 - lr: 1.2246e-04 - 39ms/epoch - 19ms/step\n",
      "Epoch 32/400\n",
      "2/2 - 0s - loss: 0.4173 - accuracy: 0.8868 - val_loss: 1.3101 - val_accuracy: 0.3571 - lr: 1.1080e-04 - 41ms/epoch - 21ms/step\n",
      "Epoch 33/400\n",
      "2/2 - 0s - loss: 0.2748 - accuracy: 0.9623 - val_loss: 1.3086 - val_accuracy: 0.3571 - lr: 1.0026e-04 - 40ms/epoch - 20ms/step\n",
      "Epoch 34/400\n",
      "2/2 - 0s - loss: 0.2981 - accuracy: 0.9623 - val_loss: 1.3098 - val_accuracy: 0.3571 - lr: 9.0718e-05 - 37ms/epoch - 18ms/step\n",
      "Epoch 35/400\n",
      "2/2 - 0s - loss: 0.3422 - accuracy: 0.9434 - val_loss: 1.3130 - val_accuracy: 0.3571 - lr: 8.2085e-05 - 36ms/epoch - 18ms/step\n",
      "Epoch 36/400\n",
      "2/2 - 0s - loss: 0.2548 - accuracy: 0.9811 - val_loss: 1.3083 - val_accuracy: 0.4286 - lr: 7.4273e-05 - 39ms/epoch - 19ms/step\n",
      "Epoch 37/400\n",
      "2/2 - 0s - loss: 0.3366 - accuracy: 0.8868 - val_loss: 1.2963 - val_accuracy: 0.3571 - lr: 6.7205e-05 - 35ms/epoch - 17ms/step\n",
      "Epoch 38/400\n",
      "2/2 - 0s - loss: 0.3350 - accuracy: 0.9245 - val_loss: 1.2893 - val_accuracy: 0.4286 - lr: 6.0810e-05 - 37ms/epoch - 19ms/step\n",
      "Epoch 39/400\n",
      "2/2 - 0s - loss: 0.3353 - accuracy: 0.8868 - val_loss: 1.2820 - val_accuracy: 0.4286 - lr: 2.7512e-05 - 42ms/epoch - 21ms/step\n",
      "Epoch 40/400\n",
      "2/2 - 0s - loss: 0.2428 - accuracy: 0.9434 - val_loss: 1.2814 - val_accuracy: 0.4286 - lr: 2.4893e-05 - 37ms/epoch - 19ms/step\n",
      "Epoch 41/400\n",
      "2/2 - 0s - loss: 0.3178 - accuracy: 0.9057 - val_loss: 1.2783 - val_accuracy: 0.5000 - lr: 2.2525e-05 - 38ms/epoch - 19ms/step\n",
      "Epoch 42/400\n",
      "2/2 - 0s - loss: 0.2739 - accuracy: 0.9057 - val_loss: 1.2741 - val_accuracy: 0.5000 - lr: 2.0381e-05 - 37ms/epoch - 18ms/step\n",
      "Epoch 43/400\n",
      "2/2 - 0s - loss: 0.2660 - accuracy: 0.9434 - val_loss: 1.2729 - val_accuracy: 0.5000 - lr: 1.8442e-05 - 37ms/epoch - 19ms/step\n",
      "Epoch 44/400\n",
      "2/2 - 0s - loss: 0.3270 - accuracy: 0.9057 - val_loss: 1.2728 - val_accuracy: 0.5000 - lr: 1.6687e-05 - 40ms/epoch - 20ms/step\n",
      "Epoch 45/400\n",
      "2/2 - 0s - loss: 0.3386 - accuracy: 0.8491 - val_loss: 1.2735 - val_accuracy: 0.5000 - lr: 1.5099e-05 - 39ms/epoch - 19ms/step\n",
      "Epoch 46/400\n",
      "2/2 - 0s - loss: 0.2926 - accuracy: 0.9434 - val_loss: 1.2727 - val_accuracy: 0.5000 - lr: 1.3662e-05 - 39ms/epoch - 20ms/step\n",
      "Epoch 47/400\n",
      "2/2 - 0s - loss: 0.1911 - accuracy: 1.0000 - val_loss: 1.2711 - val_accuracy: 0.5000 - lr: 1.2362e-05 - 39ms/epoch - 20ms/step\n",
      "Epoch 48/400\n",
      "2/2 - 0s - loss: 0.2818 - accuracy: 0.9623 - val_loss: 1.2710 - val_accuracy: 0.5000 - lr: 1.1185e-05 - 38ms/epoch - 19ms/step\n",
      "Epoch 49/400\n",
      "2/2 - 0s - loss: 0.3374 - accuracy: 0.9245 - val_loss: 1.2688 - val_accuracy: 0.5000 - lr: 5.0605e-06 - 55ms/epoch - 28ms/step\n",
      "Evaluando modelo: FCN\n",
      "Epoch 1/400\n",
      "2/2 - 3s - loss: 2.2815 - accuracy: 0.1887 - val_loss: 2.5998 - val_accuracy: 0.0714 - lr: 0.0010 - 3s/epoch - 2s/step\n",
      "Epoch 2/400\n",
      "2/2 - 0s - loss: 0.6919 - accuracy: 0.8302 - val_loss: 2.6168 - val_accuracy: 0.0714 - lr: 0.0010 - 39ms/epoch - 19ms/step\n",
      "Epoch 3/400\n",
      "2/2 - 0s - loss: 0.3504 - accuracy: 0.9811 - val_loss: 2.6606 - val_accuracy: 0.1429 - lr: 0.0010 - 38ms/epoch - 19ms/step\n",
      "Epoch 4/400\n",
      "2/2 - 0s - loss: 0.1974 - accuracy: 1.0000 - val_loss: 2.6791 - val_accuracy: 0.1429 - lr: 0.0010 - 36ms/epoch - 18ms/step\n",
      "Epoch 5/400\n",
      "2/2 - 0s - loss: 0.1146 - accuracy: 1.0000 - val_loss: 2.6507 - val_accuracy: 0.2143 - lr: 0.0010 - 37ms/epoch - 18ms/step\n",
      "Epoch 6/400\n",
      "2/2 - 0s - loss: 0.0888 - accuracy: 1.0000 - val_loss: 2.5821 - val_accuracy: 0.2143 - lr: 0.0010 - 44ms/epoch - 22ms/step\n",
      "Epoch 7/400\n",
      "2/2 - 0s - loss: 0.0611 - accuracy: 1.0000 - val_loss: 2.4876 - val_accuracy: 0.2143 - lr: 0.0010 - 42ms/epoch - 21ms/step\n",
      "Epoch 8/400\n",
      "2/2 - 0s - loss: 0.0489 - accuracy: 1.0000 - val_loss: 2.3994 - val_accuracy: 0.2143 - lr: 0.0010 - 41ms/epoch - 21ms/step\n",
      "Epoch 9/400\n",
      "2/2 - 0s - loss: 0.0391 - accuracy: 1.0000 - val_loss: 2.3337 - val_accuracy: 0.2143 - lr: 0.0010 - 42ms/epoch - 21ms/step\n",
      "Epoch 10/400\n",
      "2/2 - 0s - loss: 0.0382 - accuracy: 1.0000 - val_loss: 2.2707 - val_accuracy: 0.2143 - lr: 0.0010 - 43ms/epoch - 21ms/step\n",
      "Epoch 11/400\n",
      "2/2 - 0s - loss: 0.0300 - accuracy: 1.0000 - val_loss: 2.2192 - val_accuracy: 0.2857 - lr: 9.0484e-04 - 42ms/epoch - 21ms/step\n",
      "Epoch 12/400\n",
      "2/2 - 0s - loss: 0.0222 - accuracy: 1.0000 - val_loss: 2.1811 - val_accuracy: 0.2857 - lr: 8.1873e-04 - 43ms/epoch - 22ms/step\n",
      "Epoch 13/400\n",
      "2/2 - 0s - loss: 0.0183 - accuracy: 1.0000 - val_loss: 2.1474 - val_accuracy: 0.2857 - lr: 7.4082e-04 - 44ms/epoch - 22ms/step\n",
      "Epoch 14/400\n",
      "2/2 - 0s - loss: 0.0214 - accuracy: 1.0000 - val_loss: 2.1267 - val_accuracy: 0.2857 - lr: 6.7032e-04 - 47ms/epoch - 23ms/step\n",
      "Epoch 15/400\n",
      "2/2 - 0s - loss: 0.0230 - accuracy: 1.0000 - val_loss: 2.1182 - val_accuracy: 0.2857 - lr: 6.0653e-04 - 42ms/epoch - 21ms/step\n",
      "Epoch 16/400\n",
      "2/2 - 0s - loss: 0.0172 - accuracy: 1.0000 - val_loss: 2.1059 - val_accuracy: 0.2857 - lr: 5.4881e-04 - 44ms/epoch - 22ms/step\n",
      "Epoch 17/400\n",
      "2/2 - 0s - loss: 0.0222 - accuracy: 1.0000 - val_loss: 2.0922 - val_accuracy: 0.2143 - lr: 4.9659e-04 - 45ms/epoch - 23ms/step\n",
      "Epoch 18/400\n",
      "2/2 - 0s - loss: 0.0217 - accuracy: 1.0000 - val_loss: 2.0823 - val_accuracy: 0.2143 - lr: 4.4933e-04 - 42ms/epoch - 21ms/step\n",
      "Epoch 19/400\n",
      "2/2 - 0s - loss: 0.0138 - accuracy: 1.0000 - val_loss: 2.0674 - val_accuracy: 0.2143 - lr: 4.0657e-04 - 41ms/epoch - 21ms/step\n",
      "Epoch 20/400\n",
      "2/2 - 0s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.0524 - val_accuracy: 0.2143 - lr: 3.6788e-04 - 41ms/epoch - 21ms/step\n",
      "Epoch 21/400\n",
      "2/2 - 0s - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.0358 - val_accuracy: 0.2143 - lr: 3.3287e-04 - 42ms/epoch - 21ms/step\n",
      "Epoch 22/400\n",
      "2/2 - 0s - loss: 0.0134 - accuracy: 1.0000 - val_loss: 2.0180 - val_accuracy: 0.2143 - lr: 3.0119e-04 - 39ms/epoch - 20ms/step\n",
      "Epoch 23/400\n",
      "2/2 - 0s - loss: 0.0131 - accuracy: 1.0000 - val_loss: 1.9997 - val_accuracy: 0.2143 - lr: 2.7253e-04 - 42ms/epoch - 21ms/step\n",
      "Epoch 24/400\n",
      "2/2 - 0s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 1.9831 - val_accuracy: 0.2143 - lr: 2.4660e-04 - 42ms/epoch - 21ms/step\n",
      "Epoch 25/400\n",
      "2/2 - 0s - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.9671 - val_accuracy: 0.2143 - lr: 2.2313e-04 - 43ms/epoch - 21ms/step\n",
      "Epoch 26/400\n",
      "2/2 - 0s - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.9498 - val_accuracy: 0.2143 - lr: 2.0190e-04 - 45ms/epoch - 22ms/step\n",
      "Epoch 27/400\n",
      "2/2 - 0s - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.9327 - val_accuracy: 0.2143 - lr: 1.8268e-04 - 50ms/epoch - 25ms/step\n",
      "Epoch 28/400\n",
      "2/2 - 0s - loss: 0.0131 - accuracy: 1.0000 - val_loss: 1.9165 - val_accuracy: 0.2143 - lr: 1.6530e-04 - 41ms/epoch - 21ms/step\n",
      "Epoch 29/400\n",
      "2/2 - 0s - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.9016 - val_accuracy: 0.2143 - lr: 1.4957e-04 - 42ms/epoch - 21ms/step\n",
      "Epoch 30/400\n",
      "2/2 - 0s - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.8868 - val_accuracy: 0.2143 - lr: 1.3534e-04 - 42ms/epoch - 21ms/step\n",
      "Epoch 31/400\n",
      "2/2 - 0s - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.8715 - val_accuracy: 0.2143 - lr: 1.2246e-04 - 43ms/epoch - 22ms/step\n",
      "Epoch 32/400\n",
      "2/2 - 0s - loss: 0.0176 - accuracy: 1.0000 - val_loss: 1.8573 - val_accuracy: 0.2143 - lr: 1.1080e-04 - 43ms/epoch - 21ms/step\n",
      "Epoch 33/400\n",
      "2/2 - 0s - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.8447 - val_accuracy: 0.2143 - lr: 1.0026e-04 - 42ms/epoch - 21ms/step\n",
      "Epoch 34/400\n",
      "2/2 - 0s - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.8312 - val_accuracy: 0.2143 - lr: 9.0718e-05 - 42ms/epoch - 21ms/step\n",
      "Epoch 35/400\n",
      "2/2 - 0s - loss: 0.0121 - accuracy: 1.0000 - val_loss: 1.8189 - val_accuracy: 0.2143 - lr: 8.2085e-05 - 43ms/epoch - 21ms/step\n",
      "Epoch 36/400\n",
      "2/2 - 0s - loss: 0.0111 - accuracy: 1.0000 - val_loss: 1.8051 - val_accuracy: 0.2143 - lr: 7.4273e-05 - 43ms/epoch - 22ms/step\n",
      "Epoch 37/400\n",
      "2/2 - 0s - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.7922 - val_accuracy: 0.2143 - lr: 6.7205e-05 - 44ms/epoch - 22ms/step\n",
      "Epoch 38/400\n",
      "2/2 - 0s - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.7797 - val_accuracy: 0.2143 - lr: 6.0810e-05 - 44ms/epoch - 22ms/step\n",
      "Epoch 39/400\n",
      "2/2 - 0s - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.7672 - val_accuracy: 0.1429 - lr: 5.5023e-05 - 46ms/epoch - 23ms/step\n",
      "Epoch 40/400\n",
      "2/2 - 0s - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.7557 - val_accuracy: 0.1429 - lr: 4.9787e-05 - 42ms/epoch - 21ms/step\n",
      "Epoch 41/400\n",
      "2/2 - 0s - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.7450 - val_accuracy: 0.2143 - lr: 4.5049e-05 - 45ms/epoch - 22ms/step\n",
      "Epoch 42/400\n",
      "2/2 - 0s - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.7346 - val_accuracy: 0.2143 - lr: 4.0762e-05 - 46ms/epoch - 23ms/step\n",
      "Epoch 43/400\n",
      "2/2 - 0s - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.7246 - val_accuracy: 0.2143 - lr: 3.6883e-05 - 45ms/epoch - 23ms/step\n",
      "Epoch 44/400\n",
      "2/2 - 0s - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.7150 - val_accuracy: 0.2143 - lr: 3.3373e-05 - 42ms/epoch - 21ms/step\n",
      "Epoch 45/400\n",
      "2/2 - 0s - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.7057 - val_accuracy: 0.1429 - lr: 3.0197e-05 - 45ms/epoch - 22ms/step\n",
      "Epoch 46/400\n",
      "2/2 - 0s - loss: 0.0163 - accuracy: 1.0000 - val_loss: 1.6962 - val_accuracy: 0.2143 - lr: 2.7324e-05 - 49ms/epoch - 24ms/step\n",
      "Epoch 47/400\n",
      "2/2 - 0s - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.6887 - val_accuracy: 0.2143 - lr: 2.4723e-05 - 44ms/epoch - 22ms/step\n",
      "Epoch 48/400\n",
      "2/2 - 0s - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.6804 - val_accuracy: 0.2143 - lr: 2.2371e-05 - 43ms/epoch - 21ms/step\n",
      "Epoch 49/400\n",
      "2/2 - 0s - loss: 0.0135 - accuracy: 1.0000 - val_loss: 1.6714 - val_accuracy: 0.2857 - lr: 2.0242e-05 - 43ms/epoch - 22ms/step\n",
      "Epoch 50/400\n",
      "2/2 - 0s - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.6634 - val_accuracy: 0.2857 - lr: 1.8316e-05 - 48ms/epoch - 24ms/step\n",
      "Epoch 51/400\n",
      "2/2 - 0s - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.6552 - val_accuracy: 0.2857 - lr: 1.6573e-05 - 46ms/epoch - 23ms/step\n",
      "Epoch 52/400\n",
      "2/2 - 0s - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.6461 - val_accuracy: 0.2857 - lr: 1.4996e-05 - 45ms/epoch - 22ms/step\n",
      "Epoch 53/400\n",
      "2/2 - 0s - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.6378 - val_accuracy: 0.2857 - lr: 1.3569e-05 - 45ms/epoch - 22ms/step\n",
      "Epoch 54/400\n",
      "2/2 - 0s - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.6301 - val_accuracy: 0.2857 - lr: 1.2277e-05 - 46ms/epoch - 23ms/step\n",
      "Epoch 55/400\n",
      "2/2 - 0s - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.6222 - val_accuracy: 0.2857 - lr: 1.1109e-05 - 50ms/epoch - 25ms/step\n",
      "Epoch 56/400\n",
      "2/2 - 0s - loss: 0.0158 - accuracy: 1.0000 - val_loss: 1.6146 - val_accuracy: 0.2857 - lr: 1.0052e-05 - 44ms/epoch - 22ms/step\n",
      "Epoch 57/400\n",
      "2/2 - 0s - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.6070 - val_accuracy: 0.2857 - lr: 9.0953e-06 - 44ms/epoch - 22ms/step\n",
      "Epoch 58/400\n",
      "2/2 - 0s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 1.5985 - val_accuracy: 0.2857 - lr: 8.2297e-06 - 46ms/epoch - 23ms/step\n",
      "Epoch 59/400\n",
      "2/2 - 0s - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.5907 - val_accuracy: 0.2857 - lr: 7.4466e-06 - 46ms/epoch - 23ms/step\n",
      "Epoch 60/400\n",
      "2/2 - 0s - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.5834 - val_accuracy: 0.2857 - lr: 6.7379e-06 - 47ms/epoch - 23ms/step\n",
      "Epoch 61/400\n",
      "2/2 - 0s - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.5763 - val_accuracy: 0.2857 - lr: 6.0967e-06 - 48ms/epoch - 24ms/step\n",
      "Epoch 62/400\n",
      "2/2 - 0s - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.5689 - val_accuracy: 0.2857 - lr: 5.5165e-06 - 50ms/epoch - 25ms/step\n",
      "Epoch 63/400\n",
      "2/2 - 0s - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.5617 - val_accuracy: 0.2857 - lr: 4.9916e-06 - 51ms/epoch - 25ms/step\n",
      "Epoch 64/400\n",
      "2/2 - 0s - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.5548 - val_accuracy: 0.2857 - lr: 4.5166e-06 - 50ms/epoch - 25ms/step\n",
      "Epoch 65/400\n",
      "2/2 - 0s - loss: 0.0147 - accuracy: 1.0000 - val_loss: 1.5479 - val_accuracy: 0.2857 - lr: 4.0868e-06 - 49ms/epoch - 24ms/step\n",
      "Epoch 66/400\n",
      "2/2 - 0s - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.5412 - val_accuracy: 0.3571 - lr: 3.6979e-06 - 47ms/epoch - 24ms/step\n",
      "Epoch 67/400\n",
      "2/2 - 0s - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.5347 - val_accuracy: 0.3571 - lr: 3.3460e-06 - 44ms/epoch - 22ms/step\n",
      "Epoch 68/400\n",
      "2/2 - 0s - loss: 0.0141 - accuracy: 1.0000 - val_loss: 1.5274 - val_accuracy: 0.2857 - lr: 3.0275e-06 - 47ms/epoch - 23ms/step\n",
      "Epoch 69/400\n",
      "2/2 - 0s - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.5214 - val_accuracy: 0.2857 - lr: 2.7394e-06 - 47ms/epoch - 23ms/step\n",
      "Epoch 70/400\n",
      "2/2 - 0s - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.5155 - val_accuracy: 0.2857 - lr: 2.4787e-06 - 42ms/epoch - 21ms/step\n",
      "Epoch 71/400\n",
      "2/2 - 0s - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.5100 - val_accuracy: 0.3571 - lr: 2.2429e-06 - 44ms/epoch - 22ms/step\n",
      "Epoch 72/400\n",
      "2/2 - 0s - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.5051 - val_accuracy: 0.3571 - lr: 2.0294e-06 - 44ms/epoch - 22ms/step\n",
      "Epoch 73/400\n",
      "2/2 - 0s - loss: 0.0133 - accuracy: 1.0000 - val_loss: 1.5012 - val_accuracy: 0.3571 - lr: 1.8363e-06 - 46ms/epoch - 23ms/step\n",
      "Epoch 74/400\n",
      "2/2 - 0s - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.4961 - val_accuracy: 0.3571 - lr: 1.6616e-06 - 41ms/epoch - 20ms/step\n",
      "Epoch 75/400\n",
      "2/2 - 0s - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.4915 - val_accuracy: 0.3571 - lr: 1.5034e-06 - 44ms/epoch - 22ms/step\n",
      "Epoch 76/400\n",
      "2/2 - 0s - loss: 0.0111 - accuracy: 1.0000 - val_loss: 1.4862 - val_accuracy: 0.3571 - lr: 1.3604e-06 - 41ms/epoch - 21ms/step\n",
      "Epoch 77/400\n",
      "2/2 - 0s - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.4814 - val_accuracy: 0.3571 - lr: 1.2309e-06 - 43ms/epoch - 22ms/step\n",
      "Epoch 78/400\n",
      "2/2 - 0s - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.4771 - val_accuracy: 0.3571 - lr: 1.1138e-06 - 44ms/epoch - 22ms/step\n",
      "Epoch 79/400\n",
      "2/2 - 0s - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.4723 - val_accuracy: 0.3571 - lr: 1.0078e-06 - 42ms/epoch - 21ms/step\n",
      "Epoch 80/400\n",
      "2/2 - 0s - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.4678 - val_accuracy: 0.3571 - lr: 9.1188e-07 - 45ms/epoch - 23ms/step\n",
      "Epoch 81/400\n",
      "2/2 - 0s - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.4634 - val_accuracy: 0.3571 - lr: 8.2510e-07 - 43ms/epoch - 21ms/step\n",
      "Epoch 82/400\n",
      "2/2 - 0s - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.4591 - val_accuracy: 0.3571 - lr: 7.4658e-07 - 63ms/epoch - 31ms/step\n",
      "Epoch 83/400\n",
      "2/2 - 0s - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.4548 - val_accuracy: 0.3571 - lr: 6.7554e-07 - 44ms/epoch - 22ms/step\n",
      "Epoch 84/400\n",
      "2/2 - 0s - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.4511 - val_accuracy: 0.3571 - lr: 6.1125e-07 - 43ms/epoch - 21ms/step\n",
      "Epoch 85/400\n",
      "2/2 - 0s - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.4470 - val_accuracy: 0.3571 - lr: 5.5308e-07 - 44ms/epoch - 22ms/step\n",
      "Epoch 86/400\n",
      "2/2 - 0s - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.4432 - val_accuracy: 0.3571 - lr: 5.0045e-07 - 43ms/epoch - 21ms/step\n",
      "Epoch 87/400\n",
      "2/2 - 0s - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.4391 - val_accuracy: 0.3571 - lr: 4.5283e-07 - 43ms/epoch - 21ms/step\n",
      "Epoch 88/400\n",
      "2/2 - 0s - loss: 0.0129 - accuracy: 1.0000 - val_loss: 1.4347 - val_accuracy: 0.3571 - lr: 4.0973e-07 - 46ms/epoch - 23ms/step\n",
      "Epoch 89/400\n",
      "2/2 - 0s - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.4309 - val_accuracy: 0.3571 - lr: 3.7074e-07 - 51ms/epoch - 25ms/step\n",
      "Epoch 90/400\n",
      "2/2 - 0s - loss: 0.0143 - accuracy: 1.0000 - val_loss: 1.4265 - val_accuracy: 0.3571 - lr: 3.3546e-07 - 45ms/epoch - 23ms/step\n",
      "Epoch 91/400\n",
      "2/2 - 0s - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.4226 - val_accuracy: 0.3571 - lr: 3.0354e-07 - 47ms/epoch - 23ms/step\n",
      "Epoch 92/400\n",
      "2/2 - 0s - loss: 0.0131 - accuracy: 1.0000 - val_loss: 1.4201 - val_accuracy: 0.3571 - lr: 2.7465e-07 - 46ms/epoch - 23ms/step\n",
      "Epoch 93/400\n",
      "2/2 - 0s - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.4163 - val_accuracy: 0.3571 - lr: 2.4852e-07 - 45ms/epoch - 23ms/step\n",
      "Epoch 94/400\n",
      "2/2 - 0s - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.4132 - val_accuracy: 0.3571 - lr: 2.2487e-07 - 46ms/epoch - 23ms/step\n",
      "Epoch 95/400\n",
      "2/2 - 0s - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.4104 - val_accuracy: 0.3571 - lr: 2.0347e-07 - 43ms/epoch - 22ms/step\n",
      "Epoch 96/400\n",
      "2/2 - 0s - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.4074 - val_accuracy: 0.3571 - lr: 1.8410e-07 - 43ms/epoch - 22ms/step\n",
      "Epoch 97/400\n",
      "2/2 - 0s - loss: 0.0138 - accuracy: 1.0000 - val_loss: 1.4048 - val_accuracy: 0.3571 - lr: 1.6659e-07 - 56ms/epoch - 28ms/step\n",
      "Epoch 98/400\n",
      "2/2 - 0s - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.4019 - val_accuracy: 0.3571 - lr: 1.5073e-07 - 64ms/epoch - 32ms/step\n",
      "Epoch 99/400\n",
      "2/2 - 0s - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.3991 - val_accuracy: 0.3571 - lr: 1.3639e-07 - 64ms/epoch - 32ms/step\n",
      "Epoch 100/400\n",
      "2/2 - 0s - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.3966 - val_accuracy: 0.3571 - lr: 1.2341e-07 - 48ms/epoch - 24ms/step\n",
      "Epoch 101/400\n",
      "2/2 - 0s - loss: 0.0145 - accuracy: 1.0000 - val_loss: 1.3942 - val_accuracy: 0.3571 - lr: 1.1167e-07 - 43ms/epoch - 22ms/step\n",
      "Epoch 102/400\n",
      "2/2 - 0s - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.3923 - val_accuracy: 0.3571 - lr: 1.0104e-07 - 44ms/epoch - 22ms/step\n",
      "Epoch 103/400\n",
      "2/2 - 0s - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.3899 - val_accuracy: 0.3571 - lr: 9.1424e-08 - 44ms/epoch - 22ms/step\n",
      "Epoch 104/400\n",
      "2/2 - 0s - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.3876 - val_accuracy: 0.3571 - lr: 8.2724e-08 - 53ms/epoch - 27ms/step\n",
      "Epoch 105/400\n",
      "2/2 - 0s - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.3851 - val_accuracy: 0.3571 - lr: 7.4851e-08 - 48ms/epoch - 24ms/step\n",
      "Epoch 106/400\n",
      "2/2 - 0s - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.3829 - val_accuracy: 0.3571 - lr: 6.7728e-08 - 48ms/epoch - 24ms/step\n",
      "Epoch 107/400\n",
      "2/2 - 0s - loss: 0.0142 - accuracy: 1.0000 - val_loss: 1.3808 - val_accuracy: 0.3571 - lr: 6.1283e-08 - 47ms/epoch - 24ms/step\n",
      "Epoch 108/400\n",
      "2/2 - 0s - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.3789 - val_accuracy: 0.3571 - lr: 5.5451e-08 - 46ms/epoch - 23ms/step\n",
      "Epoch 109/400\n",
      "2/2 - 0s - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.3772 - val_accuracy: 0.3571 - lr: 5.0174e-08 - 48ms/epoch - 24ms/step\n",
      "Epoch 110/400\n",
      "2/2 - 0s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 1.3749 - val_accuracy: 0.3571 - lr: 4.5400e-08 - 47ms/epoch - 23ms/step\n",
      "Epoch 111/400\n",
      "2/2 - 0s - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.3738 - val_accuracy: 0.3571 - lr: 4.1079e-08 - 45ms/epoch - 22ms/step\n",
      "Epoch 112/400\n",
      "2/2 - 0s - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.3726 - val_accuracy: 0.3571 - lr: 3.7170e-08 - 44ms/epoch - 22ms/step\n",
      "Epoch 113/400\n",
      "2/2 - 0s - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.3707 - val_accuracy: 0.3571 - lr: 3.3633e-08 - 53ms/epoch - 27ms/step\n",
      "Epoch 114/400\n",
      "2/2 - 0s - loss: 0.0216 - accuracy: 1.0000 - val_loss: 1.3685 - val_accuracy: 0.3571 - lr: 3.0432e-08 - 45ms/epoch - 22ms/step\n",
      "Epoch 115/400\n",
      "2/2 - 0s - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.3679 - val_accuracy: 0.3571 - lr: 2.7536e-08 - 43ms/epoch - 22ms/step\n",
      "Epoch 116/400\n",
      "2/2 - 0s - loss: 0.0135 - accuracy: 1.0000 - val_loss: 1.3670 - val_accuracy: 0.3571 - lr: 2.4916e-08 - 49ms/epoch - 24ms/step\n",
      "Epoch 117/400\n",
      "2/2 - 0s - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.3664 - val_accuracy: 0.3571 - lr: 2.2545e-08 - 47ms/epoch - 23ms/step\n",
      "Epoch 118/400\n",
      "2/2 - 0s - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.3655 - val_accuracy: 0.3571 - lr: 2.0399e-08 - 45ms/epoch - 22ms/step\n",
      "Epoch 119/400\n",
      "2/2 - 0s - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.3635 - val_accuracy: 0.3571 - lr: 1.8458e-08 - 47ms/epoch - 23ms/step\n",
      "Epoch 120/400\n",
      "2/2 - 0s - loss: 0.0133 - accuracy: 1.0000 - val_loss: 1.3616 - val_accuracy: 0.3571 - lr: 1.6702e-08 - 51ms/epoch - 26ms/step\n",
      "Epoch 121/400\n",
      "2/2 - 0s - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.3608 - val_accuracy: 0.3571 - lr: 1.5112e-08 - 46ms/epoch - 23ms/step\n",
      "Epoch 122/400\n",
      "2/2 - 0s - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.3593 - val_accuracy: 0.3571 - lr: 1.3674e-08 - 54ms/epoch - 27ms/step\n",
      "Epoch 123/400\n",
      "2/2 - 0s - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.3583 - val_accuracy: 0.3571 - lr: 1.2373e-08 - 45ms/epoch - 22ms/step\n",
      "Epoch 124/400\n",
      "2/2 - 0s - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.3567 - val_accuracy: 0.3571 - lr: 1.1195e-08 - 45ms/epoch - 23ms/step\n",
      "Epoch 125/400\n",
      "2/2 - 0s - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.3555 - val_accuracy: 0.3571 - lr: 1.0130e-08 - 49ms/epoch - 25ms/step\n",
      "Epoch 126/400\n",
      "2/2 - 0s - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.3556 - val_accuracy: 0.3571 - lr: 9.1660e-09 - 42ms/epoch - 21ms/step\n",
      "Epoch 127/400\n",
      "2/2 - 0s - loss: 0.0133 - accuracy: 1.0000 - val_loss: 1.3543 - val_accuracy: 0.3571 - lr: 8.2938e-09 - 44ms/epoch - 22ms/step\n",
      "Epoch 128/400\n",
      "2/2 - 0s - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.3536 - val_accuracy: 0.3571 - lr: 7.5045e-09 - 50ms/epoch - 25ms/step\n",
      "Epoch 129/400\n",
      "2/2 - 0s - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.3528 - val_accuracy: 0.3571 - lr: 6.7904e-09 - 46ms/epoch - 23ms/step\n",
      "Epoch 130/400\n",
      "2/2 - 0s - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.3526 - val_accuracy: 0.3571 - lr: 6.1442e-09 - 47ms/epoch - 23ms/step\n",
      "Epoch 131/400\n",
      "2/2 - 0s - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.3529 - val_accuracy: 0.3571 - lr: 5.5595e-09 - 41ms/epoch - 20ms/step\n",
      "Epoch 132/400\n",
      "2/2 - 0s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 1.3510 - val_accuracy: 0.3571 - lr: 5.0304e-09 - 50ms/epoch - 25ms/step\n",
      "Epoch 133/400\n",
      "2/2 - 0s - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.3504 - val_accuracy: 0.3571 - lr: 4.5517e-09 - 50ms/epoch - 25ms/step\n",
      "Epoch 134/400\n",
      "2/2 - 0s - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.3504 - val_accuracy: 0.3571 - lr: 4.1186e-09 - 46ms/epoch - 23ms/step\n",
      "Epoch 135/400\n",
      "2/2 - 0s - loss: 0.0133 - accuracy: 1.0000 - val_loss: 1.3503 - val_accuracy: 0.3571 - lr: 3.7266e-09 - 46ms/epoch - 23ms/step\n",
      "Epoch 136/400\n",
      "2/2 - 0s - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.3492 - val_accuracy: 0.3571 - lr: 3.3720e-09 - 45ms/epoch - 23ms/step\n",
      "Epoch 137/400\n",
      "2/2 - 0s - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.3489 - val_accuracy: 0.3571 - lr: 3.0511e-09 - 48ms/epoch - 24ms/step\n",
      "Epoch 138/400\n",
      "2/2 - 0s - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.3484 - val_accuracy: 0.3571 - lr: 2.7608e-09 - 50ms/epoch - 25ms/step\n",
      "Epoch 139/400\n",
      "2/2 - 0s - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.3478 - val_accuracy: 0.3571 - lr: 2.4980e-09 - 46ms/epoch - 23ms/step\n",
      "Epoch 140/400\n",
      "2/2 - 0s - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.3474 - val_accuracy: 0.3571 - lr: 2.2603e-09 - 46ms/epoch - 23ms/step\n",
      "Epoch 141/400\n",
      "2/2 - 0s - loss: 0.0177 - accuracy: 1.0000 - val_loss: 1.3473 - val_accuracy: 0.3571 - lr: 2.0452e-09 - 46ms/epoch - 23ms/step\n",
      "Epoch 142/400\n",
      "2/2 - 0s - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.3469 - val_accuracy: 0.3571 - lr: 1.8506e-09 - 46ms/epoch - 23ms/step\n",
      "Epoch 143/400\n",
      "2/2 - 0s - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.3467 - val_accuracy: 0.3571 - lr: 1.6745e-09 - 53ms/epoch - 27ms/step\n",
      "Epoch 144/400\n",
      "2/2 - 0s - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.3469 - val_accuracy: 0.3571 - lr: 1.5151e-09 - 45ms/epoch - 23ms/step\n",
      "Epoch 145/400\n",
      "2/2 - 0s - loss: 0.0131 - accuracy: 1.0000 - val_loss: 1.3480 - val_accuracy: 0.3571 - lr: 1.3709e-09 - 39ms/epoch - 20ms/step\n",
      "Epoch 146/400\n",
      "2/2 - 0s - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.3481 - val_accuracy: 0.3571 - lr: 1.2405e-09 - 45ms/epoch - 23ms/step\n",
      "Epoch 147/400\n",
      "2/2 - 0s - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.3489 - val_accuracy: 0.3571 - lr: 1.1224e-09 - 43ms/epoch - 22ms/step\n",
      "Epoch 148/400\n",
      "2/2 - 0s - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.3497 - val_accuracy: 0.3571 - lr: 1.0156e-09 - 43ms/epoch - 22ms/step\n",
      "Epoch 149/400\n",
      "2/2 - 0s - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.3504 - val_accuracy: 0.3571 - lr: 9.1897e-10 - 42ms/epoch - 21ms/step\n",
      "Epoch 150/400\n",
      "2/2 - 0s - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.3512 - val_accuracy: 0.3571 - lr: 8.3152e-10 - 41ms/epoch - 21ms/step\n",
      "Epoch 151/400\n",
      "2/2 - 0s - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.3507 - val_accuracy: 0.3571 - lr: 7.5239e-10 - 42ms/epoch - 21ms/step\n",
      "Epoch 152/400\n",
      "2/2 - 0s - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.3506 - val_accuracy: 0.3571 - lr: 6.8079e-10 - 43ms/epoch - 22ms/step\n",
      "Epoch 153/400\n",
      "2/2 - 0s - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.3509 - val_accuracy: 0.3571 - lr: 6.1601e-10 - 43ms/epoch - 22ms/step\n",
      "Epoch 154/400\n",
      "2/2 - 0s - loss: 0.0140 - accuracy: 1.0000 - val_loss: 1.3506 - val_accuracy: 0.3571 - lr: 5.5739e-10 - 44ms/epoch - 22ms/step\n",
      "Epoch 155/400\n",
      "2/2 - 0s - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.3504 - val_accuracy: 0.3571 - lr: 5.0434e-10 - 40ms/epoch - 20ms/step\n",
      "Epoch 156/400\n",
      "2/2 - 0s - loss: 0.0131 - accuracy: 1.0000 - val_loss: 1.3502 - val_accuracy: 0.3571 - lr: 4.5635e-10 - 43ms/epoch - 21ms/step\n",
      "Epoch 157/400\n",
      "2/2 - 0s - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.3502 - val_accuracy: 0.3571 - lr: 4.1292e-10 - 47ms/epoch - 23ms/step\n",
      "Epoch 158/400\n",
      "2/2 - 0s - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.3493 - val_accuracy: 0.3571 - lr: 3.7363e-10 - 42ms/epoch - 21ms/step\n",
      "Epoch 159/400\n",
      "2/2 - 0s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 1.3488 - val_accuracy: 0.3571 - lr: 3.3807e-10 - 39ms/epoch - 20ms/step\n",
      "Epoch 160/400\n",
      "2/2 - 0s - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.3494 - val_accuracy: 0.3571 - lr: 3.0590e-10 - 41ms/epoch - 21ms/step\n",
      "Epoch 161/400\n",
      "2/2 - 0s - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.3497 - val_accuracy: 0.3571 - lr: 2.7679e-10 - 51ms/epoch - 25ms/step\n",
      "Epoch 162/400\n",
      "2/2 - 0s - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.3507 - val_accuracy: 0.3571 - lr: 2.5045e-10 - 46ms/epoch - 23ms/step\n",
      "Epoch 163/400\n",
      "2/2 - 0s - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.3510 - val_accuracy: 0.3571 - lr: 2.2662e-10 - 61ms/epoch - 30ms/step\n",
      "Evaluando modelo: ResNet\n",
      "Epoch 1/400\n",
      "2/2 - 3s - loss: 15.0632 - accuracy: 0.2264 - val_loss: 18.5596 - val_accuracy: 0.0714 - lr: 0.0010 - 3s/epoch - 2s/step\n",
      "Epoch 2/400\n",
      "2/2 - 0s - loss: 13.4358 - accuracy: 0.6415 - val_loss: 16.5288 - val_accuracy: 0.1429 - lr: 0.0010 - 66ms/epoch - 33ms/step\n",
      "Epoch 3/400\n",
      "2/2 - 0s - loss: 12.4638 - accuracy: 0.8491 - val_loss: 15.3888 - val_accuracy: 0.2143 - lr: 0.0010 - 61ms/epoch - 30ms/step\n",
      "Epoch 4/400\n",
      "2/2 - 0s - loss: 11.8404 - accuracy: 0.9811 - val_loss: 14.4723 - val_accuracy: 0.2143 - lr: 0.0010 - 61ms/epoch - 30ms/step\n",
      "Epoch 5/400\n",
      "2/2 - 0s - loss: 11.3083 - accuracy: 0.9811 - val_loss: 13.7737 - val_accuracy: 0.3571 - lr: 0.0010 - 75ms/epoch - 38ms/step\n",
      "Epoch 6/400\n",
      "2/2 - 0s - loss: 10.9456 - accuracy: 1.0000 - val_loss: 13.2071 - val_accuracy: 0.2857 - lr: 0.0010 - 60ms/epoch - 30ms/step\n",
      "Epoch 7/400\n",
      "2/2 - 0s - loss: 10.5180 - accuracy: 1.0000 - val_loss: 12.7501 - val_accuracy: 0.2857 - lr: 0.0010 - 59ms/epoch - 29ms/step\n",
      "Epoch 8/400\n",
      "2/2 - 0s - loss: 10.1930 - accuracy: 1.0000 - val_loss: 12.3459 - val_accuracy: 0.2857 - lr: 0.0010 - 63ms/epoch - 31ms/step\n",
      "Epoch 9/400\n",
      "2/2 - 0s - loss: 9.8810 - accuracy: 1.0000 - val_loss: 11.9876 - val_accuracy: 0.2857 - lr: 0.0010 - 65ms/epoch - 32ms/step\n",
      "Epoch 10/400\n",
      "2/2 - 0s - loss: 9.5623 - accuracy: 1.0000 - val_loss: 11.6545 - val_accuracy: 0.2857 - lr: 0.0010 - 63ms/epoch - 32ms/step\n",
      "Epoch 11/400\n",
      "2/2 - 0s - loss: 9.2588 - accuracy: 1.0000 - val_loss: 11.3574 - val_accuracy: 0.2857 - lr: 9.0484e-04 - 59ms/epoch - 30ms/step\n",
      "Epoch 12/400\n",
      "2/2 - 0s - loss: 9.0203 - accuracy: 1.0000 - val_loss: 11.1044 - val_accuracy: 0.2143 - lr: 8.1873e-04 - 59ms/epoch - 30ms/step\n",
      "Epoch 13/400\n",
      "2/2 - 0s - loss: 8.8598 - accuracy: 0.9811 - val_loss: 10.8812 - val_accuracy: 0.2143 - lr: 7.4082e-04 - 59ms/epoch - 30ms/step\n",
      "Epoch 14/400\n",
      "2/2 - 0s - loss: 8.6241 - accuracy: 1.0000 - val_loss: 10.6746 - val_accuracy: 0.2143 - lr: 6.7032e-04 - 63ms/epoch - 31ms/step\n",
      "Epoch 15/400\n",
      "2/2 - 0s - loss: 8.4665 - accuracy: 1.0000 - val_loss: 10.4975 - val_accuracy: 0.2143 - lr: 6.0653e-04 - 63ms/epoch - 32ms/step\n",
      "Epoch 16/400\n",
      "2/2 - 0s - loss: 8.3287 - accuracy: 1.0000 - val_loss: 10.3414 - val_accuracy: 0.2143 - lr: 5.4881e-04 - 61ms/epoch - 31ms/step\n",
      "Epoch 17/400\n",
      "2/2 - 0s - loss: 8.2072 - accuracy: 1.0000 - val_loss: 10.2036 - val_accuracy: 0.2143 - lr: 4.9659e-04 - 60ms/epoch - 30ms/step\n",
      "Epoch 18/400\n",
      "2/2 - 0s - loss: 8.0944 - accuracy: 1.0000 - val_loss: 10.0821 - val_accuracy: 0.2143 - lr: 4.4933e-04 - 58ms/epoch - 29ms/step\n",
      "Epoch 19/400\n",
      "2/2 - 0s - loss: 7.9994 - accuracy: 1.0000 - val_loss: 9.9737 - val_accuracy: 0.2143 - lr: 4.0657e-04 - 67ms/epoch - 33ms/step\n",
      "Epoch 20/400\n",
      "2/2 - 0s - loss: 7.9144 - accuracy: 1.0000 - val_loss: 9.8785 - val_accuracy: 0.2143 - lr: 3.6788e-04 - 59ms/epoch - 29ms/step\n",
      "Epoch 21/400\n",
      "2/2 - 0s - loss: 7.8410 - accuracy: 1.0000 - val_loss: 9.7943 - val_accuracy: 0.2143 - lr: 3.3287e-04 - 60ms/epoch - 30ms/step\n",
      "Epoch 22/400\n",
      "2/2 - 0s - loss: 7.7710 - accuracy: 1.0000 - val_loss: 9.7165 - val_accuracy: 0.2143 - lr: 3.0119e-04 - 62ms/epoch - 31ms/step\n",
      "Epoch 23/400\n",
      "2/2 - 0s - loss: 7.7086 - accuracy: 1.0000 - val_loss: 9.6490 - val_accuracy: 0.2143 - lr: 2.7253e-04 - 63ms/epoch - 32ms/step\n",
      "Epoch 24/400\n",
      "2/2 - 0s - loss: 7.6564 - accuracy: 1.0000 - val_loss: 9.5876 - val_accuracy: 0.2143 - lr: 2.4660e-04 - 63ms/epoch - 32ms/step\n",
      "Epoch 25/400\n",
      "2/2 - 0s - loss: 7.6179 - accuracy: 1.0000 - val_loss: 9.5337 - val_accuracy: 0.2143 - lr: 2.2313e-04 - 66ms/epoch - 33ms/step\n",
      "Epoch 26/400\n",
      "2/2 - 0s - loss: 7.5662 - accuracy: 1.0000 - val_loss: 9.4852 - val_accuracy: 0.2143 - lr: 2.0190e-04 - 64ms/epoch - 32ms/step\n",
      "Epoch 27/400\n",
      "2/2 - 0s - loss: 7.5315 - accuracy: 1.0000 - val_loss: 9.4393 - val_accuracy: 0.2857 - lr: 1.8268e-04 - 63ms/epoch - 32ms/step\n",
      "Epoch 28/400\n",
      "2/2 - 0s - loss: 7.4950 - accuracy: 1.0000 - val_loss: 9.3994 - val_accuracy: 0.2857 - lr: 1.6530e-04 - 66ms/epoch - 33ms/step\n",
      "Epoch 29/400\n",
      "2/2 - 0s - loss: 7.4709 - accuracy: 1.0000 - val_loss: 9.3641 - val_accuracy: 0.2857 - lr: 1.4957e-04 - 67ms/epoch - 33ms/step\n",
      "Epoch 30/400\n",
      "2/2 - 0s - loss: 7.4383 - accuracy: 1.0000 - val_loss: 9.3322 - val_accuracy: 0.2857 - lr: 1.3534e-04 - 60ms/epoch - 30ms/step\n",
      "Epoch 31/400\n",
      "2/2 - 0s - loss: 7.4171 - accuracy: 1.0000 - val_loss: 9.3054 - val_accuracy: 0.2857 - lr: 1.2246e-04 - 66ms/epoch - 33ms/step\n",
      "Epoch 32/400\n",
      "2/2 - 0s - loss: 7.3883 - accuracy: 1.0000 - val_loss: 9.2789 - val_accuracy: 0.2857 - lr: 1.1080e-04 - 62ms/epoch - 31ms/step\n",
      "Epoch 33/400\n",
      "2/2 - 0s - loss: 7.3800 - accuracy: 1.0000 - val_loss: 9.2565 - val_accuracy: 0.2857 - lr: 1.0026e-04 - 60ms/epoch - 30ms/step\n",
      "Epoch 34/400\n",
      "2/2 - 0s - loss: 7.3507 - accuracy: 1.0000 - val_loss: 9.2356 - val_accuracy: 0.2857 - lr: 9.0718e-05 - 62ms/epoch - 31ms/step\n",
      "Epoch 35/400\n",
      "2/2 - 0s - loss: 7.3297 - accuracy: 1.0000 - val_loss: 9.2174 - val_accuracy: 0.2857 - lr: 8.2085e-05 - 62ms/epoch - 31ms/step\n",
      "Epoch 36/400\n",
      "2/2 - 0s - loss: 7.3121 - accuracy: 1.0000 - val_loss: 9.2002 - val_accuracy: 0.2857 - lr: 7.4273e-05 - 62ms/epoch - 31ms/step\n",
      "Epoch 37/400\n",
      "2/2 - 0s - loss: 7.3032 - accuracy: 1.0000 - val_loss: 9.1867 - val_accuracy: 0.2857 - lr: 6.7205e-05 - 64ms/epoch - 32ms/step\n",
      "Epoch 38/400\n",
      "2/2 - 0s - loss: 7.2894 - accuracy: 1.0000 - val_loss: 9.1752 - val_accuracy: 0.2857 - lr: 6.0810e-05 - 64ms/epoch - 32ms/step\n",
      "Epoch 39/400\n",
      "2/2 - 0s - loss: 7.2734 - accuracy: 1.0000 - val_loss: 9.1646 - val_accuracy: 0.2857 - lr: 5.5023e-05 - 61ms/epoch - 31ms/step\n",
      "Epoch 40/400\n",
      "2/2 - 0s - loss: 7.2650 - accuracy: 1.0000 - val_loss: 9.1530 - val_accuracy: 0.2857 - lr: 4.9787e-05 - 64ms/epoch - 32ms/step\n",
      "Epoch 41/400\n",
      "2/2 - 0s - loss: 7.2540 - accuracy: 1.0000 - val_loss: 9.1419 - val_accuracy: 0.2857 - lr: 4.5049e-05 - 70ms/epoch - 35ms/step\n",
      "Epoch 42/400\n",
      "2/2 - 0s - loss: 7.2465 - accuracy: 1.0000 - val_loss: 9.1320 - val_accuracy: 0.2857 - lr: 4.0762e-05 - 62ms/epoch - 31ms/step\n",
      "Epoch 43/400\n",
      "2/2 - 0s - loss: 7.2421 - accuracy: 1.0000 - val_loss: 9.1229 - val_accuracy: 0.2857 - lr: 3.6883e-05 - 70ms/epoch - 35ms/step\n",
      "Epoch 44/400\n",
      "2/2 - 0s - loss: 7.2311 - accuracy: 1.0000 - val_loss: 9.1137 - val_accuracy: 0.2857 - lr: 3.3373e-05 - 60ms/epoch - 30ms/step\n",
      "Epoch 45/400\n",
      "2/2 - 0s - loss: 7.2271 - accuracy: 1.0000 - val_loss: 9.1042 - val_accuracy: 0.2857 - lr: 3.0197e-05 - 60ms/epoch - 30ms/step\n",
      "Epoch 46/400\n",
      "2/2 - 0s - loss: 7.2231 - accuracy: 1.0000 - val_loss: 9.0959 - val_accuracy: 0.2857 - lr: 2.7324e-05 - 64ms/epoch - 32ms/step\n",
      "Epoch 47/400\n",
      "2/2 - 0s - loss: 7.2170 - accuracy: 1.0000 - val_loss: 9.0871 - val_accuracy: 0.2857 - lr: 2.4723e-05 - 64ms/epoch - 32ms/step\n",
      "Epoch 48/400\n",
      "2/2 - 0s - loss: 7.2090 - accuracy: 1.0000 - val_loss: 9.0771 - val_accuracy: 0.2857 - lr: 2.2371e-05 - 66ms/epoch - 33ms/step\n",
      "Epoch 49/400\n",
      "2/2 - 0s - loss: 7.2088 - accuracy: 1.0000 - val_loss: 9.0677 - val_accuracy: 0.2857 - lr: 2.0242e-05 - 61ms/epoch - 30ms/step\n",
      "Epoch 50/400\n",
      "2/2 - 0s - loss: 7.2106 - accuracy: 1.0000 - val_loss: 9.0598 - val_accuracy: 0.2857 - lr: 1.8316e-05 - 67ms/epoch - 34ms/step\n",
      "Epoch 51/400\n",
      "2/2 - 0s - loss: 7.1961 - accuracy: 1.0000 - val_loss: 9.0525 - val_accuracy: 0.2857 - lr: 1.6573e-05 - 70ms/epoch - 35ms/step\n",
      "Epoch 52/400\n",
      "2/2 - 0s - loss: 7.1938 - accuracy: 1.0000 - val_loss: 9.0456 - val_accuracy: 0.2143 - lr: 1.4996e-05 - 66ms/epoch - 33ms/step\n",
      "Epoch 53/400\n",
      "2/2 - 0s - loss: 7.1922 - accuracy: 1.0000 - val_loss: 9.0389 - val_accuracy: 0.2143 - lr: 1.3569e-05 - 63ms/epoch - 31ms/step\n",
      "Epoch 54/400\n",
      "2/2 - 0s - loss: 7.1912 - accuracy: 1.0000 - val_loss: 9.0331 - val_accuracy: 0.2143 - lr: 1.2277e-05 - 65ms/epoch - 33ms/step\n",
      "Epoch 55/400\n",
      "2/2 - 0s - loss: 7.1870 - accuracy: 1.0000 - val_loss: 9.0285 - val_accuracy: 0.2143 - lr: 1.1109e-05 - 63ms/epoch - 31ms/step\n",
      "Epoch 56/400\n",
      "2/2 - 0s - loss: 7.1838 - accuracy: 1.0000 - val_loss: 9.0232 - val_accuracy: 0.2143 - lr: 1.0052e-05 - 62ms/epoch - 31ms/step\n",
      "Epoch 57/400\n",
      "2/2 - 0s - loss: 7.1809 - accuracy: 1.0000 - val_loss: 9.0192 - val_accuracy: 0.2143 - lr: 9.0953e-06 - 68ms/epoch - 34ms/step\n",
      "Epoch 58/400\n",
      "2/2 - 0s - loss: 7.1809 - accuracy: 1.0000 - val_loss: 9.0161 - val_accuracy: 0.2143 - lr: 8.2297e-06 - 63ms/epoch - 32ms/step\n",
      "Epoch 59/400\n",
      "2/2 - 0s - loss: 7.1805 - accuracy: 1.0000 - val_loss: 9.0146 - val_accuracy: 0.2857 - lr: 7.4466e-06 - 65ms/epoch - 32ms/step\n",
      "Epoch 60/400\n",
      "2/2 - 0s - loss: 7.1791 - accuracy: 1.0000 - val_loss: 9.0144 - val_accuracy: 0.2857 - lr: 6.7379e-06 - 66ms/epoch - 33ms/step\n",
      "Epoch 61/400\n",
      "2/2 - 0s - loss: 7.1836 - accuracy: 1.0000 - val_loss: 9.0140 - val_accuracy: 0.2857 - lr: 6.0967e-06 - 70ms/epoch - 35ms/step\n",
      "Epoch 62/400\n",
      "2/2 - 0s - loss: 7.1761 - accuracy: 1.0000 - val_loss: 9.0136 - val_accuracy: 0.1429 - lr: 5.5165e-06 - 66ms/epoch - 33ms/step\n",
      "Epoch 63/400\n",
      "2/2 - 0s - loss: 7.1743 - accuracy: 1.0000 - val_loss: 9.0129 - val_accuracy: 0.1429 - lr: 4.9916e-06 - 71ms/epoch - 35ms/step\n",
      "Epoch 64/400\n",
      "2/2 - 0s - loss: 7.1735 - accuracy: 1.0000 - val_loss: 9.0131 - val_accuracy: 0.1429 - lr: 4.5166e-06 - 58ms/epoch - 29ms/step\n",
      "Epoch 65/400\n",
      "2/2 - 0s - loss: 7.1756 - accuracy: 1.0000 - val_loss: 9.0137 - val_accuracy: 0.1429 - lr: 4.0868e-06 - 60ms/epoch - 30ms/step\n",
      "Epoch 66/400\n",
      "2/2 - 0s - loss: 7.1738 - accuracy: 1.0000 - val_loss: 9.0154 - val_accuracy: 0.1429 - lr: 3.6979e-06 - 53ms/epoch - 26ms/step\n",
      "Epoch 67/400\n",
      "2/2 - 0s - loss: 7.1709 - accuracy: 1.0000 - val_loss: 9.0163 - val_accuracy: 0.1429 - lr: 3.3460e-06 - 53ms/epoch - 26ms/step\n",
      "Epoch 68/400\n",
      "2/2 - 0s - loss: 7.1697 - accuracy: 1.0000 - val_loss: 9.0176 - val_accuracy: 0.1429 - lr: 3.0275e-06 - 58ms/epoch - 29ms/step\n",
      "Epoch 69/400\n",
      "2/2 - 0s - loss: 7.1694 - accuracy: 1.0000 - val_loss: 9.0201 - val_accuracy: 0.1429 - lr: 2.7394e-06 - 57ms/epoch - 29ms/step\n",
      "Epoch 70/400\n",
      "2/2 - 0s - loss: 7.1690 - accuracy: 1.0000 - val_loss: 9.0238 - val_accuracy: 0.1429 - lr: 2.4787e-06 - 56ms/epoch - 28ms/step\n",
      "Epoch 71/400\n",
      "2/2 - 0s - loss: 7.1681 - accuracy: 1.0000 - val_loss: 9.0283 - val_accuracy: 0.1429 - lr: 2.2429e-06 - 60ms/epoch - 30ms/step\n",
      "Epoch 72/400\n",
      "2/2 - 0s - loss: 7.1742 - accuracy: 1.0000 - val_loss: 9.0324 - val_accuracy: 0.1429 - lr: 2.0294e-06 - 58ms/epoch - 29ms/step\n",
      "Epoch 73/400\n",
      "2/2 - 0s - loss: 7.1810 - accuracy: 1.0000 - val_loss: 9.0356 - val_accuracy: 0.1429 - lr: 1.0000e-06 - 59ms/epoch - 29ms/step\n",
      "Epoch 74/400\n",
      "2/2 - 0s - loss: 7.1681 - accuracy: 1.0000 - val_loss: 9.0387 - val_accuracy: 0.1429 - lr: 9.0484e-07 - 56ms/epoch - 28ms/step\n",
      "Epoch 75/400\n",
      "2/2 - 0s - loss: 7.1653 - accuracy: 1.0000 - val_loss: 9.0413 - val_accuracy: 0.1429 - lr: 8.1873e-07 - 58ms/epoch - 29ms/step\n",
      "Epoch 76/400\n",
      "2/2 - 0s - loss: 7.1683 - accuracy: 1.0000 - val_loss: 9.0420 - val_accuracy: 0.2143 - lr: 7.4082e-07 - 55ms/epoch - 28ms/step\n",
      "Epoch 77/400\n",
      "2/2 - 0s - loss: 7.1707 - accuracy: 1.0000 - val_loss: 9.0427 - val_accuracy: 0.2143 - lr: 6.7032e-07 - 58ms/epoch - 29ms/step\n",
      "Epoch 78/400\n",
      "2/2 - 0s - loss: 7.1674 - accuracy: 1.0000 - val_loss: 9.0427 - val_accuracy: 0.2143 - lr: 6.0653e-07 - 52ms/epoch - 26ms/step\n",
      "Epoch 79/400\n",
      "2/2 - 0s - loss: 7.1678 - accuracy: 1.0000 - val_loss: 9.0431 - val_accuracy: 0.2143 - lr: 5.4881e-07 - 57ms/epoch - 29ms/step\n",
      "Epoch 80/400\n",
      "2/2 - 0s - loss: 7.1725 - accuracy: 1.0000 - val_loss: 9.0435 - val_accuracy: 0.2143 - lr: 4.9659e-07 - 53ms/epoch - 26ms/step\n",
      "Epoch 81/400\n",
      "2/2 - 0s - loss: 7.1644 - accuracy: 1.0000 - val_loss: 9.0431 - val_accuracy: 0.2143 - lr: 4.4933e-07 - 56ms/epoch - 28ms/step\n",
      "Epoch 82/400\n",
      "2/2 - 0s - loss: 7.1649 - accuracy: 1.0000 - val_loss: 9.0421 - val_accuracy: 0.2143 - lr: 4.0657e-07 - 53ms/epoch - 27ms/step\n",
      "Epoch 83/400\n",
      "2/2 - 0s - loss: 7.1685 - accuracy: 1.0000 - val_loss: 9.0407 - val_accuracy: 0.2143 - lr: 3.6788e-07 - 92ms/epoch - 46ms/step\n",
      "Evaluando modelo: InceptionFCN\n",
      "Epoch 1/400\n",
      "2/2 - 3s - loss: 2.5493 - accuracy: 0.2075 - val_loss: 12.1049 - val_accuracy: 0.1429 - lr: 0.0010 - 3s/epoch - 2s/step\n",
      "Epoch 2/400\n",
      "2/2 - 0s - loss: 1.6703 - accuracy: 0.4151 - val_loss: 8.2812 - val_accuracy: 0.1429 - lr: 0.0010 - 69ms/epoch - 34ms/step\n",
      "Epoch 3/400\n",
      "2/2 - 0s - loss: 1.0846 - accuracy: 0.6226 - val_loss: 6.2800 - val_accuracy: 0.1429 - lr: 0.0010 - 75ms/epoch - 37ms/step\n",
      "Epoch 4/400\n",
      "2/2 - 0s - loss: 0.6951 - accuracy: 0.7736 - val_loss: 5.0770 - val_accuracy: 0.1429 - lr: 0.0010 - 68ms/epoch - 34ms/step\n",
      "Epoch 5/400\n",
      "2/2 - 0s - loss: 0.5419 - accuracy: 0.8302 - val_loss: 4.2783 - val_accuracy: 0.1429 - lr: 0.0010 - 65ms/epoch - 32ms/step\n",
      "Epoch 6/400\n",
      "2/2 - 0s - loss: 0.4698 - accuracy: 0.8679 - val_loss: 3.6672 - val_accuracy: 0.2143 - lr: 0.0010 - 69ms/epoch - 35ms/step\n",
      "Epoch 7/400\n",
      "2/2 - 0s - loss: 0.2998 - accuracy: 0.9811 - val_loss: 3.1810 - val_accuracy: 0.2143 - lr: 0.0010 - 68ms/epoch - 34ms/step\n",
      "Epoch 8/400\n",
      "2/2 - 0s - loss: 0.1954 - accuracy: 0.9811 - val_loss: 2.8497 - val_accuracy: 0.2857 - lr: 0.0010 - 66ms/epoch - 33ms/step\n",
      "Epoch 9/400\n",
      "2/2 - 0s - loss: 0.1937 - accuracy: 0.9811 - val_loss: 2.6054 - val_accuracy: 0.2857 - lr: 0.0010 - 67ms/epoch - 34ms/step\n",
      "Epoch 10/400\n",
      "2/2 - 0s - loss: 0.1079 - accuracy: 0.9811 - val_loss: 2.4236 - val_accuracy: 0.4286 - lr: 0.0010 - 67ms/epoch - 34ms/step\n",
      "Epoch 11/400\n",
      "2/2 - 0s - loss: 0.1128 - accuracy: 1.0000 - val_loss: 2.3057 - val_accuracy: 0.3571 - lr: 9.0484e-04 - 66ms/epoch - 33ms/step\n",
      "Epoch 12/400\n",
      "2/2 - 0s - loss: 0.1149 - accuracy: 0.9811 - val_loss: 2.2073 - val_accuracy: 0.3571 - lr: 8.1873e-04 - 72ms/epoch - 36ms/step\n",
      "Epoch 13/400\n",
      "2/2 - 0s - loss: 0.0973 - accuracy: 0.9811 - val_loss: 2.1390 - val_accuracy: 0.3571 - lr: 7.4082e-04 - 66ms/epoch - 33ms/step\n",
      "Epoch 14/400\n",
      "2/2 - 0s - loss: 0.0977 - accuracy: 1.0000 - val_loss: 2.0940 - val_accuracy: 0.3571 - lr: 6.7032e-04 - 70ms/epoch - 35ms/step\n",
      "Epoch 15/400\n",
      "2/2 - 0s - loss: 0.0705 - accuracy: 1.0000 - val_loss: 2.0514 - val_accuracy: 0.3571 - lr: 6.0653e-04 - 69ms/epoch - 34ms/step\n",
      "Epoch 16/400\n",
      "2/2 - 0s - loss: 0.0492 - accuracy: 1.0000 - val_loss: 2.0205 - val_accuracy: 0.3571 - lr: 5.4881e-04 - 77ms/epoch - 39ms/step\n",
      "Epoch 17/400\n",
      "2/2 - 0s - loss: 0.0953 - accuracy: 0.9811 - val_loss: 1.9911 - val_accuracy: 0.3571 - lr: 4.9659e-04 - 74ms/epoch - 37ms/step\n",
      "Epoch 18/400\n",
      "2/2 - 0s - loss: 0.0368 - accuracy: 1.0000 - val_loss: 1.9695 - val_accuracy: 0.3571 - lr: 4.4933e-04 - 76ms/epoch - 38ms/step\n",
      "Epoch 19/400\n",
      "2/2 - 0s - loss: 0.0350 - accuracy: 1.0000 - val_loss: 1.9506 - val_accuracy: 0.3571 - lr: 4.0657e-04 - 71ms/epoch - 36ms/step\n",
      "Epoch 20/400\n",
      "2/2 - 0s - loss: 0.0534 - accuracy: 1.0000 - val_loss: 1.9321 - val_accuracy: 0.3571 - lr: 3.6788e-04 - 66ms/epoch - 33ms/step\n",
      "Epoch 21/400\n",
      "2/2 - 0s - loss: 0.0333 - accuracy: 1.0000 - val_loss: 1.9168 - val_accuracy: 0.3571 - lr: 3.3287e-04 - 68ms/epoch - 34ms/step\n",
      "Epoch 22/400\n",
      "2/2 - 0s - loss: 0.0317 - accuracy: 1.0000 - val_loss: 1.9037 - val_accuracy: 0.3571 - lr: 3.0119e-04 - 74ms/epoch - 37ms/step\n",
      "Epoch 23/400\n",
      "2/2 - 0s - loss: 0.0463 - accuracy: 1.0000 - val_loss: 1.8912 - val_accuracy: 0.3571 - lr: 2.7253e-04 - 71ms/epoch - 35ms/step\n",
      "Epoch 24/400\n",
      "2/2 - 0s - loss: 0.0436 - accuracy: 1.0000 - val_loss: 1.8809 - val_accuracy: 0.2857 - lr: 2.4660e-04 - 71ms/epoch - 36ms/step\n",
      "Epoch 25/400\n",
      "2/2 - 0s - loss: 0.0226 - accuracy: 1.0000 - val_loss: 1.8703 - val_accuracy: 0.2857 - lr: 2.2313e-04 - 73ms/epoch - 37ms/step\n",
      "Epoch 26/400\n",
      "2/2 - 0s - loss: 0.0295 - accuracy: 1.0000 - val_loss: 1.8595 - val_accuracy: 0.2857 - lr: 2.0190e-04 - 68ms/epoch - 34ms/step\n",
      "Epoch 27/400\n",
      "2/2 - 0s - loss: 0.0414 - accuracy: 1.0000 - val_loss: 1.8482 - val_accuracy: 0.2857 - lr: 1.8268e-04 - 70ms/epoch - 35ms/step\n",
      "Epoch 28/400\n",
      "2/2 - 0s - loss: 0.0655 - accuracy: 0.9811 - val_loss: 1.8368 - val_accuracy: 0.2857 - lr: 1.6530e-04 - 70ms/epoch - 35ms/step\n",
      "Epoch 29/400\n",
      "2/2 - 0s - loss: 0.0270 - accuracy: 1.0000 - val_loss: 1.8264 - val_accuracy: 0.2857 - lr: 1.4957e-04 - 75ms/epoch - 37ms/step\n",
      "Epoch 30/400\n",
      "2/2 - 0s - loss: 0.0262 - accuracy: 1.0000 - val_loss: 1.8174 - val_accuracy: 0.2857 - lr: 1.3534e-04 - 77ms/epoch - 38ms/step\n",
      "Epoch 31/400\n",
      "2/2 - 0s - loss: 0.0197 - accuracy: 1.0000 - val_loss: 1.8113 - val_accuracy: 0.2857 - lr: 1.2246e-04 - 71ms/epoch - 36ms/step\n",
      "Epoch 32/400\n",
      "2/2 - 0s - loss: 0.0376 - accuracy: 1.0000 - val_loss: 1.8048 - val_accuracy: 0.2857 - lr: 1.1080e-04 - 72ms/epoch - 36ms/step\n",
      "Epoch 33/400\n",
      "2/2 - 0s - loss: 0.0235 - accuracy: 1.0000 - val_loss: 1.7996 - val_accuracy: 0.2857 - lr: 1.0026e-04 - 71ms/epoch - 35ms/step\n",
      "Epoch 34/400\n",
      "2/2 - 0s - loss: 0.0159 - accuracy: 1.0000 - val_loss: 1.7958 - val_accuracy: 0.2857 - lr: 9.0718e-05 - 78ms/epoch - 39ms/step\n",
      "Epoch 35/400\n",
      "2/2 - 0s - loss: 0.0346 - accuracy: 1.0000 - val_loss: 1.7923 - val_accuracy: 0.3571 - lr: 8.2085e-05 - 72ms/epoch - 36ms/step\n",
      "Epoch 36/400\n",
      "2/2 - 0s - loss: 0.0325 - accuracy: 1.0000 - val_loss: 1.7896 - val_accuracy: 0.3571 - lr: 7.4273e-05 - 68ms/epoch - 34ms/step\n",
      "Epoch 37/400\n",
      "2/2 - 0s - loss: 0.0374 - accuracy: 1.0000 - val_loss: 1.7881 - val_accuracy: 0.3571 - lr: 6.7205e-05 - 66ms/epoch - 33ms/step\n",
      "Epoch 38/400\n",
      "2/2 - 0s - loss: 0.0463 - accuracy: 1.0000 - val_loss: 1.7862 - val_accuracy: 0.3571 - lr: 6.0810e-05 - 71ms/epoch - 36ms/step\n",
      "Epoch 39/400\n",
      "2/2 - 0s - loss: 0.0199 - accuracy: 1.0000 - val_loss: 1.7843 - val_accuracy: 0.3571 - lr: 5.5023e-05 - 70ms/epoch - 35ms/step\n",
      "Epoch 40/400\n",
      "2/2 - 0s - loss: 0.0199 - accuracy: 1.0000 - val_loss: 1.7823 - val_accuracy: 0.3571 - lr: 4.9787e-05 - 72ms/epoch - 36ms/step\n",
      "Epoch 41/400\n",
      "2/2 - 0s - loss: 0.0275 - accuracy: 1.0000 - val_loss: 1.7808 - val_accuracy: 0.3571 - lr: 4.5049e-05 - 76ms/epoch - 38ms/step\n",
      "Epoch 42/400\n",
      "2/2 - 0s - loss: 0.0282 - accuracy: 1.0000 - val_loss: 1.7788 - val_accuracy: 0.3571 - lr: 4.0762e-05 - 70ms/epoch - 35ms/step\n",
      "Epoch 43/400\n",
      "2/2 - 0s - loss: 0.0286 - accuracy: 1.0000 - val_loss: 1.7767 - val_accuracy: 0.3571 - lr: 3.6883e-05 - 69ms/epoch - 34ms/step\n",
      "Epoch 44/400\n",
      "2/2 - 0s - loss: 0.0606 - accuracy: 1.0000 - val_loss: 1.7756 - val_accuracy: 0.3571 - lr: 3.3373e-05 - 71ms/epoch - 36ms/step\n",
      "Epoch 45/400\n",
      "2/2 - 0s - loss: 0.0279 - accuracy: 1.0000 - val_loss: 1.7746 - val_accuracy: 0.3571 - lr: 3.0197e-05 - 71ms/epoch - 36ms/step\n",
      "Epoch 46/400\n",
      "2/2 - 0s - loss: 0.0260 - accuracy: 1.0000 - val_loss: 1.7735 - val_accuracy: 0.3571 - lr: 2.7324e-05 - 72ms/epoch - 36ms/step\n",
      "Epoch 47/400\n",
      "2/2 - 0s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 1.7721 - val_accuracy: 0.3571 - lr: 2.4723e-05 - 72ms/epoch - 36ms/step\n",
      "Epoch 48/400\n",
      "2/2 - 0s - loss: 0.0330 - accuracy: 1.0000 - val_loss: 1.7713 - val_accuracy: 0.3571 - lr: 2.2371e-05 - 71ms/epoch - 35ms/step\n",
      "Epoch 49/400\n",
      "2/2 - 0s - loss: 0.0233 - accuracy: 1.0000 - val_loss: 1.7701 - val_accuracy: 0.3571 - lr: 2.0242e-05 - 73ms/epoch - 37ms/step\n",
      "Epoch 50/400\n",
      "2/2 - 0s - loss: 0.0267 - accuracy: 1.0000 - val_loss: 1.7691 - val_accuracy: 0.3571 - lr: 1.8316e-05 - 75ms/epoch - 37ms/step\n",
      "Epoch 51/400\n",
      "2/2 - 0s - loss: 0.0188 - accuracy: 1.0000 - val_loss: 1.7669 - val_accuracy: 0.3571 - lr: 1.6573e-05 - 71ms/epoch - 36ms/step\n",
      "Epoch 52/400\n",
      "2/2 - 0s - loss: 0.0326 - accuracy: 1.0000 - val_loss: 1.7651 - val_accuracy: 0.3571 - lr: 1.4996e-05 - 78ms/epoch - 39ms/step\n",
      "Epoch 53/400\n",
      "2/2 - 0s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 1.7627 - val_accuracy: 0.3571 - lr: 1.3569e-05 - 81ms/epoch - 41ms/step\n",
      "Epoch 54/400\n",
      "2/2 - 0s - loss: 0.0253 - accuracy: 1.0000 - val_loss: 1.7602 - val_accuracy: 0.3571 - lr: 1.2277e-05 - 76ms/epoch - 38ms/step\n",
      "Epoch 55/400\n",
      "2/2 - 0s - loss: 0.0352 - accuracy: 1.0000 - val_loss: 1.7580 - val_accuracy: 0.3571 - lr: 1.1109e-05 - 75ms/epoch - 38ms/step\n",
      "Epoch 56/400\n",
      "2/2 - 0s - loss: 0.0507 - accuracy: 1.0000 - val_loss: 1.7559 - val_accuracy: 0.3571 - lr: 1.0052e-05 - 73ms/epoch - 36ms/step\n",
      "Epoch 57/400\n",
      "2/2 - 0s - loss: 0.0319 - accuracy: 1.0000 - val_loss: 1.7535 - val_accuracy: 0.2857 - lr: 9.0953e-06 - 73ms/epoch - 36ms/step\n",
      "Epoch 58/400\n",
      "2/2 - 0s - loss: 0.0266 - accuracy: 1.0000 - val_loss: 1.7511 - val_accuracy: 0.2857 - lr: 8.2297e-06 - 77ms/epoch - 38ms/step\n",
      "Epoch 59/400\n",
      "2/2 - 0s - loss: 0.0212 - accuracy: 1.0000 - val_loss: 1.7480 - val_accuracy: 0.2857 - lr: 7.4466e-06 - 75ms/epoch - 38ms/step\n",
      "Epoch 60/400\n",
      "2/2 - 0s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 1.7449 - val_accuracy: 0.2857 - lr: 6.7379e-06 - 80ms/epoch - 40ms/step\n",
      "Epoch 61/400\n",
      "2/2 - 0s - loss: 0.0182 - accuracy: 1.0000 - val_loss: 1.7415 - val_accuracy: 0.2857 - lr: 6.0967e-06 - 73ms/epoch - 37ms/step\n",
      "Epoch 62/400\n",
      "2/2 - 0s - loss: 0.0253 - accuracy: 1.0000 - val_loss: 1.7388 - val_accuracy: 0.2857 - lr: 5.5165e-06 - 76ms/epoch - 38ms/step\n",
      "Epoch 63/400\n",
      "2/2 - 0s - loss: 0.0172 - accuracy: 1.0000 - val_loss: 1.7360 - val_accuracy: 0.2857 - lr: 4.9916e-06 - 81ms/epoch - 41ms/step\n",
      "Epoch 64/400\n",
      "2/2 - 0s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.7330 - val_accuracy: 0.2857 - lr: 4.5166e-06 - 74ms/epoch - 37ms/step\n",
      "Epoch 65/400\n",
      "2/2 - 0s - loss: 0.0219 - accuracy: 1.0000 - val_loss: 1.7294 - val_accuracy: 0.2857 - lr: 4.0868e-06 - 76ms/epoch - 38ms/step\n",
      "Epoch 66/400\n",
      "2/2 - 0s - loss: 0.0270 - accuracy: 1.0000 - val_loss: 1.7267 - val_accuracy: 0.2857 - lr: 3.6979e-06 - 75ms/epoch - 37ms/step\n",
      "Epoch 67/400\n",
      "2/2 - 0s - loss: 0.0190 - accuracy: 1.0000 - val_loss: 1.7233 - val_accuracy: 0.2857 - lr: 3.3460e-06 - 77ms/epoch - 39ms/step\n",
      "Epoch 68/400\n",
      "2/2 - 0s - loss: 0.0305 - accuracy: 1.0000 - val_loss: 1.7203 - val_accuracy: 0.2857 - lr: 3.0275e-06 - 79ms/epoch - 39ms/step\n",
      "Epoch 69/400\n",
      "2/2 - 0s - loss: 0.0265 - accuracy: 1.0000 - val_loss: 1.7166 - val_accuracy: 0.2857 - lr: 2.7394e-06 - 80ms/epoch - 40ms/step\n",
      "Epoch 70/400\n",
      "2/2 - 0s - loss: 0.0201 - accuracy: 1.0000 - val_loss: 1.7126 - val_accuracy: 0.2857 - lr: 2.4787e-06 - 78ms/epoch - 39ms/step\n",
      "Epoch 71/400\n",
      "2/2 - 0s - loss: 0.0256 - accuracy: 1.0000 - val_loss: 1.7089 - val_accuracy: 0.2857 - lr: 2.2429e-06 - 70ms/epoch - 35ms/step\n",
      "Epoch 72/400\n",
      "2/2 - 0s - loss: 0.0226 - accuracy: 1.0000 - val_loss: 1.7052 - val_accuracy: 0.2857 - lr: 2.0294e-06 - 75ms/epoch - 38ms/step\n",
      "Epoch 73/400\n",
      "2/2 - 0s - loss: 0.0158 - accuracy: 1.0000 - val_loss: 1.7014 - val_accuracy: 0.2857 - lr: 1.8363e-06 - 95ms/epoch - 48ms/step\n",
      "Epoch 74/400\n",
      "2/2 - 0s - loss: 0.0174 - accuracy: 1.0000 - val_loss: 1.6977 - val_accuracy: 0.2857 - lr: 1.6616e-06 - 78ms/epoch - 39ms/step\n",
      "Epoch 75/400\n",
      "2/2 - 0s - loss: 0.0267 - accuracy: 1.0000 - val_loss: 1.6934 - val_accuracy: 0.2857 - lr: 1.5034e-06 - 83ms/epoch - 41ms/step\n",
      "Epoch 76/400\n",
      "2/2 - 0s - loss: 0.0262 - accuracy: 1.0000 - val_loss: 1.6887 - val_accuracy: 0.2857 - lr: 1.3604e-06 - 76ms/epoch - 38ms/step\n",
      "Epoch 77/400\n",
      "2/2 - 0s - loss: 0.0217 - accuracy: 1.0000 - val_loss: 1.6849 - val_accuracy: 0.2857 - lr: 1.2309e-06 - 83ms/epoch - 41ms/step\n",
      "Epoch 78/400\n",
      "2/2 - 0s - loss: 0.0194 - accuracy: 1.0000 - val_loss: 1.6818 - val_accuracy: 0.2857 - lr: 1.1138e-06 - 77ms/epoch - 39ms/step\n",
      "Epoch 79/400\n",
      "2/2 - 0s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 1.6776 - val_accuracy: 0.2857 - lr: 1.0078e-06 - 77ms/epoch - 38ms/step\n",
      "Epoch 80/400\n",
      "2/2 - 0s - loss: 0.0293 - accuracy: 1.0000 - val_loss: 1.6739 - val_accuracy: 0.2857 - lr: 9.1188e-07 - 77ms/epoch - 38ms/step\n",
      "Epoch 81/400\n",
      "2/2 - 0s - loss: 0.0217 - accuracy: 1.0000 - val_loss: 1.6693 - val_accuracy: 0.2857 - lr: 8.2510e-07 - 75ms/epoch - 37ms/step\n",
      "Epoch 82/400\n",
      "2/2 - 0s - loss: 0.0204 - accuracy: 1.0000 - val_loss: 1.6652 - val_accuracy: 0.2857 - lr: 7.4658e-07 - 77ms/epoch - 39ms/step\n",
      "Epoch 83/400\n",
      "2/2 - 0s - loss: 0.0203 - accuracy: 1.0000 - val_loss: 1.6608 - val_accuracy: 0.2857 - lr: 6.7554e-07 - 80ms/epoch - 40ms/step\n",
      "Epoch 84/400\n",
      "2/2 - 0s - loss: 0.0176 - accuracy: 1.0000 - val_loss: 1.6566 - val_accuracy: 0.2857 - lr: 6.1125e-07 - 75ms/epoch - 37ms/step\n",
      "Epoch 85/400\n",
      "2/2 - 0s - loss: 0.0174 - accuracy: 1.0000 - val_loss: 1.6527 - val_accuracy: 0.2857 - lr: 5.5308e-07 - 84ms/epoch - 42ms/step\n",
      "Epoch 86/400\n",
      "2/2 - 0s - loss: 0.0421 - accuracy: 1.0000 - val_loss: 1.6482 - val_accuracy: 0.2857 - lr: 5.0045e-07 - 75ms/epoch - 38ms/step\n",
      "Epoch 87/400\n",
      "2/2 - 0s - loss: 0.0351 - accuracy: 1.0000 - val_loss: 1.6440 - val_accuracy: 0.2857 - lr: 4.5283e-07 - 76ms/epoch - 38ms/step\n",
      "Epoch 88/400\n",
      "2/2 - 0s - loss: 0.0317 - accuracy: 1.0000 - val_loss: 1.6403 - val_accuracy: 0.2857 - lr: 4.0973e-07 - 73ms/epoch - 36ms/step\n",
      "Epoch 89/400\n",
      "2/2 - 0s - loss: 0.0198 - accuracy: 1.0000 - val_loss: 1.6369 - val_accuracy: 0.2857 - lr: 3.7074e-07 - 78ms/epoch - 39ms/step\n",
      "Epoch 90/400\n",
      "2/2 - 0s - loss: 0.0214 - accuracy: 1.0000 - val_loss: 1.6328 - val_accuracy: 0.2857 - lr: 3.3546e-07 - 80ms/epoch - 40ms/step\n",
      "Epoch 91/400\n",
      "2/2 - 0s - loss: 0.0204 - accuracy: 1.0000 - val_loss: 1.6291 - val_accuracy: 0.2857 - lr: 3.0354e-07 - 80ms/epoch - 40ms/step\n",
      "Epoch 92/400\n",
      "2/2 - 0s - loss: 0.0252 - accuracy: 1.0000 - val_loss: 1.6256 - val_accuracy: 0.2857 - lr: 2.7465e-07 - 83ms/epoch - 42ms/step\n",
      "Epoch 93/400\n",
      "2/2 - 0s - loss: 0.0254 - accuracy: 1.0000 - val_loss: 1.6217 - val_accuracy: 0.2857 - lr: 2.4852e-07 - 85ms/epoch - 43ms/step\n",
      "Epoch 94/400\n",
      "2/2 - 0s - loss: 0.0236 - accuracy: 1.0000 - val_loss: 1.6181 - val_accuracy: 0.2857 - lr: 2.2487e-07 - 82ms/epoch - 41ms/step\n",
      "Epoch 95/400\n",
      "2/2 - 0s - loss: 0.0245 - accuracy: 1.0000 - val_loss: 1.6142 - val_accuracy: 0.2857 - lr: 2.0347e-07 - 83ms/epoch - 41ms/step\n",
      "Epoch 96/400\n",
      "2/2 - 0s - loss: 0.0268 - accuracy: 1.0000 - val_loss: 1.6100 - val_accuracy: 0.2857 - lr: 1.8410e-07 - 86ms/epoch - 43ms/step\n",
      "Epoch 97/400\n",
      "2/2 - 0s - loss: 0.0238 - accuracy: 1.0000 - val_loss: 1.6057 - val_accuracy: 0.2857 - lr: 1.6659e-07 - 73ms/epoch - 36ms/step\n",
      "Epoch 98/400\n",
      "2/2 - 0s - loss: 0.0287 - accuracy: 1.0000 - val_loss: 1.6014 - val_accuracy: 0.2857 - lr: 1.5073e-07 - 74ms/epoch - 37ms/step\n",
      "Epoch 99/400\n",
      "2/2 - 0s - loss: 0.0238 - accuracy: 1.0000 - val_loss: 1.5976 - val_accuracy: 0.2857 - lr: 1.3639e-07 - 78ms/epoch - 39ms/step\n",
      "Epoch 100/400\n",
      "2/2 - 0s - loss: 0.0314 - accuracy: 1.0000 - val_loss: 1.5938 - val_accuracy: 0.2857 - lr: 1.2341e-07 - 77ms/epoch - 38ms/step\n",
      "Epoch 101/400\n",
      "2/2 - 0s - loss: 0.0347 - accuracy: 1.0000 - val_loss: 1.5914 - val_accuracy: 0.2857 - lr: 1.1167e-07 - 75ms/epoch - 37ms/step\n",
      "Epoch 102/400\n",
      "2/2 - 0s - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.5877 - val_accuracy: 0.2857 - lr: 1.0104e-07 - 83ms/epoch - 42ms/step\n",
      "Epoch 103/400\n",
      "2/2 - 0s - loss: 0.0145 - accuracy: 1.0000 - val_loss: 1.5844 - val_accuracy: 0.2857 - lr: 9.1424e-08 - 77ms/epoch - 38ms/step\n",
      "Epoch 104/400\n",
      "2/2 - 0s - loss: 0.0351 - accuracy: 1.0000 - val_loss: 1.5803 - val_accuracy: 0.2857 - lr: 8.2724e-08 - 80ms/epoch - 40ms/step\n",
      "Epoch 105/400\n",
      "2/2 - 0s - loss: 0.0309 - accuracy: 1.0000 - val_loss: 1.5776 - val_accuracy: 0.3571 - lr: 7.4851e-08 - 79ms/epoch - 39ms/step\n",
      "Epoch 106/400\n",
      "2/2 - 0s - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.5745 - val_accuracy: 0.3571 - lr: 6.7728e-08 - 84ms/epoch - 42ms/step\n",
      "Epoch 107/400\n",
      "2/2 - 0s - loss: 0.0404 - accuracy: 1.0000 - val_loss: 1.5720 - val_accuracy: 0.2857 - lr: 6.1283e-08 - 84ms/epoch - 42ms/step\n",
      "Epoch 108/400\n",
      "2/2 - 0s - loss: 0.0182 - accuracy: 1.0000 - val_loss: 1.5694 - val_accuracy: 0.2857 - lr: 5.5451e-08 - 75ms/epoch - 37ms/step\n",
      "Epoch 109/400\n",
      "2/2 - 0s - loss: 0.0261 - accuracy: 1.0000 - val_loss: 1.5666 - val_accuracy: 0.2857 - lr: 5.0174e-08 - 79ms/epoch - 39ms/step\n",
      "Epoch 110/400\n",
      "2/2 - 0s - loss: 0.0256 - accuracy: 1.0000 - val_loss: 1.5651 - val_accuracy: 0.2857 - lr: 4.5400e-08 - 75ms/epoch - 37ms/step\n",
      "Epoch 111/400\n",
      "2/2 - 0s - loss: 0.0182 - accuracy: 1.0000 - val_loss: 1.5622 - val_accuracy: 0.2857 - lr: 4.1079e-08 - 75ms/epoch - 37ms/step\n",
      "Epoch 112/400\n",
      "2/2 - 0s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 1.5594 - val_accuracy: 0.2857 - lr: 3.7170e-08 - 75ms/epoch - 37ms/step\n",
      "Epoch 113/400\n",
      "2/2 - 0s - loss: 0.0232 - accuracy: 1.0000 - val_loss: 1.5571 - val_accuracy: 0.2857 - lr: 3.3633e-08 - 73ms/epoch - 36ms/step\n",
      "Epoch 114/400\n",
      "2/2 - 0s - loss: 0.0305 - accuracy: 1.0000 - val_loss: 1.5547 - val_accuracy: 0.2857 - lr: 3.0432e-08 - 75ms/epoch - 38ms/step\n",
      "Epoch 115/400\n",
      "2/2 - 0s - loss: 0.0292 - accuracy: 1.0000 - val_loss: 1.5521 - val_accuracy: 0.2857 - lr: 2.7536e-08 - 74ms/epoch - 37ms/step\n",
      "Epoch 116/400\n",
      "2/2 - 0s - loss: 0.0306 - accuracy: 1.0000 - val_loss: 1.5507 - val_accuracy: 0.2857 - lr: 2.4916e-08 - 74ms/epoch - 37ms/step\n",
      "Epoch 117/400\n",
      "2/2 - 0s - loss: 0.0275 - accuracy: 1.0000 - val_loss: 1.5495 - val_accuracy: 0.2857 - lr: 2.2545e-08 - 77ms/epoch - 38ms/step\n",
      "Epoch 118/400\n",
      "2/2 - 0s - loss: 0.0240 - accuracy: 1.0000 - val_loss: 1.5476 - val_accuracy: 0.2857 - lr: 2.0399e-08 - 75ms/epoch - 38ms/step\n",
      "Epoch 119/400\n",
      "2/2 - 0s - loss: 0.0144 - accuracy: 1.0000 - val_loss: 1.5459 - val_accuracy: 0.2857 - lr: 1.8458e-08 - 75ms/epoch - 37ms/step\n",
      "Epoch 120/400\n",
      "2/2 - 0s - loss: 0.0198 - accuracy: 1.0000 - val_loss: 1.5449 - val_accuracy: 0.2857 - lr: 1.6702e-08 - 75ms/epoch - 38ms/step\n",
      "Epoch 121/400\n",
      "2/2 - 0s - loss: 0.0281 - accuracy: 1.0000 - val_loss: 1.5437 - val_accuracy: 0.2857 - lr: 1.5112e-08 - 74ms/epoch - 37ms/step\n",
      "Epoch 122/400\n",
      "2/2 - 0s - loss: 0.0190 - accuracy: 1.0000 - val_loss: 1.5419 - val_accuracy: 0.2857 - lr: 1.3674e-08 - 74ms/epoch - 37ms/step\n",
      "Epoch 123/400\n",
      "2/2 - 0s - loss: 0.0248 - accuracy: 1.0000 - val_loss: 1.5398 - val_accuracy: 0.2857 - lr: 1.2373e-08 - 70ms/epoch - 35ms/step\n",
      "Epoch 124/400\n",
      "2/2 - 0s - loss: 0.0228 - accuracy: 1.0000 - val_loss: 1.5376 - val_accuracy: 0.2857 - lr: 1.1195e-08 - 69ms/epoch - 34ms/step\n",
      "Epoch 125/400\n",
      "2/2 - 0s - loss: 0.0194 - accuracy: 1.0000 - val_loss: 1.5353 - val_accuracy: 0.2857 - lr: 1.0130e-08 - 71ms/epoch - 35ms/step\n",
      "Epoch 126/400\n",
      "2/2 - 0s - loss: 0.0205 - accuracy: 1.0000 - val_loss: 1.5328 - val_accuracy: 0.2857 - lr: 9.1660e-09 - 69ms/epoch - 35ms/step\n",
      "Epoch 127/400\n",
      "2/2 - 0s - loss: 0.0279 - accuracy: 1.0000 - val_loss: 1.5320 - val_accuracy: 0.2857 - lr: 8.2938e-09 - 76ms/epoch - 38ms/step\n",
      "Epoch 128/400\n",
      "2/2 - 0s - loss: 0.0380 - accuracy: 1.0000 - val_loss: 1.5314 - val_accuracy: 0.2857 - lr: 7.5045e-09 - 74ms/epoch - 37ms/step\n",
      "Epoch 129/400\n",
      "2/2 - 0s - loss: 0.0550 - accuracy: 1.0000 - val_loss: 1.5296 - val_accuracy: 0.2857 - lr: 6.7904e-09 - 72ms/epoch - 36ms/step\n",
      "Epoch 130/400\n",
      "2/2 - 0s - loss: 0.0202 - accuracy: 1.0000 - val_loss: 1.5280 - val_accuracy: 0.2857 - lr: 6.1442e-09 - 72ms/epoch - 36ms/step\n",
      "Epoch 131/400\n",
      "2/2 - 0s - loss: 0.0353 - accuracy: 1.0000 - val_loss: 1.5258 - val_accuracy: 0.2857 - lr: 5.5595e-09 - 77ms/epoch - 38ms/step\n",
      "Epoch 132/400\n",
      "2/2 - 0s - loss: 0.0394 - accuracy: 1.0000 - val_loss: 1.5235 - val_accuracy: 0.2857 - lr: 5.0304e-09 - 73ms/epoch - 37ms/step\n",
      "Epoch 133/400\n",
      "2/2 - 0s - loss: 0.0409 - accuracy: 1.0000 - val_loss: 1.5224 - val_accuracy: 0.2857 - lr: 4.5517e-09 - 76ms/epoch - 38ms/step\n",
      "Epoch 134/400\n",
      "2/2 - 0s - loss: 0.0296 - accuracy: 1.0000 - val_loss: 1.5203 - val_accuracy: 0.2857 - lr: 4.1186e-09 - 70ms/epoch - 35ms/step\n",
      "Epoch 135/400\n",
      "2/2 - 0s - loss: 0.0273 - accuracy: 1.0000 - val_loss: 1.5187 - val_accuracy: 0.2857 - lr: 3.7266e-09 - 70ms/epoch - 35ms/step\n",
      "Epoch 136/400\n",
      "2/2 - 0s - loss: 0.0308 - accuracy: 1.0000 - val_loss: 1.5182 - val_accuracy: 0.2857 - lr: 3.3720e-09 - 80ms/epoch - 40ms/step\n",
      "Epoch 137/400\n",
      "2/2 - 0s - loss: 0.0302 - accuracy: 1.0000 - val_loss: 1.5178 - val_accuracy: 0.2857 - lr: 3.0511e-09 - 72ms/epoch - 36ms/step\n",
      "Epoch 138/400\n",
      "2/2 - 0s - loss: 0.0471 - accuracy: 1.0000 - val_loss: 1.5151 - val_accuracy: 0.3571 - lr: 2.7608e-09 - 75ms/epoch - 37ms/step\n",
      "Epoch 139/400\n",
      "2/2 - 0s - loss: 0.0325 - accuracy: 1.0000 - val_loss: 1.5126 - val_accuracy: 0.3571 - lr: 2.4980e-09 - 74ms/epoch - 37ms/step\n",
      "Epoch 140/400\n",
      "2/2 - 0s - loss: 0.0339 - accuracy: 1.0000 - val_loss: 1.5105 - val_accuracy: 0.3571 - lr: 2.2603e-09 - 75ms/epoch - 37ms/step\n",
      "Epoch 141/400\n",
      "2/2 - 0s - loss: 0.0366 - accuracy: 1.0000 - val_loss: 1.5106 - val_accuracy: 0.3571 - lr: 2.0452e-09 - 59ms/epoch - 30ms/step\n",
      "Epoch 142/400\n",
      "2/2 - 0s - loss: 0.0199 - accuracy: 1.0000 - val_loss: 1.5099 - val_accuracy: 0.3571 - lr: 1.8506e-09 - 77ms/epoch - 38ms/step\n",
      "Epoch 143/400\n",
      "2/2 - 0s - loss: 0.0188 - accuracy: 1.0000 - val_loss: 1.5092 - val_accuracy: 0.3571 - lr: 1.6745e-09 - 74ms/epoch - 37ms/step\n",
      "Epoch 144/400\n",
      "2/2 - 0s - loss: 0.0411 - accuracy: 1.0000 - val_loss: 1.5078 - val_accuracy: 0.3571 - lr: 1.5151e-09 - 74ms/epoch - 37ms/step\n",
      "Epoch 145/400\n",
      "2/2 - 0s - loss: 0.0315 - accuracy: 1.0000 - val_loss: 1.5069 - val_accuracy: 0.3571 - lr: 1.3709e-09 - 73ms/epoch - 36ms/step\n",
      "Epoch 146/400\n",
      "2/2 - 0s - loss: 0.0159 - accuracy: 1.0000 - val_loss: 1.5063 - val_accuracy: 0.3571 - lr: 1.2405e-09 - 77ms/epoch - 38ms/step\n",
      "Epoch 147/400\n",
      "2/2 - 0s - loss: 0.0300 - accuracy: 1.0000 - val_loss: 1.5052 - val_accuracy: 0.3571 - lr: 1.1224e-09 - 75ms/epoch - 38ms/step\n",
      "Epoch 148/400\n",
      "2/2 - 0s - loss: 0.0583 - accuracy: 1.0000 - val_loss: 1.5045 - val_accuracy: 0.3571 - lr: 1.0156e-09 - 75ms/epoch - 37ms/step\n",
      "Epoch 149/400\n",
      "2/2 - 0s - loss: 0.0366 - accuracy: 1.0000 - val_loss: 1.5021 - val_accuracy: 0.3571 - lr: 9.1897e-10 - 72ms/epoch - 36ms/step\n",
      "Epoch 150/400\n",
      "2/2 - 0s - loss: 0.0296 - accuracy: 1.0000 - val_loss: 1.5009 - val_accuracy: 0.3571 - lr: 8.3152e-10 - 76ms/epoch - 38ms/step\n",
      "Epoch 151/400\n",
      "2/2 - 0s - loss: 0.0288 - accuracy: 1.0000 - val_loss: 1.4998 - val_accuracy: 0.3571 - lr: 7.5239e-10 - 80ms/epoch - 40ms/step\n",
      "Epoch 152/400\n",
      "2/2 - 0s - loss: 0.0217 - accuracy: 1.0000 - val_loss: 1.4993 - val_accuracy: 0.3571 - lr: 6.8079e-10 - 72ms/epoch - 36ms/step\n",
      "Epoch 153/400\n",
      "2/2 - 0s - loss: 0.0420 - accuracy: 1.0000 - val_loss: 1.4993 - val_accuracy: 0.3571 - lr: 6.1601e-10 - 63ms/epoch - 32ms/step\n",
      "Epoch 154/400\n",
      "2/2 - 0s - loss: 0.0316 - accuracy: 1.0000 - val_loss: 1.4983 - val_accuracy: 0.3571 - lr: 5.5739e-10 - 77ms/epoch - 38ms/step\n",
      "Epoch 155/400\n",
      "2/2 - 0s - loss: 0.0247 - accuracy: 1.0000 - val_loss: 1.4977 - val_accuracy: 0.3571 - lr: 5.0434e-10 - 83ms/epoch - 42ms/step\n",
      "Epoch 156/400\n",
      "2/2 - 0s - loss: 0.0181 - accuracy: 1.0000 - val_loss: 1.4979 - val_accuracy: 0.3571 - lr: 4.5635e-10 - 69ms/epoch - 35ms/step\n",
      "Epoch 157/400\n",
      "2/2 - 0s - loss: 0.0645 - accuracy: 0.9811 - val_loss: 1.4966 - val_accuracy: 0.3571 - lr: 4.1292e-10 - 81ms/epoch - 41ms/step\n",
      "Epoch 158/400\n",
      "2/2 - 0s - loss: 0.0346 - accuracy: 1.0000 - val_loss: 1.4956 - val_accuracy: 0.3571 - lr: 3.7363e-10 - 74ms/epoch - 37ms/step\n",
      "Epoch 159/400\n",
      "2/2 - 0s - loss: 0.0318 - accuracy: 1.0000 - val_loss: 1.4947 - val_accuracy: 0.3571 - lr: 3.3807e-10 - 72ms/epoch - 36ms/step\n",
      "Epoch 160/400\n",
      "2/2 - 0s - loss: 0.0230 - accuracy: 1.0000 - val_loss: 1.4945 - val_accuracy: 0.3571 - lr: 3.0590e-10 - 74ms/epoch - 37ms/step\n",
      "Epoch 161/400\n",
      "2/2 - 0s - loss: 0.0233 - accuracy: 1.0000 - val_loss: 1.4939 - val_accuracy: 0.3571 - lr: 2.7679e-10 - 67ms/epoch - 34ms/step\n",
      "Epoch 162/400\n",
      "2/2 - 0s - loss: 0.0201 - accuracy: 1.0000 - val_loss: 1.4935 - val_accuracy: 0.3571 - lr: 2.5045e-10 - 69ms/epoch - 34ms/step\n",
      "Epoch 163/400\n",
      "2/2 - 0s - loss: 0.0231 - accuracy: 1.0000 - val_loss: 1.4930 - val_accuracy: 0.3571 - lr: 2.2662e-10 - 73ms/epoch - 37ms/step\n",
      "Epoch 164/400\n",
      "2/2 - 0s - loss: 0.0336 - accuracy: 1.0000 - val_loss: 1.4932 - val_accuracy: 0.3571 - lr: 2.0505e-10 - 58ms/epoch - 29ms/step\n",
      "Epoch 165/400\n",
      "2/2 - 0s - loss: 0.0328 - accuracy: 1.0000 - val_loss: 1.4929 - val_accuracy: 0.3571 - lr: 1.8554e-10 - 72ms/epoch - 36ms/step\n",
      "Epoch 166/400\n",
      "2/2 - 0s - loss: 0.0515 - accuracy: 1.0000 - val_loss: 1.4917 - val_accuracy: 0.3571 - lr: 1.6788e-10 - 75ms/epoch - 38ms/step\n",
      "Epoch 167/400\n",
      "2/2 - 0s - loss: 0.0228 - accuracy: 1.0000 - val_loss: 1.4913 - val_accuracy: 0.3571 - lr: 1.5191e-10 - 74ms/epoch - 37ms/step\n",
      "Epoch 168/400\n",
      "2/2 - 0s - loss: 0.0322 - accuracy: 1.0000 - val_loss: 1.4905 - val_accuracy: 0.3571 - lr: 1.3745e-10 - 75ms/epoch - 38ms/step\n",
      "Epoch 169/400\n",
      "2/2 - 0s - loss: 0.0227 - accuracy: 1.0000 - val_loss: 1.4912 - val_accuracy: 0.3571 - lr: 1.2437e-10 - 62ms/epoch - 31ms/step\n",
      "Epoch 170/400\n",
      "2/2 - 0s - loss: 0.0402 - accuracy: 1.0000 - val_loss: 1.4903 - val_accuracy: 0.3571 - lr: 1.1253e-10 - 76ms/epoch - 38ms/step\n",
      "Epoch 171/400\n",
      "2/2 - 0s - loss: 0.0212 - accuracy: 1.0000 - val_loss: 1.4892 - val_accuracy: 0.3571 - lr: 1.0183e-10 - 77ms/epoch - 39ms/step\n",
      "Epoch 172/400\n",
      "2/2 - 0s - loss: 0.0272 - accuracy: 1.0000 - val_loss: 1.4890 - val_accuracy: 0.3571 - lr: 9.2135e-11 - 76ms/epoch - 38ms/step\n",
      "Epoch 173/400\n",
      "2/2 - 0s - loss: 0.0351 - accuracy: 1.0000 - val_loss: 1.4889 - val_accuracy: 0.3571 - lr: 8.3367e-11 - 74ms/epoch - 37ms/step\n",
      "Epoch 174/400\n",
      "2/2 - 0s - loss: 0.0213 - accuracy: 1.0000 - val_loss: 1.4895 - val_accuracy: 0.3571 - lr: 7.5434e-11 - 55ms/epoch - 28ms/step\n",
      "Epoch 175/400\n",
      "2/2 - 0s - loss: 0.0171 - accuracy: 1.0000 - val_loss: 1.4889 - val_accuracy: 0.3571 - lr: 6.8255e-11 - 57ms/epoch - 28ms/step\n",
      "Epoch 176/400\n",
      "2/2 - 0s - loss: 0.0273 - accuracy: 1.0000 - val_loss: 1.4891 - val_accuracy: 0.3571 - lr: 6.1760e-11 - 57ms/epoch - 28ms/step\n",
      "Epoch 177/400\n",
      "2/2 - 0s - loss: 0.0167 - accuracy: 1.0000 - val_loss: 1.4892 - val_accuracy: 0.3571 - lr: 5.5883e-11 - 55ms/epoch - 28ms/step\n",
      "Epoch 178/400\n",
      "2/2 - 0s - loss: 0.0599 - accuracy: 1.0000 - val_loss: 1.4881 - val_accuracy: 0.2857 - lr: 5.0565e-11 - 72ms/epoch - 36ms/step\n",
      "Epoch 179/400\n",
      "2/2 - 0s - loss: 0.0504 - accuracy: 1.0000 - val_loss: 1.4879 - val_accuracy: 0.2857 - lr: 4.5753e-11 - 74ms/epoch - 37ms/step\n",
      "Epoch 180/400\n",
      "2/2 - 0s - loss: 0.0218 - accuracy: 1.0000 - val_loss: 1.4877 - val_accuracy: 0.2857 - lr: 4.1399e-11 - 93ms/epoch - 47ms/step\n",
      "Epoch 181/400\n",
      "2/2 - 0s - loss: 0.0269 - accuracy: 1.0000 - val_loss: 1.4876 - val_accuracy: 0.2857 - lr: 3.7459e-11 - 74ms/epoch - 37ms/step\n",
      "Epoch 182/400\n",
      "2/2 - 0s - loss: 0.0216 - accuracy: 1.0000 - val_loss: 1.4866 - val_accuracy: 0.2857 - lr: 3.3895e-11 - 75ms/epoch - 37ms/step\n",
      "Epoch 183/400\n",
      "2/2 - 0s - loss: 0.0332 - accuracy: 1.0000 - val_loss: 1.4857 - val_accuracy: 0.2857 - lr: 3.0669e-11 - 77ms/epoch - 39ms/step\n",
      "Epoch 184/400\n",
      "2/2 - 0s - loss: 0.0205 - accuracy: 1.0000 - val_loss: 1.4859 - val_accuracy: 0.2857 - lr: 2.7751e-11 - 63ms/epoch - 31ms/step\n",
      "Epoch 185/400\n",
      "2/2 - 0s - loss: 0.0220 - accuracy: 1.0000 - val_loss: 1.4866 - val_accuracy: 0.2857 - lr: 2.5110e-11 - 60ms/epoch - 30ms/step\n",
      "Epoch 186/400\n",
      "2/2 - 0s - loss: 0.0235 - accuracy: 1.0000 - val_loss: 1.4867 - val_accuracy: 0.2857 - lr: 2.2720e-11 - 62ms/epoch - 31ms/step\n",
      "Epoch 187/400\n",
      "2/2 - 0s - loss: 0.0210 - accuracy: 1.0000 - val_loss: 1.4865 - val_accuracy: 0.2857 - lr: 2.0558e-11 - 62ms/epoch - 31ms/step\n",
      "Epoch 188/400\n",
      "2/2 - 0s - loss: 0.0381 - accuracy: 1.0000 - val_loss: 1.4857 - val_accuracy: 0.2857 - lr: 1.8602e-11 - 60ms/epoch - 30ms/step\n",
      "Epoch 189/400\n",
      "2/2 - 0s - loss: 0.0291 - accuracy: 1.0000 - val_loss: 1.4854 - val_accuracy: 0.2857 - lr: 1.6832e-11 - 81ms/epoch - 41ms/step\n",
      "Epoch 190/400\n",
      "2/2 - 0s - loss: 0.0210 - accuracy: 1.0000 - val_loss: 1.4854 - val_accuracy: 0.2857 - lr: 1.5230e-11 - 78ms/epoch - 39ms/step\n",
      "Epoch 191/400\n",
      "2/2 - 0s - loss: 0.0362 - accuracy: 1.0000 - val_loss: 1.4843 - val_accuracy: 0.2857 - lr: 1.3781e-11 - 74ms/epoch - 37ms/step\n",
      "Epoch 192/400\n",
      "2/2 - 0s - loss: 0.0200 - accuracy: 1.0000 - val_loss: 1.4834 - val_accuracy: 0.3571 - lr: 1.2469e-11 - 85ms/epoch - 43ms/step\n",
      "Epoch 193/400\n",
      "2/2 - 0s - loss: 0.0291 - accuracy: 1.0000 - val_loss: 1.4848 - val_accuracy: 0.3571 - lr: 1.1283e-11 - 63ms/epoch - 31ms/step\n",
      "Epoch 194/400\n",
      "2/2 - 0s - loss: 0.0337 - accuracy: 1.0000 - val_loss: 1.4849 - val_accuracy: 0.3571 - lr: 1.0209e-11 - 67ms/epoch - 33ms/step\n",
      "Epoch 195/400\n",
      "2/2 - 0s - loss: 0.0275 - accuracy: 1.0000 - val_loss: 1.4843 - val_accuracy: 0.3571 - lr: 9.2374e-12 - 62ms/epoch - 31ms/step\n",
      "Epoch 196/400\n",
      "2/2 - 0s - loss: 0.0326 - accuracy: 1.0000 - val_loss: 1.4832 - val_accuracy: 0.3571 - lr: 8.3583e-12 - 80ms/epoch - 40ms/step\n",
      "Epoch 197/400\n",
      "2/2 - 0s - loss: 0.0468 - accuracy: 1.0000 - val_loss: 1.4838 - val_accuracy: 0.3571 - lr: 7.5629e-12 - 56ms/epoch - 28ms/step\n",
      "Epoch 198/400\n",
      "2/2 - 0s - loss: 0.0175 - accuracy: 1.0000 - val_loss: 1.4832 - val_accuracy: 0.3571 - lr: 6.8432e-12 - 63ms/epoch - 32ms/step\n",
      "Epoch 199/400\n",
      "2/2 - 0s - loss: 0.0191 - accuracy: 1.0000 - val_loss: 1.4833 - val_accuracy: 0.3571 - lr: 6.1920e-12 - 61ms/epoch - 31ms/step\n",
      "Epoch 200/400\n",
      "2/2 - 0s - loss: 0.0184 - accuracy: 1.0000 - val_loss: 1.4825 - val_accuracy: 0.3571 - lr: 5.6027e-12 - 77ms/epoch - 39ms/step\n",
      "Epoch 201/400\n",
      "2/2 - 0s - loss: 0.0228 - accuracy: 1.0000 - val_loss: 1.4822 - val_accuracy: 0.3571 - lr: 5.0696e-12 - 78ms/epoch - 39ms/step\n",
      "Epoch 202/400\n",
      "2/2 - 0s - loss: 0.0259 - accuracy: 1.0000 - val_loss: 1.4819 - val_accuracy: 0.3571 - lr: 4.5871e-12 - 72ms/epoch - 36ms/step\n",
      "Epoch 203/400\n",
      "2/2 - 0s - loss: 0.0268 - accuracy: 1.0000 - val_loss: 1.4821 - val_accuracy: 0.3571 - lr: 4.1506e-12 - 62ms/epoch - 31ms/step\n",
      "Epoch 204/400\n",
      "2/2 - 0s - loss: 0.0266 - accuracy: 1.0000 - val_loss: 1.4829 - val_accuracy: 0.3571 - lr: 3.7556e-12 - 59ms/epoch - 30ms/step\n",
      "Epoch 205/400\n",
      "2/2 - 0s - loss: 0.0234 - accuracy: 1.0000 - val_loss: 1.4823 - val_accuracy: 0.3571 - lr: 3.3982e-12 - 62ms/epoch - 31ms/step\n",
      "Epoch 206/400\n",
      "2/2 - 0s - loss: 0.0216 - accuracy: 1.0000 - val_loss: 1.4809 - val_accuracy: 0.3571 - lr: 3.0748e-12 - 76ms/epoch - 38ms/step\n",
      "Epoch 207/400\n",
      "2/2 - 0s - loss: 0.0253 - accuracy: 1.0000 - val_loss: 1.4801 - val_accuracy: 0.3571 - lr: 2.7822e-12 - 77ms/epoch - 39ms/step\n",
      "Epoch 208/400\n",
      "2/2 - 0s - loss: 0.0290 - accuracy: 1.0000 - val_loss: 1.4797 - val_accuracy: 0.3571 - lr: 2.5175e-12 - 77ms/epoch - 39ms/step\n",
      "Epoch 209/400\n",
      "2/2 - 0s - loss: 0.0218 - accuracy: 1.0000 - val_loss: 1.4798 - val_accuracy: 0.3571 - lr: 2.2779e-12 - 58ms/epoch - 29ms/step\n",
      "Epoch 210/400\n",
      "2/2 - 0s - loss: 0.0121 - accuracy: 1.0000 - val_loss: 1.4799 - val_accuracy: 0.3571 - lr: 2.0611e-12 - 60ms/epoch - 30ms/step\n",
      "Epoch 211/400\n",
      "2/2 - 0s - loss: 0.0487 - accuracy: 1.0000 - val_loss: 1.4798 - val_accuracy: 0.3571 - lr: 1.8650e-12 - 55ms/epoch - 28ms/step\n",
      "Epoch 212/400\n",
      "2/2 - 0s - loss: 0.0249 - accuracy: 1.0000 - val_loss: 1.4800 - val_accuracy: 0.3571 - lr: 1.6875e-12 - 62ms/epoch - 31ms/step\n",
      "Epoch 213/400\n",
      "2/2 - 0s - loss: 0.0302 - accuracy: 1.0000 - val_loss: 1.4803 - val_accuracy: 0.3571 - lr: 1.5269e-12 - 60ms/epoch - 30ms/step\n",
      "Epoch 214/400\n",
      "2/2 - 0s - loss: 0.0188 - accuracy: 1.0000 - val_loss: 1.4807 - val_accuracy: 0.3571 - lr: 1.3816e-12 - 61ms/epoch - 30ms/step\n",
      "Epoch 215/400\n",
      "2/2 - 0s - loss: 0.0251 - accuracy: 1.0000 - val_loss: 1.4802 - val_accuracy: 0.3571 - lr: 1.2501e-12 - 67ms/epoch - 34ms/step\n",
      "Epoch 216/400\n",
      "2/2 - 0s - loss: 0.0243 - accuracy: 1.0000 - val_loss: 1.4791 - val_accuracy: 0.3571 - lr: 1.1312e-12 - 79ms/epoch - 39ms/step\n",
      "Epoch 217/400\n",
      "2/2 - 0s - loss: 0.0194 - accuracy: 1.0000 - val_loss: 1.4790 - val_accuracy: 0.3571 - lr: 1.0235e-12 - 74ms/epoch - 37ms/step\n",
      "Epoch 218/400\n",
      "2/2 - 0s - loss: 0.0363 - accuracy: 1.0000 - val_loss: 1.4781 - val_accuracy: 0.3571 - lr: 9.2613e-13 - 74ms/epoch - 37ms/step\n",
      "Epoch 219/400\n",
      "2/2 - 0s - loss: 0.0219 - accuracy: 1.0000 - val_loss: 1.4776 - val_accuracy: 0.3571 - lr: 8.3799e-13 - 77ms/epoch - 39ms/step\n",
      "Epoch 220/400\n",
      "2/2 - 0s - loss: 0.0347 - accuracy: 1.0000 - val_loss: 1.4778 - val_accuracy: 0.3571 - lr: 7.5825e-13 - 60ms/epoch - 30ms/step\n",
      "Epoch 221/400\n",
      "2/2 - 0s - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.4778 - val_accuracy: 0.3571 - lr: 6.8609e-13 - 59ms/epoch - 29ms/step\n",
      "Epoch 222/400\n",
      "2/2 - 0s - loss: 0.0332 - accuracy: 1.0000 - val_loss: 1.4783 - val_accuracy: 0.3571 - lr: 6.2080e-13 - 69ms/epoch - 35ms/step\n",
      "Epoch 223/400\n",
      "2/2 - 0s - loss: 0.0428 - accuracy: 0.9811 - val_loss: 1.4798 - val_accuracy: 0.3571 - lr: 5.6172e-13 - 67ms/epoch - 33ms/step\n",
      "Epoch 224/400\n",
      "2/2 - 0s - loss: 0.0302 - accuracy: 1.0000 - val_loss: 1.4810 - val_accuracy: 0.3571 - lr: 5.0827e-13 - 71ms/epoch - 36ms/step\n",
      "Epoch 225/400\n",
      "2/2 - 0s - loss: 0.0176 - accuracy: 1.0000 - val_loss: 1.4819 - val_accuracy: 0.3571 - lr: 4.5990e-13 - 62ms/epoch - 31ms/step\n",
      "Epoch 226/400\n",
      "2/2 - 0s - loss: 0.0275 - accuracy: 1.0000 - val_loss: 1.4798 - val_accuracy: 0.3571 - lr: 4.1613e-13 - 68ms/epoch - 34ms/step\n",
      "Epoch 227/400\n",
      "2/2 - 0s - loss: 0.0313 - accuracy: 1.0000 - val_loss: 1.4786 - val_accuracy: 0.3571 - lr: 3.7653e-13 - 64ms/epoch - 32ms/step\n",
      "Epoch 228/400\n",
      "2/2 - 0s - loss: 0.0273 - accuracy: 1.0000 - val_loss: 1.4787 - val_accuracy: 0.3571 - lr: 3.4070e-13 - 61ms/epoch - 30ms/step\n",
      "Epoch 229/400\n",
      "2/2 - 0s - loss: 0.0250 - accuracy: 1.0000 - val_loss: 1.4795 - val_accuracy: 0.3571 - lr: 3.0828e-13 - 57ms/epoch - 29ms/step\n",
      "Epoch 230/400\n",
      "2/2 - 0s - loss: 0.0318 - accuracy: 1.0000 - val_loss: 1.4817 - val_accuracy: 0.3571 - lr: 2.7894e-13 - 60ms/epoch - 30ms/step\n",
      "Epoch 231/400\n",
      "2/2 - 0s - loss: 0.0172 - accuracy: 1.0000 - val_loss: 1.4811 - val_accuracy: 0.3571 - lr: 2.5240e-13 - 56ms/epoch - 28ms/step\n",
      "Epoch 232/400\n",
      "2/2 - 0s - loss: 0.0185 - accuracy: 1.0000 - val_loss: 1.4807 - val_accuracy: 0.3571 - lr: 2.2838e-13 - 61ms/epoch - 30ms/step\n",
      "Epoch 233/400\n",
      "2/2 - 0s - loss: 0.0303 - accuracy: 1.0000 - val_loss: 1.4810 - val_accuracy: 0.3571 - lr: 2.0665e-13 - 78ms/epoch - 39ms/step\n",
      "Epoch 234/400\n",
      "2/2 - 0s - loss: 0.0380 - accuracy: 1.0000 - val_loss: 1.4793 - val_accuracy: 0.3571 - lr: 1.8698e-13 - 60ms/epoch - 30ms/step\n",
      "Epoch 235/400\n",
      "2/2 - 0s - loss: 0.0259 - accuracy: 1.0000 - val_loss: 1.4806 - val_accuracy: 0.3571 - lr: 1.6919e-13 - 61ms/epoch - 31ms/step\n",
      "Epoch 236/400\n",
      "2/2 - 0s - loss: 0.0335 - accuracy: 1.0000 - val_loss: 1.4809 - val_accuracy: 0.3571 - lr: 1.5309e-13 - 63ms/epoch - 32ms/step\n",
      "Epoch 237/400\n",
      "2/2 - 0s - loss: 0.0198 - accuracy: 1.0000 - val_loss: 1.4806 - val_accuracy: 0.3571 - lr: 1.3852e-13 - 64ms/epoch - 32ms/step\n",
      "Epoch 238/400\n",
      "2/2 - 0s - loss: 0.0227 - accuracy: 1.0000 - val_loss: 1.4793 - val_accuracy: 0.3571 - lr: 1.2534e-13 - 64ms/epoch - 32ms/step\n",
      "Epoch 239/400\n",
      "2/2 - 0s - loss: 0.0234 - accuracy: 1.0000 - val_loss: 1.4786 - val_accuracy: 0.3571 - lr: 1.1341e-13 - 90ms/epoch - 45ms/step\n",
      "Evaluando modelo: S2SwA\n",
      "Epoch 1/400\n",
      "2/2 - 7s - loss: 2.2278 - accuracy: 0.1509 - val_loss: 2.1633 - val_accuracy: 0.1429 - lr: 0.0010 - 7s/epoch - 3s/step\n",
      "Epoch 2/400\n",
      "2/2 - 0s - loss: 2.1488 - accuracy: 0.2453 - val_loss: 2.1601 - val_accuracy: 0.1429 - lr: 0.0010 - 69ms/epoch - 34ms/step\n",
      "Epoch 3/400\n",
      "2/2 - 0s - loss: 2.1590 - accuracy: 0.1321 - val_loss: 2.1570 - val_accuracy: 0.1429 - lr: 0.0010 - 72ms/epoch - 36ms/step\n",
      "Epoch 4/400\n",
      "2/2 - 0s - loss: 2.1643 - accuracy: 0.1321 - val_loss: 2.1538 - val_accuracy: 0.1429 - lr: 0.0010 - 70ms/epoch - 35ms/step\n",
      "Epoch 5/400\n",
      "2/2 - 0s - loss: 2.1311 - accuracy: 0.2830 - val_loss: 2.1508 - val_accuracy: 0.1429 - lr: 0.0010 - 63ms/epoch - 31ms/step\n",
      "Epoch 6/400\n",
      "2/2 - 0s - loss: 2.0658 - accuracy: 0.1509 - val_loss: 2.1480 - val_accuracy: 0.1429 - lr: 0.0010 - 58ms/epoch - 29ms/step\n",
      "Epoch 7/400\n",
      "2/2 - 0s - loss: 2.0743 - accuracy: 0.2264 - val_loss: 2.1453 - val_accuracy: 0.1429 - lr: 0.0010 - 61ms/epoch - 31ms/step\n",
      "Epoch 8/400\n",
      "2/2 - 0s - loss: 2.0286 - accuracy: 0.2453 - val_loss: 2.1428 - val_accuracy: 0.1429 - lr: 0.0010 - 61ms/epoch - 31ms/step\n",
      "Epoch 9/400\n",
      "2/2 - 0s - loss: 2.0291 - accuracy: 0.2453 - val_loss: 2.1405 - val_accuracy: 0.1429 - lr: 0.0010 - 61ms/epoch - 30ms/step\n",
      "Epoch 10/400\n",
      "2/2 - 0s - loss: 2.0006 - accuracy: 0.2453 - val_loss: 2.1383 - val_accuracy: 0.1429 - lr: 0.0010 - 64ms/epoch - 32ms/step\n",
      "Epoch 11/400\n",
      "2/2 - 0s - loss: 1.9267 - accuracy: 0.3585 - val_loss: 2.1365 - val_accuracy: 0.1429 - lr: 9.0484e-04 - 63ms/epoch - 32ms/step\n",
      "Epoch 12/400\n",
      "2/2 - 0s - loss: 1.9718 - accuracy: 0.3396 - val_loss: 2.1348 - val_accuracy: 0.1429 - lr: 8.1873e-04 - 58ms/epoch - 29ms/step\n",
      "Epoch 13/400\n",
      "2/2 - 0s - loss: 1.8932 - accuracy: 0.2453 - val_loss: 2.1335 - val_accuracy: 0.1429 - lr: 7.4082e-04 - 63ms/epoch - 32ms/step\n",
      "Epoch 14/400\n",
      "2/2 - 0s - loss: 1.8767 - accuracy: 0.3019 - val_loss: 2.1324 - val_accuracy: 0.1429 - lr: 6.7032e-04 - 70ms/epoch - 35ms/step\n",
      "Epoch 15/400\n",
      "2/2 - 0s - loss: 1.8924 - accuracy: 0.2830 - val_loss: 2.1311 - val_accuracy: 0.1429 - lr: 6.0653e-04 - 69ms/epoch - 34ms/step\n",
      "Epoch 16/400\n",
      "2/2 - 0s - loss: 1.8851 - accuracy: 0.2830 - val_loss: 2.1302 - val_accuracy: 0.1429 - lr: 5.4881e-04 - 71ms/epoch - 35ms/step\n",
      "Epoch 17/400\n",
      "2/2 - 0s - loss: 1.8502 - accuracy: 0.3208 - val_loss: 2.1294 - val_accuracy: 0.1429 - lr: 4.9659e-04 - 68ms/epoch - 34ms/step\n",
      "Epoch 18/400\n",
      "2/2 - 0s - loss: 1.8749 - accuracy: 0.1887 - val_loss: 2.1285 - val_accuracy: 0.1429 - lr: 4.4933e-04 - 65ms/epoch - 33ms/step\n",
      "Epoch 19/400\n",
      "2/2 - 0s - loss: 1.8308 - accuracy: 0.3396 - val_loss: 2.1277 - val_accuracy: 0.1429 - lr: 4.0657e-04 - 66ms/epoch - 33ms/step\n",
      "Epoch 20/400\n",
      "2/2 - 0s - loss: 1.8304 - accuracy: 0.3019 - val_loss: 2.1270 - val_accuracy: 0.1429 - lr: 3.6788e-04 - 65ms/epoch - 32ms/step\n",
      "Epoch 21/400\n",
      "2/2 - 0s - loss: 1.8438 - accuracy: 0.3585 - val_loss: 2.1265 - val_accuracy: 0.1429 - lr: 3.3287e-04 - 54ms/epoch - 27ms/step\n",
      "Epoch 22/400\n",
      "2/2 - 0s - loss: 1.8106 - accuracy: 0.3396 - val_loss: 2.1260 - val_accuracy: 0.1429 - lr: 3.0119e-04 - 57ms/epoch - 29ms/step\n",
      "Epoch 23/400\n",
      "2/2 - 0s - loss: 1.8738 - accuracy: 0.3208 - val_loss: 2.1255 - val_accuracy: 0.1429 - lr: 2.7253e-04 - 57ms/epoch - 29ms/step\n",
      "Epoch 24/400\n",
      "2/2 - 0s - loss: 1.7912 - accuracy: 0.2830 - val_loss: 2.1251 - val_accuracy: 0.1429 - lr: 2.4660e-04 - 61ms/epoch - 30ms/step\n",
      "Epoch 25/400\n",
      "2/2 - 0s - loss: 1.7631 - accuracy: 0.3019 - val_loss: 2.1248 - val_accuracy: 0.1429 - lr: 2.2313e-04 - 58ms/epoch - 29ms/step\n",
      "Epoch 26/400\n",
      "2/2 - 0s - loss: 1.8152 - accuracy: 0.3585 - val_loss: 2.1245 - val_accuracy: 0.1429 - lr: 2.0190e-04 - 56ms/epoch - 28ms/step\n",
      "Epoch 27/400\n",
      "2/2 - 0s - loss: 1.7394 - accuracy: 0.3396 - val_loss: 2.1243 - val_accuracy: 0.1429 - lr: 1.8268e-04 - 56ms/epoch - 28ms/step\n",
      "Epoch 28/400\n",
      "2/2 - 0s - loss: 1.7337 - accuracy: 0.2830 - val_loss: 2.1240 - val_accuracy: 0.1429 - lr: 1.6530e-04 - 60ms/epoch - 30ms/step\n",
      "Epoch 29/400\n",
      "2/2 - 0s - loss: 1.8393 - accuracy: 0.2264 - val_loss: 2.1236 - val_accuracy: 0.1429 - lr: 1.4957e-04 - 62ms/epoch - 31ms/step\n",
      "Epoch 30/400\n",
      "2/2 - 0s - loss: 1.7395 - accuracy: 0.3585 - val_loss: 2.1234 - val_accuracy: 0.1429 - lr: 1.3534e-04 - 61ms/epoch - 30ms/step\n",
      "Epoch 31/400\n",
      "2/2 - 0s - loss: 1.7648 - accuracy: 0.2830 - val_loss: 2.1231 - val_accuracy: 0.1429 - lr: 1.2246e-04 - 59ms/epoch - 30ms/step\n",
      "Epoch 32/400\n",
      "2/2 - 0s - loss: 1.7032 - accuracy: 0.3019 - val_loss: 2.1228 - val_accuracy: 0.1429 - lr: 1.1080e-04 - 62ms/epoch - 31ms/step\n",
      "Epoch 33/400\n",
      "2/2 - 0s - loss: 1.6855 - accuracy: 0.3585 - val_loss: 2.1226 - val_accuracy: 0.1429 - lr: 1.0026e-04 - 61ms/epoch - 30ms/step\n",
      "Epoch 34/400\n",
      "2/2 - 0s - loss: 1.7331 - accuracy: 0.3208 - val_loss: 2.1223 - val_accuracy: 0.1429 - lr: 9.0718e-05 - 59ms/epoch - 29ms/step\n",
      "Epoch 35/400\n",
      "2/2 - 0s - loss: 1.7627 - accuracy: 0.3019 - val_loss: 2.1221 - val_accuracy: 0.1429 - lr: 8.2085e-05 - 59ms/epoch - 29ms/step\n",
      "Epoch 36/400\n",
      "2/2 - 0s - loss: 1.6858 - accuracy: 0.3774 - val_loss: 2.1219 - val_accuracy: 0.1429 - lr: 7.4273e-05 - 62ms/epoch - 31ms/step\n",
      "Epoch 37/400\n",
      "2/2 - 0s - loss: 1.7467 - accuracy: 0.3019 - val_loss: 2.1217 - val_accuracy: 0.1429 - lr: 6.7205e-05 - 63ms/epoch - 31ms/step\n",
      "Epoch 38/400\n",
      "2/2 - 0s - loss: 1.6936 - accuracy: 0.3396 - val_loss: 2.1215 - val_accuracy: 0.1429 - lr: 6.0810e-05 - 56ms/epoch - 28ms/step\n",
      "Epoch 39/400\n",
      "2/2 - 0s - loss: 1.7459 - accuracy: 0.3019 - val_loss: 2.1213 - val_accuracy: 0.1429 - lr: 5.5023e-05 - 59ms/epoch - 30ms/step\n",
      "Epoch 40/400\n",
      "2/2 - 0s - loss: 1.6729 - accuracy: 0.3774 - val_loss: 2.1211 - val_accuracy: 0.1429 - lr: 4.9787e-05 - 59ms/epoch - 29ms/step\n",
      "Epoch 41/400\n",
      "2/2 - 0s - loss: 1.6606 - accuracy: 0.3208 - val_loss: 2.1209 - val_accuracy: 0.1429 - lr: 4.5049e-05 - 61ms/epoch - 30ms/step\n",
      "Epoch 42/400\n",
      "2/2 - 0s - loss: 1.7459 - accuracy: 0.3585 - val_loss: 2.1207 - val_accuracy: 0.1429 - lr: 4.0762e-05 - 62ms/epoch - 31ms/step\n",
      "Epoch 43/400\n",
      "2/2 - 0s - loss: 1.7609 - accuracy: 0.2453 - val_loss: 2.1205 - val_accuracy: 0.1429 - lr: 3.6883e-05 - 59ms/epoch - 30ms/step\n",
      "Epoch 44/400\n",
      "2/2 - 0s - loss: 1.7523 - accuracy: 0.3208 - val_loss: 2.1203 - val_accuracy: 0.1429 - lr: 3.3373e-05 - 62ms/epoch - 31ms/step\n",
      "Epoch 45/400\n",
      "2/2 - 0s - loss: 1.6814 - accuracy: 0.3019 - val_loss: 2.1201 - val_accuracy: 0.1429 - lr: 3.0197e-05 - 57ms/epoch - 28ms/step\n",
      "Epoch 46/400\n",
      "2/2 - 0s - loss: 1.7299 - accuracy: 0.2642 - val_loss: 2.1199 - val_accuracy: 0.1429 - lr: 2.7324e-05 - 55ms/epoch - 28ms/step\n",
      "Epoch 47/400\n",
      "2/2 - 0s - loss: 1.6504 - accuracy: 0.3019 - val_loss: 2.1197 - val_accuracy: 0.1429 - lr: 2.4723e-05 - 60ms/epoch - 30ms/step\n",
      "Epoch 48/400\n",
      "2/2 - 0s - loss: 1.7138 - accuracy: 0.3774 - val_loss: 2.1195 - val_accuracy: 0.1429 - lr: 2.2371e-05 - 60ms/epoch - 30ms/step\n",
      "Epoch 49/400\n",
      "2/2 - 0s - loss: 1.8129 - accuracy: 0.3396 - val_loss: 2.1193 - val_accuracy: 0.1429 - lr: 2.0242e-05 - 59ms/epoch - 30ms/step\n",
      "Epoch 50/400\n",
      "2/2 - 0s - loss: 1.7374 - accuracy: 0.3396 - val_loss: 2.1192 - val_accuracy: 0.1429 - lr: 1.8316e-05 - 59ms/epoch - 30ms/step\n",
      "Epoch 51/400\n",
      "2/2 - 0s - loss: 1.6715 - accuracy: 0.2830 - val_loss: 2.1190 - val_accuracy: 0.1429 - lr: 1.6573e-05 - 58ms/epoch - 29ms/step\n",
      "Epoch 52/400\n",
      "2/2 - 0s - loss: 1.7027 - accuracy: 0.4151 - val_loss: 2.1188 - val_accuracy: 0.1429 - lr: 1.4996e-05 - 64ms/epoch - 32ms/step\n",
      "Epoch 53/400\n",
      "2/2 - 0s - loss: 1.7304 - accuracy: 0.3396 - val_loss: 2.1186 - val_accuracy: 0.1429 - lr: 1.3569e-05 - 56ms/epoch - 28ms/step\n",
      "Epoch 54/400\n",
      "2/2 - 0s - loss: 1.7031 - accuracy: 0.2642 - val_loss: 2.1184 - val_accuracy: 0.1429 - lr: 1.2277e-05 - 56ms/epoch - 28ms/step\n",
      "Epoch 55/400\n",
      "2/2 - 0s - loss: 1.7763 - accuracy: 0.2830 - val_loss: 2.1182 - val_accuracy: 0.1429 - lr: 1.1109e-05 - 56ms/epoch - 28ms/step\n",
      "Epoch 56/400\n",
      "2/2 - 0s - loss: 1.7174 - accuracy: 0.2453 - val_loss: 2.1180 - val_accuracy: 0.1429 - lr: 1.0052e-05 - 59ms/epoch - 30ms/step\n",
      "Epoch 57/400\n",
      "2/2 - 0s - loss: 1.7267 - accuracy: 0.3962 - val_loss: 2.1178 - val_accuracy: 0.1429 - lr: 9.0953e-06 - 55ms/epoch - 27ms/step\n",
      "Epoch 58/400\n",
      "2/2 - 0s - loss: 1.6445 - accuracy: 0.4528 - val_loss: 2.1176 - val_accuracy: 0.1429 - lr: 8.2297e-06 - 61ms/epoch - 31ms/step\n",
      "Epoch 59/400\n",
      "2/2 - 0s - loss: 1.6364 - accuracy: 0.3962 - val_loss: 2.1174 - val_accuracy: 0.1429 - lr: 7.4466e-06 - 57ms/epoch - 28ms/step\n",
      "Epoch 60/400\n",
      "2/2 - 0s - loss: 1.6958 - accuracy: 0.3396 - val_loss: 2.1171 - val_accuracy: 0.1429 - lr: 6.7379e-06 - 57ms/epoch - 28ms/step\n",
      "Epoch 61/400\n",
      "2/2 - 0s - loss: 1.7170 - accuracy: 0.3019 - val_loss: 2.1169 - val_accuracy: 0.1429 - lr: 6.0967e-06 - 63ms/epoch - 31ms/step\n",
      "Epoch 62/400\n",
      "2/2 - 0s - loss: 1.6112 - accuracy: 0.3774 - val_loss: 2.1167 - val_accuracy: 0.1429 - lr: 5.5165e-06 - 59ms/epoch - 29ms/step\n",
      "Epoch 63/400\n",
      "2/2 - 0s - loss: 1.7118 - accuracy: 0.3396 - val_loss: 2.1165 - val_accuracy: 0.1429 - lr: 4.9916e-06 - 59ms/epoch - 29ms/step\n",
      "Epoch 64/400\n",
      "2/2 - 0s - loss: 1.6458 - accuracy: 0.3774 - val_loss: 2.1162 - val_accuracy: 0.1429 - lr: 4.5166e-06 - 65ms/epoch - 32ms/step\n",
      "Epoch 65/400\n",
      "2/2 - 0s - loss: 1.7274 - accuracy: 0.2830 - val_loss: 2.1159 - val_accuracy: 0.1429 - lr: 4.0868e-06 - 56ms/epoch - 28ms/step\n",
      "Epoch 66/400\n",
      "2/2 - 0s - loss: 1.7165 - accuracy: 0.3208 - val_loss: 2.1157 - val_accuracy: 0.1429 - lr: 3.6979e-06 - 59ms/epoch - 29ms/step\n",
      "Epoch 67/400\n",
      "2/2 - 0s - loss: 1.7297 - accuracy: 0.4151 - val_loss: 2.1155 - val_accuracy: 0.1429 - lr: 3.3460e-06 - 59ms/epoch - 30ms/step\n",
      "Epoch 68/400\n",
      "2/2 - 0s - loss: 1.6993 - accuracy: 0.3396 - val_loss: 2.1152 - val_accuracy: 0.1429 - lr: 3.0275e-06 - 60ms/epoch - 30ms/step\n",
      "Epoch 69/400\n",
      "2/2 - 0s - loss: 1.6773 - accuracy: 0.3019 - val_loss: 2.1149 - val_accuracy: 0.1429 - lr: 2.7394e-06 - 57ms/epoch - 29ms/step\n",
      "Epoch 70/400\n",
      "2/2 - 0s - loss: 1.6987 - accuracy: 0.2830 - val_loss: 2.1147 - val_accuracy: 0.1429 - lr: 2.4787e-06 - 60ms/epoch - 30ms/step\n",
      "Epoch 71/400\n",
      "2/2 - 0s - loss: 1.7051 - accuracy: 0.3396 - val_loss: 2.1144 - val_accuracy: 0.1429 - lr: 2.2429e-06 - 62ms/epoch - 31ms/step\n",
      "Epoch 72/400\n",
      "2/2 - 0s - loss: 1.7312 - accuracy: 0.3396 - val_loss: 2.1142 - val_accuracy: 0.1429 - lr: 2.0294e-06 - 61ms/epoch - 30ms/step\n",
      "Epoch 73/400\n",
      "2/2 - 0s - loss: 1.6902 - accuracy: 0.3774 - val_loss: 2.1139 - val_accuracy: 0.1429 - lr: 1.8363e-06 - 57ms/epoch - 28ms/step\n",
      "Epoch 74/400\n",
      "2/2 - 0s - loss: 1.7043 - accuracy: 0.3774 - val_loss: 2.1136 - val_accuracy: 0.1429 - lr: 1.6616e-06 - 60ms/epoch - 30ms/step\n",
      "Epoch 75/400\n",
      "2/2 - 0s - loss: 1.6747 - accuracy: 0.4151 - val_loss: 2.1133 - val_accuracy: 0.1429 - lr: 1.5034e-06 - 60ms/epoch - 30ms/step\n",
      "Epoch 76/400\n",
      "2/2 - 0s - loss: 1.6832 - accuracy: 0.3396 - val_loss: 2.1131 - val_accuracy: 0.1429 - lr: 1.3604e-06 - 56ms/epoch - 28ms/step\n",
      "Epoch 77/400\n",
      "2/2 - 0s - loss: 1.7031 - accuracy: 0.4151 - val_loss: 2.1127 - val_accuracy: 0.1429 - lr: 1.2309e-06 - 64ms/epoch - 32ms/step\n",
      "Epoch 78/400\n",
      "2/2 - 0s - loss: 1.6843 - accuracy: 0.3019 - val_loss: 2.1124 - val_accuracy: 0.1429 - lr: 1.1138e-06 - 62ms/epoch - 31ms/step\n",
      "Epoch 79/400\n",
      "2/2 - 0s - loss: 1.6963 - accuracy: 0.3962 - val_loss: 2.1121 - val_accuracy: 0.1429 - lr: 1.0078e-06 - 62ms/epoch - 31ms/step\n",
      "Epoch 80/400\n",
      "2/2 - 0s - loss: 1.6420 - accuracy: 0.3962 - val_loss: 2.1117 - val_accuracy: 0.1429 - lr: 9.1188e-07 - 59ms/epoch - 30ms/step\n",
      "Epoch 81/400\n",
      "2/2 - 0s - loss: 1.7520 - accuracy: 0.2830 - val_loss: 2.1114 - val_accuracy: 0.1429 - lr: 8.2510e-07 - 57ms/epoch - 29ms/step\n",
      "Epoch 82/400\n",
      "2/2 - 0s - loss: 1.7161 - accuracy: 0.3585 - val_loss: 2.1111 - val_accuracy: 0.1429 - lr: 7.4658e-07 - 61ms/epoch - 30ms/step\n",
      "Epoch 83/400\n",
      "2/2 - 0s - loss: 1.7027 - accuracy: 0.3019 - val_loss: 2.1107 - val_accuracy: 0.1429 - lr: 6.7554e-07 - 57ms/epoch - 29ms/step\n",
      "Epoch 84/400\n",
      "2/2 - 0s - loss: 1.6123 - accuracy: 0.4717 - val_loss: 2.1104 - val_accuracy: 0.1429 - lr: 6.1125e-07 - 60ms/epoch - 30ms/step\n",
      "Epoch 85/400\n",
      "2/2 - 0s - loss: 1.6973 - accuracy: 0.3396 - val_loss: 2.1100 - val_accuracy: 0.1429 - lr: 5.5308e-07 - 58ms/epoch - 29ms/step\n",
      "Epoch 86/400\n",
      "2/2 - 0s - loss: 1.7439 - accuracy: 0.2453 - val_loss: 2.1097 - val_accuracy: 0.1429 - lr: 5.0045e-07 - 58ms/epoch - 29ms/step\n",
      "Epoch 87/400\n",
      "2/2 - 0s - loss: 1.6739 - accuracy: 0.3962 - val_loss: 2.1092 - val_accuracy: 0.1429 - lr: 4.5283e-07 - 58ms/epoch - 29ms/step\n",
      "Epoch 88/400\n",
      "2/2 - 0s - loss: 1.7824 - accuracy: 0.2830 - val_loss: 2.1088 - val_accuracy: 0.1429 - lr: 4.0973e-07 - 58ms/epoch - 29ms/step\n",
      "Epoch 89/400\n",
      "2/2 - 0s - loss: 1.6537 - accuracy: 0.4340 - val_loss: 2.1085 - val_accuracy: 0.1429 - lr: 3.7074e-07 - 62ms/epoch - 31ms/step\n",
      "Epoch 90/400\n",
      "2/2 - 0s - loss: 1.6906 - accuracy: 0.2642 - val_loss: 2.1081 - val_accuracy: 0.1429 - lr: 3.3546e-07 - 58ms/epoch - 29ms/step\n",
      "Epoch 91/400\n",
      "2/2 - 0s - loss: 1.7061 - accuracy: 0.3396 - val_loss: 2.1076 - val_accuracy: 0.1429 - lr: 3.0354e-07 - 60ms/epoch - 30ms/step\n",
      "Epoch 92/400\n",
      "2/2 - 0s - loss: 1.6324 - accuracy: 0.4151 - val_loss: 2.1072 - val_accuracy: 0.1429 - lr: 2.7465e-07 - 77ms/epoch - 38ms/step\n",
      "Epoch 93/400\n",
      "2/2 - 0s - loss: 1.6817 - accuracy: 0.3585 - val_loss: 2.1068 - val_accuracy: 0.1429 - lr: 2.4852e-07 - 75ms/epoch - 37ms/step\n",
      "Epoch 94/400\n",
      "2/2 - 0s - loss: 1.7107 - accuracy: 0.2642 - val_loss: 2.1063 - val_accuracy: 0.1429 - lr: 2.2487e-07 - 67ms/epoch - 33ms/step\n",
      "Epoch 95/400\n",
      "2/2 - 0s - loss: 1.7272 - accuracy: 0.3585 - val_loss: 2.1059 - val_accuracy: 0.1429 - lr: 2.0347e-07 - 61ms/epoch - 30ms/step\n",
      "Epoch 96/400\n",
      "2/2 - 0s - loss: 1.7082 - accuracy: 0.2830 - val_loss: 2.1055 - val_accuracy: 0.1429 - lr: 1.8410e-07 - 59ms/epoch - 29ms/step\n",
      "Epoch 97/400\n",
      "2/2 - 0s - loss: 1.6504 - accuracy: 0.3962 - val_loss: 2.1049 - val_accuracy: 0.1429 - lr: 1.6659e-07 - 61ms/epoch - 31ms/step\n",
      "Epoch 98/400\n",
      "2/2 - 0s - loss: 1.7537 - accuracy: 0.3396 - val_loss: 2.1044 - val_accuracy: 0.1429 - lr: 1.5073e-07 - 60ms/epoch - 30ms/step\n",
      "Epoch 99/400\n",
      "2/2 - 0s - loss: 1.7157 - accuracy: 0.4528 - val_loss: 2.1040 - val_accuracy: 0.1429 - lr: 1.3639e-07 - 57ms/epoch - 28ms/step\n",
      "Epoch 100/400\n",
      "2/2 - 0s - loss: 1.7216 - accuracy: 0.3396 - val_loss: 2.1034 - val_accuracy: 0.1429 - lr: 1.2341e-07 - 60ms/epoch - 30ms/step\n",
      "Epoch 101/400\n",
      "2/2 - 0s - loss: 1.7017 - accuracy: 0.2453 - val_loss: 2.1030 - val_accuracy: 0.1429 - lr: 1.1167e-07 - 59ms/epoch - 29ms/step\n",
      "Epoch 102/400\n",
      "2/2 - 0s - loss: 1.7414 - accuracy: 0.3585 - val_loss: 2.1025 - val_accuracy: 0.1429 - lr: 1.0104e-07 - 61ms/epoch - 30ms/step\n",
      "Epoch 103/400\n",
      "2/2 - 0s - loss: 1.7030 - accuracy: 0.3585 - val_loss: 2.1020 - val_accuracy: 0.1429 - lr: 9.1424e-08 - 52ms/epoch - 26ms/step\n",
      "Epoch 104/400\n",
      "2/2 - 0s - loss: 1.7043 - accuracy: 0.2264 - val_loss: 2.1014 - val_accuracy: 0.1429 - lr: 8.2724e-08 - 54ms/epoch - 27ms/step\n",
      "Epoch 105/400\n",
      "2/2 - 0s - loss: 1.6804 - accuracy: 0.3585 - val_loss: 2.1009 - val_accuracy: 0.1429 - lr: 7.4851e-08 - 59ms/epoch - 30ms/step\n",
      "Epoch 106/400\n",
      "2/2 - 0s - loss: 1.6370 - accuracy: 0.4151 - val_loss: 2.1003 - val_accuracy: 0.1429 - lr: 6.7728e-08 - 56ms/epoch - 28ms/step\n",
      "Epoch 107/400\n",
      "2/2 - 0s - loss: 1.6668 - accuracy: 0.3774 - val_loss: 2.0998 - val_accuracy: 0.1429 - lr: 6.1283e-08 - 59ms/epoch - 30ms/step\n",
      "Epoch 108/400\n",
      "2/2 - 0s - loss: 1.7709 - accuracy: 0.3019 - val_loss: 2.0993 - val_accuracy: 0.1429 - lr: 5.5451e-08 - 55ms/epoch - 28ms/step\n",
      "Epoch 109/400\n",
      "2/2 - 0s - loss: 1.6866 - accuracy: 0.4151 - val_loss: 2.0987 - val_accuracy: 0.1429 - lr: 5.0174e-08 - 55ms/epoch - 27ms/step\n",
      "Epoch 110/400\n",
      "2/2 - 0s - loss: 1.7102 - accuracy: 0.3774 - val_loss: 2.0982 - val_accuracy: 0.1429 - lr: 4.5400e-08 - 56ms/epoch - 28ms/step\n",
      "Epoch 111/400\n",
      "2/2 - 0s - loss: 1.7053 - accuracy: 0.3019 - val_loss: 2.0976 - val_accuracy: 0.1429 - lr: 4.1079e-08 - 57ms/epoch - 28ms/step\n",
      "Epoch 112/400\n",
      "2/2 - 0s - loss: 1.7025 - accuracy: 0.3774 - val_loss: 2.0971 - val_accuracy: 0.1429 - lr: 3.7170e-08 - 53ms/epoch - 26ms/step\n",
      "Epoch 113/400\n",
      "2/2 - 0s - loss: 1.7095 - accuracy: 0.3396 - val_loss: 2.0965 - val_accuracy: 0.1429 - lr: 3.3633e-08 - 56ms/epoch - 28ms/step\n",
      "Epoch 114/400\n",
      "2/2 - 0s - loss: 1.6760 - accuracy: 0.3396 - val_loss: 2.0959 - val_accuracy: 0.1429 - lr: 3.0432e-08 - 58ms/epoch - 29ms/step\n",
      "Epoch 115/400\n",
      "2/2 - 0s - loss: 1.7479 - accuracy: 0.2453 - val_loss: 2.0953 - val_accuracy: 0.1429 - lr: 2.7536e-08 - 80ms/epoch - 40ms/step\n",
      "Epoch 116/400\n",
      "2/2 - 0s - loss: 1.7263 - accuracy: 0.3019 - val_loss: 2.0947 - val_accuracy: 0.1429 - lr: 2.4916e-08 - 107ms/epoch - 54ms/step\n",
      "Epoch 117/400\n",
      "2/2 - 0s - loss: 1.7274 - accuracy: 0.2830 - val_loss: 2.0940 - val_accuracy: 0.1429 - lr: 2.2545e-08 - 99ms/epoch - 49ms/step\n",
      "Epoch 118/400\n",
      "2/2 - 0s - loss: 1.6862 - accuracy: 0.3774 - val_loss: 2.0933 - val_accuracy: 0.1429 - lr: 2.0399e-08 - 75ms/epoch - 37ms/step\n",
      "Epoch 119/400\n",
      "2/2 - 0s - loss: 1.7186 - accuracy: 0.2830 - val_loss: 2.0927 - val_accuracy: 0.1429 - lr: 1.8458e-08 - 54ms/epoch - 27ms/step\n",
      "Epoch 120/400\n",
      "2/2 - 0s - loss: 1.6633 - accuracy: 0.3774 - val_loss: 2.0922 - val_accuracy: 0.1429 - lr: 1.6702e-08 - 60ms/epoch - 30ms/step\n",
      "Epoch 121/400\n",
      "2/2 - 0s - loss: 1.6652 - accuracy: 0.3208 - val_loss: 2.0916 - val_accuracy: 0.1429 - lr: 1.5112e-08 - 56ms/epoch - 28ms/step\n",
      "Epoch 122/400\n",
      "2/2 - 0s - loss: 1.7291 - accuracy: 0.3774 - val_loss: 2.0909 - val_accuracy: 0.1429 - lr: 1.3674e-08 - 55ms/epoch - 28ms/step\n",
      "Epoch 123/400\n",
      "2/2 - 0s - loss: 1.6404 - accuracy: 0.3774 - val_loss: 2.0902 - val_accuracy: 0.1429 - lr: 1.2373e-08 - 69ms/epoch - 34ms/step\n",
      "Epoch 124/400\n",
      "2/2 - 0s - loss: 1.6803 - accuracy: 0.3396 - val_loss: 2.0895 - val_accuracy: 0.1429 - lr: 1.1195e-08 - 59ms/epoch - 29ms/step\n",
      "Epoch 125/400\n",
      "2/2 - 0s - loss: 1.6589 - accuracy: 0.3962 - val_loss: 2.0887 - val_accuracy: 0.1429 - lr: 1.0130e-08 - 74ms/epoch - 37ms/step\n",
      "Epoch 126/400\n",
      "2/2 - 0s - loss: 1.7289 - accuracy: 0.3019 - val_loss: 2.0880 - val_accuracy: 0.1429 - lr: 9.1660e-09 - 63ms/epoch - 32ms/step\n",
      "Epoch 127/400\n",
      "2/2 - 0s - loss: 1.7406 - accuracy: 0.3208 - val_loss: 2.0873 - val_accuracy: 0.1429 - lr: 8.2938e-09 - 65ms/epoch - 32ms/step\n",
      "Epoch 128/400\n",
      "2/2 - 0s - loss: 1.6992 - accuracy: 0.3962 - val_loss: 2.0866 - val_accuracy: 0.1429 - lr: 7.5045e-09 - 72ms/epoch - 36ms/step\n",
      "Epoch 129/400\n",
      "2/2 - 0s - loss: 1.6942 - accuracy: 0.4151 - val_loss: 2.0858 - val_accuracy: 0.1429 - lr: 6.7904e-09 - 62ms/epoch - 31ms/step\n",
      "Epoch 130/400\n",
      "2/2 - 0s - loss: 1.7446 - accuracy: 0.2830 - val_loss: 2.0850 - val_accuracy: 0.1429 - lr: 6.1442e-09 - 63ms/epoch - 31ms/step\n",
      "Epoch 131/400\n",
      "2/2 - 0s - loss: 1.6908 - accuracy: 0.3208 - val_loss: 2.0842 - val_accuracy: 0.1429 - lr: 5.5595e-09 - 68ms/epoch - 34ms/step\n",
      "Epoch 132/400\n",
      "2/2 - 0s - loss: 1.7506 - accuracy: 0.2830 - val_loss: 2.0835 - val_accuracy: 0.1429 - lr: 5.0304e-09 - 58ms/epoch - 29ms/step\n",
      "Epoch 133/400\n",
      "2/2 - 0s - loss: 1.7427 - accuracy: 0.2453 - val_loss: 2.0827 - val_accuracy: 0.1429 - lr: 4.5517e-09 - 62ms/epoch - 31ms/step\n",
      "Epoch 134/400\n",
      "2/2 - 0s - loss: 1.7254 - accuracy: 0.3396 - val_loss: 2.0820 - val_accuracy: 0.1429 - lr: 4.1186e-09 - 59ms/epoch - 29ms/step\n",
      "Epoch 135/400\n",
      "2/2 - 0s - loss: 1.6222 - accuracy: 0.4340 - val_loss: 2.0812 - val_accuracy: 0.1429 - lr: 3.7266e-09 - 59ms/epoch - 30ms/step\n",
      "Epoch 136/400\n",
      "2/2 - 0s - loss: 1.6722 - accuracy: 0.3774 - val_loss: 2.0803 - val_accuracy: 0.1429 - lr: 3.3720e-09 - 62ms/epoch - 31ms/step\n",
      "Epoch 137/400\n",
      "2/2 - 0s - loss: 1.6585 - accuracy: 0.4717 - val_loss: 2.0795 - val_accuracy: 0.1429 - lr: 3.0511e-09 - 62ms/epoch - 31ms/step\n",
      "Epoch 138/400\n",
      "2/2 - 0s - loss: 1.7126 - accuracy: 0.2453 - val_loss: 2.0786 - val_accuracy: 0.1429 - lr: 2.7608e-09 - 60ms/epoch - 30ms/step\n",
      "Epoch 139/400\n",
      "2/2 - 0s - loss: 1.6759 - accuracy: 0.3208 - val_loss: 2.0778 - val_accuracy: 0.1429 - lr: 2.4980e-09 - 66ms/epoch - 33ms/step\n",
      "Epoch 140/400\n",
      "2/2 - 0s - loss: 1.7101 - accuracy: 0.3585 - val_loss: 2.0770 - val_accuracy: 0.1429 - lr: 2.2603e-09 - 61ms/epoch - 30ms/step\n",
      "Epoch 141/400\n",
      "2/2 - 0s - loss: 1.7013 - accuracy: 0.3774 - val_loss: 2.0762 - val_accuracy: 0.1429 - lr: 2.0452e-09 - 58ms/epoch - 29ms/step\n",
      "Epoch 142/400\n",
      "2/2 - 0s - loss: 1.7044 - accuracy: 0.3208 - val_loss: 2.0754 - val_accuracy: 0.1429 - lr: 1.8506e-09 - 62ms/epoch - 31ms/step\n",
      "Epoch 143/400\n",
      "2/2 - 0s - loss: 1.6533 - accuracy: 0.4906 - val_loss: 2.0746 - val_accuracy: 0.1429 - lr: 1.6745e-09 - 58ms/epoch - 29ms/step\n",
      "Epoch 144/400\n",
      "2/2 - 0s - loss: 1.7478 - accuracy: 0.3396 - val_loss: 2.0738 - val_accuracy: 0.1429 - lr: 1.5151e-09 - 60ms/epoch - 30ms/step\n",
      "Epoch 145/400\n",
      "2/2 - 0s - loss: 1.7261 - accuracy: 0.3585 - val_loss: 2.0730 - val_accuracy: 0.1429 - lr: 1.3709e-09 - 60ms/epoch - 30ms/step\n",
      "Epoch 146/400\n",
      "2/2 - 0s - loss: 1.7094 - accuracy: 0.2642 - val_loss: 2.0721 - val_accuracy: 0.1429 - lr: 1.2405e-09 - 59ms/epoch - 29ms/step\n",
      "Epoch 147/400\n",
      "2/2 - 0s - loss: 1.7191 - accuracy: 0.3019 - val_loss: 2.0713 - val_accuracy: 0.1429 - lr: 1.1224e-09 - 60ms/epoch - 30ms/step\n",
      "Epoch 148/400\n",
      "2/2 - 0s - loss: 1.6797 - accuracy: 0.3019 - val_loss: 2.0705 - val_accuracy: 0.1429 - lr: 1.0156e-09 - 60ms/epoch - 30ms/step\n",
      "Epoch 149/400\n",
      "2/2 - 0s - loss: 1.6831 - accuracy: 0.3774 - val_loss: 2.0696 - val_accuracy: 0.1429 - lr: 9.1897e-10 - 61ms/epoch - 30ms/step\n",
      "Epoch 150/400\n",
      "2/2 - 0s - loss: 1.7004 - accuracy: 0.3585 - val_loss: 2.0688 - val_accuracy: 0.1429 - lr: 8.3152e-10 - 58ms/epoch - 29ms/step\n",
      "Epoch 151/400\n",
      "2/2 - 0s - loss: 1.6945 - accuracy: 0.4340 - val_loss: 2.0679 - val_accuracy: 0.1429 - lr: 7.5239e-10 - 60ms/epoch - 30ms/step\n",
      "Epoch 152/400\n",
      "2/2 - 0s - loss: 1.7232 - accuracy: 0.3208 - val_loss: 2.0670 - val_accuracy: 0.1429 - lr: 6.8079e-10 - 55ms/epoch - 28ms/step\n",
      "Epoch 153/400\n",
      "2/2 - 0s - loss: 1.7615 - accuracy: 0.3208 - val_loss: 2.0661 - val_accuracy: 0.1429 - lr: 6.1601e-10 - 60ms/epoch - 30ms/step\n",
      "Epoch 154/400\n",
      "2/2 - 0s - loss: 1.7101 - accuracy: 0.2830 - val_loss: 2.0652 - val_accuracy: 0.1429 - lr: 5.5739e-10 - 62ms/epoch - 31ms/step\n",
      "Epoch 155/400\n",
      "2/2 - 0s - loss: 1.7136 - accuracy: 0.3585 - val_loss: 2.0644 - val_accuracy: 0.1429 - lr: 5.0434e-10 - 67ms/epoch - 34ms/step\n",
      "Epoch 156/400\n",
      "2/2 - 0s - loss: 1.7486 - accuracy: 0.2453 - val_loss: 2.0635 - val_accuracy: 0.1429 - lr: 4.5635e-10 - 65ms/epoch - 32ms/step\n",
      "Epoch 157/400\n",
      "2/2 - 0s - loss: 1.6719 - accuracy: 0.3774 - val_loss: 2.0627 - val_accuracy: 0.1429 - lr: 4.1292e-10 - 66ms/epoch - 33ms/step\n",
      "Epoch 158/400\n",
      "2/2 - 0s - loss: 1.6952 - accuracy: 0.3396 - val_loss: 2.0618 - val_accuracy: 0.1429 - lr: 3.7363e-10 - 66ms/epoch - 33ms/step\n",
      "Epoch 159/400\n",
      "2/2 - 0s - loss: 1.6363 - accuracy: 0.3208 - val_loss: 2.0608 - val_accuracy: 0.1429 - lr: 3.3807e-10 - 63ms/epoch - 32ms/step\n",
      "Epoch 160/400\n",
      "2/2 - 0s - loss: 1.7119 - accuracy: 0.4340 - val_loss: 2.0598 - val_accuracy: 0.1429 - lr: 3.0590e-10 - 66ms/epoch - 33ms/step\n",
      "Epoch 161/400\n",
      "2/2 - 0s - loss: 1.7137 - accuracy: 0.3585 - val_loss: 2.0590 - val_accuracy: 0.1429 - lr: 2.7679e-10 - 65ms/epoch - 32ms/step\n",
      "Epoch 162/400\n",
      "2/2 - 0s - loss: 1.7279 - accuracy: 0.3019 - val_loss: 2.0580 - val_accuracy: 0.1429 - lr: 2.5045e-10 - 61ms/epoch - 31ms/step\n",
      "Epoch 163/400\n",
      "2/2 - 0s - loss: 1.7169 - accuracy: 0.3019 - val_loss: 2.0571 - val_accuracy: 0.1429 - lr: 2.2662e-10 - 63ms/epoch - 31ms/step\n",
      "Epoch 164/400\n",
      "2/2 - 0s - loss: 1.6770 - accuracy: 0.3208 - val_loss: 2.0561 - val_accuracy: 0.1429 - lr: 2.0505e-10 - 58ms/epoch - 29ms/step\n",
      "Epoch 165/400\n",
      "2/2 - 0s - loss: 1.7314 - accuracy: 0.2075 - val_loss: 2.0553 - val_accuracy: 0.1429 - lr: 1.8554e-10 - 59ms/epoch - 30ms/step\n",
      "Epoch 166/400\n",
      "2/2 - 0s - loss: 1.6249 - accuracy: 0.3774 - val_loss: 2.0543 - val_accuracy: 0.1429 - lr: 1.6788e-10 - 58ms/epoch - 29ms/step\n",
      "Epoch 167/400\n",
      "2/2 - 0s - loss: 1.6947 - accuracy: 0.4340 - val_loss: 2.0534 - val_accuracy: 0.1429 - lr: 1.5191e-10 - 58ms/epoch - 29ms/step\n",
      "Epoch 168/400\n",
      "2/2 - 0s - loss: 1.7080 - accuracy: 0.3962 - val_loss: 2.0525 - val_accuracy: 0.1429 - lr: 1.3745e-10 - 63ms/epoch - 31ms/step\n",
      "Epoch 169/400\n",
      "2/2 - 0s - loss: 1.7544 - accuracy: 0.2264 - val_loss: 2.0515 - val_accuracy: 0.2143 - lr: 1.2437e-10 - 66ms/epoch - 33ms/step\n",
      "Epoch 170/400\n",
      "2/2 - 0s - loss: 1.6670 - accuracy: 0.3585 - val_loss: 2.0506 - val_accuracy: 0.2143 - lr: 1.1253e-10 - 68ms/epoch - 34ms/step\n",
      "Epoch 171/400\n",
      "2/2 - 0s - loss: 1.6952 - accuracy: 0.3962 - val_loss: 2.0496 - val_accuracy: 0.2143 - lr: 1.0183e-10 - 60ms/epoch - 30ms/step\n",
      "Epoch 172/400\n",
      "2/2 - 0s - loss: 1.7245 - accuracy: 0.3962 - val_loss: 2.0487 - val_accuracy: 0.2143 - lr: 9.2135e-11 - 62ms/epoch - 31ms/step\n",
      "Epoch 173/400\n",
      "2/2 - 0s - loss: 1.6507 - accuracy: 0.3774 - val_loss: 2.0478 - val_accuracy: 0.2143 - lr: 8.3367e-11 - 64ms/epoch - 32ms/step\n",
      "Epoch 174/400\n",
      "2/2 - 0s - loss: 1.6792 - accuracy: 0.3208 - val_loss: 2.0469 - val_accuracy: 0.2143 - lr: 7.5434e-11 - 57ms/epoch - 28ms/step\n",
      "Epoch 175/400\n",
      "2/2 - 0s - loss: 1.7260 - accuracy: 0.3208 - val_loss: 2.0459 - val_accuracy: 0.2143 - lr: 6.8255e-11 - 64ms/epoch - 32ms/step\n",
      "Epoch 176/400\n",
      "2/2 - 0s - loss: 1.7223 - accuracy: 0.2642 - val_loss: 2.0449 - val_accuracy: 0.2143 - lr: 6.1760e-11 - 55ms/epoch - 27ms/step\n",
      "Epoch 177/400\n",
      "2/2 - 0s - loss: 1.7109 - accuracy: 0.3019 - val_loss: 2.0440 - val_accuracy: 0.2143 - lr: 5.5883e-11 - 55ms/epoch - 27ms/step\n",
      "Epoch 178/400\n",
      "2/2 - 0s - loss: 1.6716 - accuracy: 0.4528 - val_loss: 2.0431 - val_accuracy: 0.2143 - lr: 5.0565e-11 - 55ms/epoch - 28ms/step\n",
      "Epoch 179/400\n",
      "2/2 - 0s - loss: 1.6799 - accuracy: 0.2830 - val_loss: 2.0421 - val_accuracy: 0.2143 - lr: 4.5753e-11 - 58ms/epoch - 29ms/step\n",
      "Epoch 180/400\n",
      "2/2 - 0s - loss: 1.7077 - accuracy: 0.3774 - val_loss: 2.0412 - val_accuracy: 0.2143 - lr: 4.1399e-11 - 62ms/epoch - 31ms/step\n",
      "Epoch 181/400\n",
      "2/2 - 0s - loss: 1.6417 - accuracy: 0.3396 - val_loss: 2.0402 - val_accuracy: 0.2143 - lr: 3.7459e-11 - 60ms/epoch - 30ms/step\n",
      "Epoch 182/400\n",
      "2/2 - 0s - loss: 1.6876 - accuracy: 0.3774 - val_loss: 2.0393 - val_accuracy: 0.2143 - lr: 3.3895e-11 - 59ms/epoch - 30ms/step\n",
      "Epoch 183/400\n",
      "2/2 - 0s - loss: 1.6593 - accuracy: 0.4151 - val_loss: 2.0383 - val_accuracy: 0.2143 - lr: 3.0669e-11 - 63ms/epoch - 31ms/step\n",
      "Epoch 184/400\n",
      "2/2 - 0s - loss: 1.6037 - accuracy: 0.3962 - val_loss: 2.0373 - val_accuracy: 0.2857 - lr: 2.7751e-11 - 60ms/epoch - 30ms/step\n",
      "Epoch 185/400\n",
      "2/2 - 0s - loss: 1.7089 - accuracy: 0.2453 - val_loss: 2.0363 - val_accuracy: 0.2857 - lr: 2.5110e-11 - 62ms/epoch - 31ms/step\n",
      "Epoch 186/400\n",
      "2/2 - 0s - loss: 1.7072 - accuracy: 0.3019 - val_loss: 2.0353 - val_accuracy: 0.2857 - lr: 2.2720e-11 - 57ms/epoch - 29ms/step\n",
      "Epoch 187/400\n",
      "2/2 - 0s - loss: 1.7060 - accuracy: 0.3208 - val_loss: 2.0343 - val_accuracy: 0.2857 - lr: 2.0558e-11 - 59ms/epoch - 29ms/step\n",
      "Epoch 188/400\n",
      "2/2 - 0s - loss: 1.6725 - accuracy: 0.3585 - val_loss: 2.0333 - val_accuracy: 0.2857 - lr: 1.8602e-11 - 61ms/epoch - 31ms/step\n",
      "Epoch 189/400\n",
      "2/2 - 0s - loss: 1.6989 - accuracy: 0.3208 - val_loss: 2.0323 - val_accuracy: 0.2857 - lr: 1.6832e-11 - 65ms/epoch - 33ms/step\n",
      "Epoch 190/400\n",
      "2/2 - 0s - loss: 1.7057 - accuracy: 0.2453 - val_loss: 2.0313 - val_accuracy: 0.2857 - lr: 1.5230e-11 - 57ms/epoch - 29ms/step\n",
      "Epoch 191/400\n",
      "2/2 - 0s - loss: 1.6965 - accuracy: 0.3396 - val_loss: 2.0303 - val_accuracy: 0.2857 - lr: 1.3781e-11 - 59ms/epoch - 30ms/step\n",
      "Epoch 192/400\n",
      "2/2 - 0s - loss: 1.7075 - accuracy: 0.2642 - val_loss: 2.0292 - val_accuracy: 0.2857 - lr: 1.2469e-11 - 68ms/epoch - 34ms/step\n",
      "Epoch 193/400\n",
      "2/2 - 0s - loss: 1.6516 - accuracy: 0.3962 - val_loss: 2.0282 - val_accuracy: 0.2857 - lr: 1.1283e-11 - 60ms/epoch - 30ms/step\n",
      "Epoch 194/400\n",
      "2/2 - 0s - loss: 1.7232 - accuracy: 0.2830 - val_loss: 2.0273 - val_accuracy: 0.2857 - lr: 1.0209e-11 - 62ms/epoch - 31ms/step\n",
      "Epoch 195/400\n",
      "2/2 - 0s - loss: 1.7053 - accuracy: 0.3774 - val_loss: 2.0261 - val_accuracy: 0.2857 - lr: 9.2374e-12 - 65ms/epoch - 33ms/step\n",
      "Epoch 196/400\n",
      "2/2 - 0s - loss: 1.6403 - accuracy: 0.4717 - val_loss: 2.0251 - val_accuracy: 0.2857 - lr: 8.3583e-12 - 59ms/epoch - 29ms/step\n",
      "Epoch 197/400\n",
      "2/2 - 0s - loss: 1.6840 - accuracy: 0.3208 - val_loss: 2.0240 - val_accuracy: 0.2857 - lr: 7.5629e-12 - 56ms/epoch - 28ms/step\n",
      "Epoch 198/400\n",
      "2/2 - 0s - loss: 1.6724 - accuracy: 0.3208 - val_loss: 2.0229 - val_accuracy: 0.2857 - lr: 6.8432e-12 - 60ms/epoch - 30ms/step\n",
      "Epoch 199/400\n",
      "2/2 - 0s - loss: 1.6909 - accuracy: 0.3019 - val_loss: 2.0218 - val_accuracy: 0.2857 - lr: 6.1920e-12 - 57ms/epoch - 28ms/step\n",
      "Epoch 200/400\n",
      "2/2 - 0s - loss: 1.6605 - accuracy: 0.3774 - val_loss: 2.0207 - val_accuracy: 0.2857 - lr: 5.6027e-12 - 65ms/epoch - 33ms/step\n",
      "Epoch 201/400\n",
      "2/2 - 0s - loss: 1.6800 - accuracy: 0.2830 - val_loss: 2.0197 - val_accuracy: 0.2857 - lr: 5.0696e-12 - 71ms/epoch - 36ms/step\n",
      "Epoch 202/400\n",
      "2/2 - 0s - loss: 1.6682 - accuracy: 0.3774 - val_loss: 2.0186 - val_accuracy: 0.2857 - lr: 4.5871e-12 - 57ms/epoch - 28ms/step\n",
      "Epoch 203/400\n",
      "2/2 - 0s - loss: 1.6991 - accuracy: 0.3208 - val_loss: 2.0174 - val_accuracy: 0.2857 - lr: 4.1506e-12 - 56ms/epoch - 28ms/step\n",
      "Epoch 204/400\n",
      "2/2 - 0s - loss: 1.6744 - accuracy: 0.3962 - val_loss: 2.0163 - val_accuracy: 0.2857 - lr: 3.7556e-12 - 57ms/epoch - 29ms/step\n",
      "Epoch 205/400\n",
      "2/2 - 0s - loss: 1.6965 - accuracy: 0.2830 - val_loss: 2.0152 - val_accuracy: 0.2857 - lr: 3.3982e-12 - 59ms/epoch - 30ms/step\n",
      "Epoch 206/400\n",
      "2/2 - 0s - loss: 1.7580 - accuracy: 0.3019 - val_loss: 2.0141 - val_accuracy: 0.2857 - lr: 3.0748e-12 - 58ms/epoch - 29ms/step\n",
      "Epoch 207/400\n",
      "2/2 - 0s - loss: 1.6953 - accuracy: 0.3019 - val_loss: 2.0130 - val_accuracy: 0.2857 - lr: 2.7822e-12 - 55ms/epoch - 28ms/step\n",
      "Epoch 208/400\n",
      "2/2 - 0s - loss: 1.6826 - accuracy: 0.3396 - val_loss: 2.0120 - val_accuracy: 0.2857 - lr: 2.5175e-12 - 59ms/epoch - 30ms/step\n",
      "Epoch 209/400\n",
      "2/2 - 0s - loss: 1.6767 - accuracy: 0.3019 - val_loss: 2.0108 - val_accuracy: 0.2857 - lr: 2.2779e-12 - 63ms/epoch - 31ms/step\n",
      "Epoch 210/400\n",
      "2/2 - 0s - loss: 1.6772 - accuracy: 0.3019 - val_loss: 2.0098 - val_accuracy: 0.2857 - lr: 2.0611e-12 - 59ms/epoch - 29ms/step\n",
      "Epoch 211/400\n",
      "2/2 - 0s - loss: 1.7315 - accuracy: 0.2830 - val_loss: 2.0087 - val_accuracy: 0.2857 - lr: 1.8650e-12 - 57ms/epoch - 28ms/step\n",
      "Epoch 212/400\n",
      "2/2 - 0s - loss: 1.6383 - accuracy: 0.4151 - val_loss: 2.0075 - val_accuracy: 0.2857 - lr: 1.6875e-12 - 59ms/epoch - 29ms/step\n",
      "Epoch 213/400\n",
      "2/2 - 0s - loss: 1.6895 - accuracy: 0.2830 - val_loss: 2.0063 - val_accuracy: 0.2857 - lr: 1.5269e-12 - 57ms/epoch - 28ms/step\n",
      "Epoch 214/400\n",
      "2/2 - 0s - loss: 1.6293 - accuracy: 0.3396 - val_loss: 2.0052 - val_accuracy: 0.2857 - lr: 1.3816e-12 - 55ms/epoch - 28ms/step\n",
      "Epoch 215/400\n",
      "2/2 - 0s - loss: 1.6892 - accuracy: 0.2453 - val_loss: 2.0040 - val_accuracy: 0.2857 - lr: 1.2501e-12 - 57ms/epoch - 28ms/step\n",
      "Epoch 216/400\n",
      "2/2 - 0s - loss: 1.6772 - accuracy: 0.2830 - val_loss: 2.0029 - val_accuracy: 0.2857 - lr: 1.1312e-12 - 57ms/epoch - 29ms/step\n",
      "Epoch 217/400\n",
      "2/2 - 0s - loss: 1.7351 - accuracy: 0.1698 - val_loss: 2.0018 - val_accuracy: 0.2857 - lr: 1.0235e-12 - 56ms/epoch - 28ms/step\n",
      "Epoch 218/400\n",
      "2/2 - 0s - loss: 1.6933 - accuracy: 0.2642 - val_loss: 2.0006 - val_accuracy: 0.2857 - lr: 9.2613e-13 - 58ms/epoch - 29ms/step\n",
      "Epoch 219/400\n",
      "2/2 - 0s - loss: 1.7320 - accuracy: 0.2453 - val_loss: 1.9995 - val_accuracy: 0.2857 - lr: 8.3799e-13 - 56ms/epoch - 28ms/step\n",
      "Epoch 220/400\n",
      "2/2 - 0s - loss: 1.6666 - accuracy: 0.4151 - val_loss: 1.9982 - val_accuracy: 0.2857 - lr: 7.5825e-13 - 56ms/epoch - 28ms/step\n",
      "Epoch 221/400\n",
      "2/2 - 0s - loss: 1.6839 - accuracy: 0.3774 - val_loss: 1.9970 - val_accuracy: 0.2857 - lr: 6.8609e-13 - 60ms/epoch - 30ms/step\n",
      "Epoch 222/400\n",
      "2/2 - 0s - loss: 1.6799 - accuracy: 0.3585 - val_loss: 1.9960 - val_accuracy: 0.2857 - lr: 6.2080e-13 - 53ms/epoch - 26ms/step\n",
      "Epoch 223/400\n",
      "2/2 - 0s - loss: 1.6742 - accuracy: 0.3396 - val_loss: 1.9948 - val_accuracy: 0.2857 - lr: 5.6172e-13 - 58ms/epoch - 29ms/step\n",
      "Epoch 224/400\n",
      "2/2 - 0s - loss: 1.7245 - accuracy: 0.3208 - val_loss: 1.9937 - val_accuracy: 0.2857 - lr: 5.0827e-13 - 56ms/epoch - 28ms/step\n",
      "Epoch 225/400\n",
      "2/2 - 0s - loss: 1.6829 - accuracy: 0.3396 - val_loss: 1.9925 - val_accuracy: 0.2857 - lr: 4.5990e-13 - 57ms/epoch - 28ms/step\n",
      "Epoch 226/400\n",
      "2/2 - 0s - loss: 1.6508 - accuracy: 0.3396 - val_loss: 1.9913 - val_accuracy: 0.2857 - lr: 4.1613e-13 - 56ms/epoch - 28ms/step\n",
      "Epoch 227/400\n",
      "2/2 - 0s - loss: 1.6809 - accuracy: 0.4340 - val_loss: 1.9901 - val_accuracy: 0.2857 - lr: 3.7653e-13 - 70ms/epoch - 35ms/step\n",
      "Epoch 228/400\n",
      "2/2 - 0s - loss: 1.6232 - accuracy: 0.4528 - val_loss: 1.9889 - val_accuracy: 0.2857 - lr: 3.4070e-13 - 62ms/epoch - 31ms/step\n",
      "Epoch 229/400\n",
      "2/2 - 0s - loss: 1.6943 - accuracy: 0.3585 - val_loss: 1.9877 - val_accuracy: 0.2857 - lr: 3.0828e-13 - 56ms/epoch - 28ms/step\n",
      "Epoch 230/400\n",
      "2/2 - 0s - loss: 1.6086 - accuracy: 0.4340 - val_loss: 1.9865 - val_accuracy: 0.2857 - lr: 2.7894e-13 - 60ms/epoch - 30ms/step\n",
      "Epoch 231/400\n",
      "2/2 - 0s - loss: 1.7351 - accuracy: 0.3585 - val_loss: 1.9853 - val_accuracy: 0.2857 - lr: 2.5240e-13 - 61ms/epoch - 31ms/step\n",
      "Epoch 232/400\n",
      "2/2 - 0s - loss: 1.6703 - accuracy: 0.4151 - val_loss: 1.9839 - val_accuracy: 0.2857 - lr: 2.2838e-13 - 57ms/epoch - 28ms/step\n",
      "Epoch 233/400\n",
      "2/2 - 0s - loss: 1.6761 - accuracy: 0.3774 - val_loss: 1.9828 - val_accuracy: 0.2857 - lr: 2.0665e-13 - 60ms/epoch - 30ms/step\n",
      "Epoch 234/400\n",
      "2/2 - 0s - loss: 1.7283 - accuracy: 0.3396 - val_loss: 1.9817 - val_accuracy: 0.2857 - lr: 1.8698e-13 - 55ms/epoch - 28ms/step\n",
      "Epoch 235/400\n",
      "2/2 - 0s - loss: 1.6820 - accuracy: 0.3396 - val_loss: 1.9804 - val_accuracy: 0.2857 - lr: 1.6919e-13 - 56ms/epoch - 28ms/step\n",
      "Epoch 236/400\n",
      "2/2 - 0s - loss: 1.7004 - accuracy: 0.3774 - val_loss: 1.9792 - val_accuracy: 0.2857 - lr: 1.5309e-13 - 55ms/epoch - 27ms/step\n",
      "Epoch 237/400\n",
      "2/2 - 0s - loss: 1.6881 - accuracy: 0.3208 - val_loss: 1.9780 - val_accuracy: 0.2857 - lr: 1.3852e-13 - 64ms/epoch - 32ms/step\n",
      "Epoch 238/400\n",
      "2/2 - 0s - loss: 1.7407 - accuracy: 0.3208 - val_loss: 1.9767 - val_accuracy: 0.2857 - lr: 1.2534e-13 - 61ms/epoch - 30ms/step\n",
      "Epoch 239/400\n",
      "2/2 - 0s - loss: 1.6454 - accuracy: 0.4151 - val_loss: 1.9755 - val_accuracy: 0.2857 - lr: 1.1341e-13 - 59ms/epoch - 30ms/step\n",
      "Epoch 240/400\n",
      "2/2 - 0s - loss: 1.6730 - accuracy: 0.3774 - val_loss: 1.9743 - val_accuracy: 0.2857 - lr: 1.0262e-13 - 64ms/epoch - 32ms/step\n",
      "Epoch 241/400\n",
      "2/2 - 0s - loss: 1.6822 - accuracy: 0.3019 - val_loss: 1.9730 - val_accuracy: 0.2857 - lr: 9.2852e-14 - 60ms/epoch - 30ms/step\n",
      "Epoch 242/400\n",
      "2/2 - 0s - loss: 1.7078 - accuracy: 0.3774 - val_loss: 1.9719 - val_accuracy: 0.2857 - lr: 8.4016e-14 - 60ms/epoch - 30ms/step\n",
      "Epoch 243/400\n",
      "2/2 - 0s - loss: 1.7118 - accuracy: 0.3585 - val_loss: 1.9707 - val_accuracy: 0.2857 - lr: 7.6021e-14 - 59ms/epoch - 30ms/step\n",
      "Epoch 244/400\n",
      "2/2 - 0s - loss: 1.6238 - accuracy: 0.3962 - val_loss: 1.9694 - val_accuracy: 0.2857 - lr: 6.8787e-14 - 57ms/epoch - 28ms/step\n",
      "Epoch 245/400\n",
      "2/2 - 0s - loss: 1.7090 - accuracy: 0.3019 - val_loss: 1.9680 - val_accuracy: 0.2857 - lr: 6.2241e-14 - 63ms/epoch - 31ms/step\n",
      "Epoch 246/400\n",
      "2/2 - 0s - loss: 1.7591 - accuracy: 0.3208 - val_loss: 1.9668 - val_accuracy: 0.2857 - lr: 5.6318e-14 - 72ms/epoch - 36ms/step\n",
      "Epoch 247/400\n",
      "2/2 - 0s - loss: 1.6797 - accuracy: 0.3585 - val_loss: 1.9657 - val_accuracy: 0.2857 - lr: 5.0958e-14 - 67ms/epoch - 33ms/step\n",
      "Epoch 248/400\n",
      "2/2 - 0s - loss: 1.7314 - accuracy: 0.3585 - val_loss: 1.9644 - val_accuracy: 0.2857 - lr: 4.6109e-14 - 64ms/epoch - 32ms/step\n",
      "Epoch 249/400\n",
      "2/2 - 0s - loss: 1.7587 - accuracy: 0.2830 - val_loss: 1.9632 - val_accuracy: 0.2857 - lr: 4.1721e-14 - 63ms/epoch - 31ms/step\n",
      "Epoch 250/400\n",
      "2/2 - 0s - loss: 1.6760 - accuracy: 0.3208 - val_loss: 1.9621 - val_accuracy: 0.2857 - lr: 3.7751e-14 - 56ms/epoch - 28ms/step\n",
      "Epoch 251/400\n",
      "2/2 - 0s - loss: 1.6435 - accuracy: 0.3019 - val_loss: 1.9610 - val_accuracy: 0.2857 - lr: 3.4158e-14 - 60ms/epoch - 30ms/step\n",
      "Epoch 252/400\n",
      "2/2 - 0s - loss: 1.7253 - accuracy: 0.3585 - val_loss: 1.9599 - val_accuracy: 0.2857 - lr: 3.0908e-14 - 58ms/epoch - 29ms/step\n",
      "Epoch 253/400\n",
      "2/2 - 0s - loss: 1.6979 - accuracy: 0.3019 - val_loss: 1.9588 - val_accuracy: 0.2857 - lr: 2.7967e-14 - 58ms/epoch - 29ms/step\n",
      "Epoch 254/400\n",
      "2/2 - 0s - loss: 1.6591 - accuracy: 0.3396 - val_loss: 1.9576 - val_accuracy: 0.2857 - lr: 2.5305e-14 - 56ms/epoch - 28ms/step\n",
      "Epoch 255/400\n",
      "2/2 - 0s - loss: 1.7148 - accuracy: 0.3396 - val_loss: 1.9564 - val_accuracy: 0.2857 - lr: 2.2897e-14 - 55ms/epoch - 27ms/step\n",
      "Epoch 256/400\n",
      "2/2 - 0s - loss: 1.6111 - accuracy: 0.3396 - val_loss: 1.9551 - val_accuracy: 0.2857 - lr: 2.0718e-14 - 62ms/epoch - 31ms/step\n",
      "Epoch 257/400\n",
      "2/2 - 0s - loss: 1.6972 - accuracy: 0.3208 - val_loss: 1.9540 - val_accuracy: 0.2857 - lr: 1.8747e-14 - 58ms/epoch - 29ms/step\n",
      "Epoch 258/400\n",
      "2/2 - 0s - loss: 1.7141 - accuracy: 0.2830 - val_loss: 1.9527 - val_accuracy: 0.2857 - lr: 1.6963e-14 - 57ms/epoch - 29ms/step\n",
      "Epoch 259/400\n",
      "2/2 - 0s - loss: 1.6565 - accuracy: 0.3774 - val_loss: 1.9514 - val_accuracy: 0.2857 - lr: 1.5348e-14 - 62ms/epoch - 31ms/step\n",
      "Epoch 260/400\n",
      "2/2 - 0s - loss: 1.6984 - accuracy: 0.3585 - val_loss: 1.9502 - val_accuracy: 0.2857 - lr: 1.3888e-14 - 56ms/epoch - 28ms/step\n",
      "Epoch 261/400\n",
      "2/2 - 0s - loss: 1.6886 - accuracy: 0.3019 - val_loss: 1.9491 - val_accuracy: 0.2857 - lr: 1.2566e-14 - 61ms/epoch - 31ms/step\n",
      "Epoch 262/400\n",
      "2/2 - 0s - loss: 1.7368 - accuracy: 0.3019 - val_loss: 1.9480 - val_accuracy: 0.2857 - lr: 1.1370e-14 - 54ms/epoch - 27ms/step\n",
      "Epoch 263/400\n",
      "2/2 - 0s - loss: 1.7166 - accuracy: 0.3019 - val_loss: 1.9469 - val_accuracy: 0.2857 - lr: 1.0288e-14 - 63ms/epoch - 32ms/step\n",
      "Epoch 264/400\n",
      "2/2 - 0s - loss: 1.7466 - accuracy: 0.3208 - val_loss: 1.9457 - val_accuracy: 0.2857 - lr: 9.3092e-15 - 58ms/epoch - 29ms/step\n",
      "Epoch 265/400\n",
      "2/2 - 0s - loss: 1.6369 - accuracy: 0.3396 - val_loss: 1.9447 - val_accuracy: 0.2857 - lr: 8.4233e-15 - 58ms/epoch - 29ms/step\n",
      "Epoch 266/400\n",
      "2/2 - 0s - loss: 1.6783 - accuracy: 0.2642 - val_loss: 1.9435 - val_accuracy: 0.2857 - lr: 7.6218e-15 - 58ms/epoch - 29ms/step\n",
      "Epoch 267/400\n",
      "2/2 - 0s - loss: 1.7056 - accuracy: 0.3019 - val_loss: 1.9423 - val_accuracy: 0.2857 - lr: 6.8965e-15 - 56ms/epoch - 28ms/step\n",
      "Epoch 268/400\n",
      "2/2 - 0s - loss: 1.7222 - accuracy: 0.2264 - val_loss: 1.9411 - val_accuracy: 0.2857 - lr: 6.2402e-15 - 57ms/epoch - 28ms/step\n",
      "Epoch 269/400\n",
      "2/2 - 0s - loss: 1.6895 - accuracy: 0.3585 - val_loss: 1.9398 - val_accuracy: 0.2857 - lr: 5.6463e-15 - 57ms/epoch - 28ms/step\n",
      "Epoch 270/400\n",
      "2/2 - 0s - loss: 1.6164 - accuracy: 0.3774 - val_loss: 1.9387 - val_accuracy: 0.2857 - lr: 5.1090e-15 - 61ms/epoch - 31ms/step\n",
      "Epoch 271/400\n",
      "2/2 - 0s - loss: 1.7959 - accuracy: 0.2642 - val_loss: 1.9375 - val_accuracy: 0.2857 - lr: 4.6228e-15 - 58ms/epoch - 29ms/step\n",
      "Epoch 272/400\n",
      "2/2 - 0s - loss: 1.7227 - accuracy: 0.2830 - val_loss: 1.9364 - val_accuracy: 0.2857 - lr: 4.1829e-15 - 57ms/epoch - 29ms/step\n",
      "Epoch 273/400\n",
      "2/2 - 0s - loss: 1.6867 - accuracy: 0.3019 - val_loss: 1.9354 - val_accuracy: 0.2857 - lr: 3.7849e-15 - 57ms/epoch - 28ms/step\n",
      "Epoch 274/400\n",
      "2/2 - 0s - loss: 1.6957 - accuracy: 0.3019 - val_loss: 1.9344 - val_accuracy: 0.2857 - lr: 3.4247e-15 - 57ms/epoch - 29ms/step\n",
      "Epoch 275/400\n",
      "2/2 - 0s - loss: 1.7231 - accuracy: 0.2642 - val_loss: 1.9333 - val_accuracy: 0.2857 - lr: 3.0988e-15 - 60ms/epoch - 30ms/step\n",
      "Epoch 276/400\n",
      "2/2 - 0s - loss: 1.6781 - accuracy: 0.2830 - val_loss: 1.9322 - val_accuracy: 0.2857 - lr: 2.8039e-15 - 56ms/epoch - 28ms/step\n",
      "Epoch 277/400\n",
      "2/2 - 0s - loss: 1.7244 - accuracy: 0.3208 - val_loss: 1.9309 - val_accuracy: 0.2857 - lr: 2.5371e-15 - 60ms/epoch - 30ms/step\n",
      "Epoch 278/400\n",
      "2/2 - 0s - loss: 1.6726 - accuracy: 0.3774 - val_loss: 1.9299 - val_accuracy: 0.2857 - lr: 2.2956e-15 - 63ms/epoch - 31ms/step\n",
      "Epoch 279/400\n",
      "2/2 - 0s - loss: 1.6565 - accuracy: 0.3396 - val_loss: 1.9288 - val_accuracy: 0.2857 - lr: 2.0772e-15 - 61ms/epoch - 31ms/step\n",
      "Epoch 280/400\n",
      "2/2 - 0s - loss: 1.6663 - accuracy: 0.2830 - val_loss: 1.9278 - val_accuracy: 0.2857 - lr: 1.8795e-15 - 64ms/epoch - 32ms/step\n",
      "Epoch 281/400\n",
      "2/2 - 0s - loss: 1.7394 - accuracy: 0.3019 - val_loss: 1.9267 - val_accuracy: 0.2857 - lr: 1.7006e-15 - 57ms/epoch - 29ms/step\n",
      "Epoch 282/400\n",
      "2/2 - 0s - loss: 1.6881 - accuracy: 0.2830 - val_loss: 1.9256 - val_accuracy: 0.2857 - lr: 1.5388e-15 - 61ms/epoch - 30ms/step\n",
      "Epoch 283/400\n",
      "2/2 - 0s - loss: 1.6792 - accuracy: 0.2642 - val_loss: 1.9245 - val_accuracy: 0.2857 - lr: 1.3924e-15 - 73ms/epoch - 37ms/step\n",
      "Epoch 284/400\n",
      "2/2 - 0s - loss: 1.7323 - accuracy: 0.3962 - val_loss: 1.9235 - val_accuracy: 0.2857 - lr: 1.2599e-15 - 68ms/epoch - 34ms/step\n",
      "Epoch 285/400\n",
      "2/2 - 0s - loss: 1.7206 - accuracy: 0.2642 - val_loss: 1.9225 - val_accuracy: 0.2857 - lr: 1.1400e-15 - 63ms/epoch - 32ms/step\n",
      "Epoch 286/400\n",
      "2/2 - 0s - loss: 1.7231 - accuracy: 0.3774 - val_loss: 1.9213 - val_accuracy: 0.2857 - lr: 1.0315e-15 - 59ms/epoch - 29ms/step\n",
      "Epoch 287/400\n",
      "2/2 - 0s - loss: 1.7321 - accuracy: 0.3208 - val_loss: 1.9202 - val_accuracy: 0.2857 - lr: 9.3333e-16 - 67ms/epoch - 34ms/step\n",
      "Epoch 288/400\n",
      "2/2 - 0s - loss: 1.7241 - accuracy: 0.2830 - val_loss: 1.9192 - val_accuracy: 0.2857 - lr: 8.4451e-16 - 61ms/epoch - 30ms/step\n",
      "Epoch 289/400\n",
      "2/2 - 0s - loss: 1.7600 - accuracy: 0.2264 - val_loss: 1.9184 - val_accuracy: 0.2857 - lr: 7.6415e-16 - 63ms/epoch - 32ms/step\n",
      "Epoch 290/400\n",
      "2/2 - 0s - loss: 1.6479 - accuracy: 0.3962 - val_loss: 1.9176 - val_accuracy: 0.2857 - lr: 6.9143e-16 - 61ms/epoch - 31ms/step\n",
      "Epoch 291/400\n",
      "2/2 - 0s - loss: 1.6805 - accuracy: 0.3962 - val_loss: 1.9166 - val_accuracy: 0.2857 - lr: 6.2563e-16 - 62ms/epoch - 31ms/step\n",
      "Epoch 292/400\n",
      "2/2 - 0s - loss: 1.6565 - accuracy: 0.3585 - val_loss: 1.9155 - val_accuracy: 0.2857 - lr: 5.6609e-16 - 56ms/epoch - 28ms/step\n",
      "Epoch 293/400\n",
      "2/2 - 0s - loss: 1.6947 - accuracy: 0.3585 - val_loss: 1.9144 - val_accuracy: 0.2857 - lr: 5.1222e-16 - 59ms/epoch - 29ms/step\n",
      "Epoch 294/400\n",
      "2/2 - 0s - loss: 1.6765 - accuracy: 0.3208 - val_loss: 1.9135 - val_accuracy: 0.2857 - lr: 4.6348e-16 - 63ms/epoch - 32ms/step\n",
      "Epoch 295/400\n",
      "2/2 - 0s - loss: 1.7650 - accuracy: 0.2830 - val_loss: 1.9125 - val_accuracy: 0.2857 - lr: 4.1937e-16 - 60ms/epoch - 30ms/step\n",
      "Epoch 296/400\n",
      "2/2 - 0s - loss: 1.6409 - accuracy: 0.3774 - val_loss: 1.9115 - val_accuracy: 0.2857 - lr: 3.7946e-16 - 56ms/epoch - 28ms/step\n",
      "Epoch 297/400\n",
      "2/2 - 0s - loss: 1.7462 - accuracy: 0.2453 - val_loss: 1.9105 - val_accuracy: 0.2857 - lr: 3.4335e-16 - 55ms/epoch - 27ms/step\n",
      "Epoch 298/400\n",
      "2/2 - 0s - loss: 1.6500 - accuracy: 0.3019 - val_loss: 1.9094 - val_accuracy: 0.2857 - lr: 3.1068e-16 - 64ms/epoch - 32ms/step\n",
      "Epoch 299/400\n",
      "2/2 - 0s - loss: 1.7330 - accuracy: 0.2830 - val_loss: 1.9085 - val_accuracy: 0.2857 - lr: 2.8111e-16 - 60ms/epoch - 30ms/step\n",
      "Epoch 300/400\n",
      "2/2 - 0s - loss: 1.6954 - accuracy: 0.2642 - val_loss: 1.9079 - val_accuracy: 0.2857 - lr: 2.5436e-16 - 56ms/epoch - 28ms/step\n",
      "Epoch 301/400\n",
      "2/2 - 0s - loss: 1.7226 - accuracy: 0.3585 - val_loss: 1.9068 - val_accuracy: 0.2857 - lr: 2.3016e-16 - 60ms/epoch - 30ms/step\n",
      "Epoch 302/400\n",
      "2/2 - 0s - loss: 1.6411 - accuracy: 0.3585 - val_loss: 1.9057 - val_accuracy: 0.2857 - lr: 2.0825e-16 - 66ms/epoch - 33ms/step\n",
      "Epoch 303/400\n",
      "2/2 - 0s - loss: 1.7202 - accuracy: 0.2453 - val_loss: 1.9046 - val_accuracy: 0.2857 - lr: 1.8844e-16 - 59ms/epoch - 30ms/step\n",
      "Epoch 304/400\n",
      "2/2 - 0s - loss: 1.7134 - accuracy: 0.3208 - val_loss: 1.9038 - val_accuracy: 0.2857 - lr: 1.7050e-16 - 63ms/epoch - 31ms/step\n",
      "Epoch 305/400\n",
      "2/2 - 0s - loss: 1.7275 - accuracy: 0.3396 - val_loss: 1.9031 - val_accuracy: 0.2857 - lr: 1.5428e-16 - 57ms/epoch - 29ms/step\n",
      "Epoch 306/400\n",
      "2/2 - 0s - loss: 1.6971 - accuracy: 0.3019 - val_loss: 1.9023 - val_accuracy: 0.2857 - lr: 1.3960e-16 - 57ms/epoch - 28ms/step\n",
      "Epoch 307/400\n",
      "2/2 - 0s - loss: 1.7589 - accuracy: 0.3962 - val_loss: 1.9017 - val_accuracy: 0.2857 - lr: 1.2631e-16 - 62ms/epoch - 31ms/step\n",
      "Epoch 308/400\n",
      "2/2 - 0s - loss: 1.6464 - accuracy: 0.3585 - val_loss: 1.9007 - val_accuracy: 0.2857 - lr: 1.1429e-16 - 62ms/epoch - 31ms/step\n",
      "Epoch 309/400\n",
      "2/2 - 0s - loss: 1.6782 - accuracy: 0.3585 - val_loss: 1.9000 - val_accuracy: 0.2857 - lr: 1.0342e-16 - 63ms/epoch - 31ms/step\n",
      "Epoch 310/400\n",
      "2/2 - 0s - loss: 1.6755 - accuracy: 0.4151 - val_loss: 1.8992 - val_accuracy: 0.2857 - lr: 9.3575e-17 - 60ms/epoch - 30ms/step\n",
      "Epoch 311/400\n",
      "2/2 - 0s - loss: 1.6966 - accuracy: 0.3019 - val_loss: 1.8984 - val_accuracy: 0.2857 - lr: 8.4670e-17 - 69ms/epoch - 34ms/step\n",
      "Epoch 312/400\n",
      "2/2 - 0s - loss: 1.6871 - accuracy: 0.3208 - val_loss: 1.8974 - val_accuracy: 0.2857 - lr: 7.6613e-17 - 58ms/epoch - 29ms/step\n",
      "Epoch 313/400\n",
      "2/2 - 0s - loss: 1.6716 - accuracy: 0.3396 - val_loss: 1.8965 - val_accuracy: 0.2857 - lr: 6.9322e-17 - 59ms/epoch - 29ms/step\n",
      "Epoch 314/400\n",
      "2/2 - 0s - loss: 1.6716 - accuracy: 0.3962 - val_loss: 1.8957 - val_accuracy: 0.2857 - lr: 6.2725e-17 - 61ms/epoch - 31ms/step\n",
      "Epoch 315/400\n",
      "2/2 - 0s - loss: 1.6647 - accuracy: 0.3774 - val_loss: 1.8950 - val_accuracy: 0.2857 - lr: 5.6756e-17 - 63ms/epoch - 32ms/step\n",
      "Epoch 316/400\n",
      "2/2 - 0s - loss: 1.7557 - accuracy: 0.2830 - val_loss: 1.8941 - val_accuracy: 0.2857 - lr: 5.1355e-17 - 61ms/epoch - 31ms/step\n",
      "Epoch 317/400\n",
      "2/2 - 0s - loss: 1.7761 - accuracy: 0.2830 - val_loss: 1.8935 - val_accuracy: 0.2857 - lr: 4.6468e-17 - 73ms/epoch - 37ms/step\n",
      "Epoch 318/400\n",
      "2/2 - 0s - loss: 1.6633 - accuracy: 0.3396 - val_loss: 1.8926 - val_accuracy: 0.2857 - lr: 4.2046e-17 - 68ms/epoch - 34ms/step\n",
      "Epoch 319/400\n",
      "2/2 - 0s - loss: 1.6532 - accuracy: 0.3019 - val_loss: 1.8922 - val_accuracy: 0.2857 - lr: 3.8045e-17 - 62ms/epoch - 31ms/step\n",
      "Epoch 320/400\n",
      "2/2 - 0s - loss: 1.6623 - accuracy: 0.3585 - val_loss: 1.8913 - val_accuracy: 0.2857 - lr: 3.4424e-17 - 62ms/epoch - 31ms/step\n",
      "Epoch 321/400\n",
      "2/2 - 0s - loss: 1.6644 - accuracy: 0.3019 - val_loss: 1.8905 - val_accuracy: 0.2857 - lr: 3.1148e-17 - 61ms/epoch - 30ms/step\n",
      "Epoch 322/400\n",
      "2/2 - 0s - loss: 1.7496 - accuracy: 0.2830 - val_loss: 1.8896 - val_accuracy: 0.2857 - lr: 2.8184e-17 - 60ms/epoch - 30ms/step\n",
      "Epoch 323/400\n",
      "2/2 - 0s - loss: 1.7195 - accuracy: 0.2830 - val_loss: 1.8891 - val_accuracy: 0.2857 - lr: 2.5502e-17 - 62ms/epoch - 31ms/step\n",
      "Epoch 324/400\n",
      "2/2 - 0s - loss: 1.6691 - accuracy: 0.3396 - val_loss: 1.8884 - val_accuracy: 0.2857 - lr: 2.3075e-17 - 65ms/epoch - 33ms/step\n",
      "Epoch 325/400\n",
      "2/2 - 0s - loss: 1.7004 - accuracy: 0.3585 - val_loss: 1.8876 - val_accuracy: 0.2857 - lr: 2.0879e-17 - 69ms/epoch - 34ms/step\n",
      "Epoch 326/400\n",
      "2/2 - 0s - loss: 1.6590 - accuracy: 0.3208 - val_loss: 1.8871 - val_accuracy: 0.2857 - lr: 1.8892e-17 - 81ms/epoch - 41ms/step\n",
      "Epoch 327/400\n",
      "2/2 - 0s - loss: 1.6918 - accuracy: 0.3962 - val_loss: 1.8865 - val_accuracy: 0.2857 - lr: 1.7095e-17 - 69ms/epoch - 34ms/step\n",
      "Epoch 328/400\n",
      "2/2 - 0s - loss: 1.6849 - accuracy: 0.3208 - val_loss: 1.8857 - val_accuracy: 0.2857 - lr: 1.5468e-17 - 62ms/epoch - 31ms/step\n",
      "Epoch 329/400\n",
      "2/2 - 0s - loss: 1.6824 - accuracy: 0.3208 - val_loss: 1.8852 - val_accuracy: 0.2857 - lr: 1.3996e-17 - 62ms/epoch - 31ms/step\n",
      "Epoch 330/400\n",
      "2/2 - 0s - loss: 1.6449 - accuracy: 0.4151 - val_loss: 1.8846 - val_accuracy: 0.2857 - lr: 1.2664e-17 - 62ms/epoch - 31ms/step\n",
      "Epoch 331/400\n",
      "2/2 - 0s - loss: 1.6663 - accuracy: 0.3774 - val_loss: 1.8841 - val_accuracy: 0.2857 - lr: 1.1459e-17 - 56ms/epoch - 28ms/step\n",
      "Epoch 332/400\n",
      "2/2 - 0s - loss: 1.7187 - accuracy: 0.3208 - val_loss: 1.8835 - val_accuracy: 0.2857 - lr: 1.0368e-17 - 56ms/epoch - 28ms/step\n",
      "Epoch 333/400\n",
      "2/2 - 0s - loss: 1.6908 - accuracy: 0.3019 - val_loss: 1.8829 - val_accuracy: 0.2857 - lr: 9.3817e-18 - 64ms/epoch - 32ms/step\n",
      "Epoch 334/400\n",
      "2/2 - 0s - loss: 1.6600 - accuracy: 0.3962 - val_loss: 1.8824 - val_accuracy: 0.2857 - lr: 8.4889e-18 - 57ms/epoch - 28ms/step\n",
      "Epoch 335/400\n",
      "2/2 - 0s - loss: 1.7207 - accuracy: 0.4151 - val_loss: 1.8822 - val_accuracy: 0.2857 - lr: 7.6811e-18 - 59ms/epoch - 29ms/step\n",
      "Epoch 336/400\n",
      "2/2 - 0s - loss: 1.7229 - accuracy: 0.3585 - val_loss: 1.8813 - val_accuracy: 0.2857 - lr: 6.9501e-18 - 61ms/epoch - 31ms/step\n",
      "Epoch 337/400\n",
      "2/2 - 0s - loss: 1.7349 - accuracy: 0.2830 - val_loss: 1.8811 - val_accuracy: 0.2857 - lr: 6.2887e-18 - 64ms/epoch - 32ms/step\n",
      "Epoch 338/400\n",
      "2/2 - 0s - loss: 1.6713 - accuracy: 0.3019 - val_loss: 1.8805 - val_accuracy: 0.2857 - lr: 5.6903e-18 - 61ms/epoch - 30ms/step\n",
      "Epoch 339/400\n",
      "2/2 - 0s - loss: 1.7254 - accuracy: 0.2075 - val_loss: 1.8798 - val_accuracy: 0.2857 - lr: 5.1488e-18 - 59ms/epoch - 29ms/step\n",
      "Epoch 340/400\n",
      "2/2 - 0s - loss: 1.6362 - accuracy: 0.3396 - val_loss: 1.8792 - val_accuracy: 0.2857 - lr: 4.6588e-18 - 63ms/epoch - 31ms/step\n",
      "Epoch 341/400\n",
      "2/2 - 0s - loss: 1.6807 - accuracy: 0.3208 - val_loss: 1.8787 - val_accuracy: 0.2857 - lr: 4.2155e-18 - 60ms/epoch - 30ms/step\n",
      "Epoch 342/400\n",
      "2/2 - 0s - loss: 1.7366 - accuracy: 0.2830 - val_loss: 1.8783 - val_accuracy: 0.2857 - lr: 3.8143e-18 - 54ms/epoch - 27ms/step\n",
      "Epoch 343/400\n",
      "2/2 - 0s - loss: 1.7626 - accuracy: 0.2642 - val_loss: 1.8780 - val_accuracy: 0.2857 - lr: 3.4513e-18 - 65ms/epoch - 32ms/step\n",
      "Epoch 344/400\n",
      "2/2 - 0s - loss: 1.6956 - accuracy: 0.3774 - val_loss: 1.8777 - val_accuracy: 0.2857 - lr: 3.1229e-18 - 61ms/epoch - 31ms/step\n",
      "Epoch 345/400\n",
      "2/2 - 0s - loss: 1.7091 - accuracy: 0.3019 - val_loss: 1.8772 - val_accuracy: 0.2857 - lr: 2.8257e-18 - 56ms/epoch - 28ms/step\n",
      "Epoch 346/400\n",
      "2/2 - 0s - loss: 1.7205 - accuracy: 0.2642 - val_loss: 1.8768 - val_accuracy: 0.2857 - lr: 2.5568e-18 - 59ms/epoch - 29ms/step\n",
      "Epoch 347/400\n",
      "2/2 - 0s - loss: 1.6713 - accuracy: 0.3396 - val_loss: 1.8763 - val_accuracy: 0.2857 - lr: 2.3135e-18 - 60ms/epoch - 30ms/step\n",
      "Epoch 348/400\n",
      "2/2 - 0s - loss: 1.7341 - accuracy: 0.3208 - val_loss: 1.8758 - val_accuracy: 0.2857 - lr: 2.0933e-18 - 70ms/epoch - 35ms/step\n",
      "Epoch 349/400\n",
      "2/2 - 0s - loss: 1.7312 - accuracy: 0.3019 - val_loss: 1.8755 - val_accuracy: 0.2857 - lr: 1.8941e-18 - 58ms/epoch - 29ms/step\n",
      "Epoch 350/400\n",
      "2/2 - 0s - loss: 1.6415 - accuracy: 0.3396 - val_loss: 1.8749 - val_accuracy: 0.2857 - lr: 1.7139e-18 - 60ms/epoch - 30ms/step\n",
      "Epoch 351/400\n",
      "2/2 - 0s - loss: 1.7092 - accuracy: 0.2830 - val_loss: 1.8745 - val_accuracy: 0.2857 - lr: 1.5508e-18 - 64ms/epoch - 32ms/step\n",
      "Epoch 352/400\n",
      "2/2 - 0s - loss: 1.6741 - accuracy: 0.3208 - val_loss: 1.8741 - val_accuracy: 0.2857 - lr: 1.4032e-18 - 67ms/epoch - 33ms/step\n",
      "Epoch 353/400\n",
      "2/2 - 0s - loss: 1.7063 - accuracy: 0.3774 - val_loss: 1.8738 - val_accuracy: 0.2857 - lr: 1.2697e-18 - 56ms/epoch - 28ms/step\n",
      "Epoch 354/400\n",
      "2/2 - 0s - loss: 1.6590 - accuracy: 0.3774 - val_loss: 1.8734 - val_accuracy: 0.2857 - lr: 1.1488e-18 - 57ms/epoch - 29ms/step\n",
      "Epoch 355/400\n",
      "2/2 - 0s - loss: 1.7177 - accuracy: 0.2830 - val_loss: 1.8728 - val_accuracy: 0.2857 - lr: 1.0395e-18 - 70ms/epoch - 35ms/step\n",
      "Epoch 356/400\n",
      "2/2 - 0s - loss: 1.6392 - accuracy: 0.3962 - val_loss: 1.8723 - val_accuracy: 0.2857 - lr: 9.4060e-19 - 66ms/epoch - 33ms/step\n",
      "Epoch 357/400\n",
      "2/2 - 0s - loss: 1.6354 - accuracy: 0.3962 - val_loss: 1.8721 - val_accuracy: 0.2857 - lr: 8.5109e-19 - 65ms/epoch - 32ms/step\n",
      "Epoch 358/400\n",
      "2/2 - 0s - loss: 1.6815 - accuracy: 0.4151 - val_loss: 1.8720 - val_accuracy: 0.2857 - lr: 7.7009e-19 - 58ms/epoch - 29ms/step\n",
      "Epoch 359/400\n",
      "2/2 - 0s - loss: 1.7663 - accuracy: 0.2642 - val_loss: 1.8720 - val_accuracy: 0.2857 - lr: 6.9681e-19 - 52ms/epoch - 26ms/step\n",
      "Epoch 360/400\n",
      "2/2 - 0s - loss: 1.7137 - accuracy: 0.3396 - val_loss: 1.8718 - val_accuracy: 0.2857 - lr: 6.3050e-19 - 59ms/epoch - 30ms/step\n",
      "Epoch 361/400\n",
      "2/2 - 0s - loss: 1.6658 - accuracy: 0.3208 - val_loss: 1.8714 - val_accuracy: 0.2857 - lr: 5.7050e-19 - 59ms/epoch - 29ms/step\n",
      "Epoch 362/400\n",
      "2/2 - 0s - loss: 1.7171 - accuracy: 0.2830 - val_loss: 1.8710 - val_accuracy: 0.2857 - lr: 5.1621e-19 - 56ms/epoch - 28ms/step\n",
      "Epoch 363/400\n",
      "2/2 - 0s - loss: 1.7074 - accuracy: 0.4151 - val_loss: 1.8707 - val_accuracy: 0.2857 - lr: 4.6709e-19 - 58ms/epoch - 29ms/step\n",
      "Epoch 364/400\n",
      "2/2 - 0s - loss: 1.7389 - accuracy: 0.3396 - val_loss: 1.8704 - val_accuracy: 0.2857 - lr: 4.2264e-19 - 59ms/epoch - 30ms/step\n",
      "Epoch 365/400\n",
      "2/2 - 0s - loss: 1.6651 - accuracy: 0.3585 - val_loss: 1.8699 - val_accuracy: 0.2857 - lr: 3.8242e-19 - 55ms/epoch - 28ms/step\n",
      "Epoch 366/400\n",
      "2/2 - 0s - loss: 1.7408 - accuracy: 0.3962 - val_loss: 1.8698 - val_accuracy: 0.2857 - lr: 3.4603e-19 - 59ms/epoch - 29ms/step\n",
      "Epoch 367/400\n",
      "2/2 - 0s - loss: 1.7091 - accuracy: 0.3774 - val_loss: 1.8693 - val_accuracy: 0.2857 - lr: 3.1310e-19 - 59ms/epoch - 30ms/step\n",
      "Epoch 368/400\n",
      "2/2 - 0s - loss: 1.7359 - accuracy: 0.3019 - val_loss: 1.8693 - val_accuracy: 0.2857 - lr: 2.8330e-19 - 61ms/epoch - 30ms/step\n",
      "Epoch 369/400\n",
      "2/2 - 0s - loss: 1.6989 - accuracy: 0.3019 - val_loss: 1.8688 - val_accuracy: 0.2857 - lr: 2.5634e-19 - 55ms/epoch - 28ms/step\n",
      "Epoch 370/400\n",
      "2/2 - 0s - loss: 1.7154 - accuracy: 0.2830 - val_loss: 1.8685 - val_accuracy: 0.2857 - lr: 2.3195e-19 - 58ms/epoch - 29ms/step\n",
      "Epoch 371/400\n",
      "2/2 - 0s - loss: 1.7265 - accuracy: 0.3774 - val_loss: 1.8680 - val_accuracy: 0.2857 - lr: 2.0988e-19 - 65ms/epoch - 32ms/step\n",
      "Epoch 372/400\n",
      "2/2 - 0s - loss: 1.6915 - accuracy: 0.3585 - val_loss: 1.8673 - val_accuracy: 0.2857 - lr: 1.8990e-19 - 51ms/epoch - 26ms/step\n",
      "Epoch 373/400\n",
      "2/2 - 0s - loss: 1.6913 - accuracy: 0.4151 - val_loss: 1.8666 - val_accuracy: 0.2857 - lr: 1.7183e-19 - 56ms/epoch - 28ms/step\n",
      "Epoch 374/400\n",
      "2/2 - 0s - loss: 1.7252 - accuracy: 0.3019 - val_loss: 1.8663 - val_accuracy: 0.2857 - lr: 1.5548e-19 - 57ms/epoch - 28ms/step\n",
      "Epoch 375/400\n",
      "2/2 - 0s - loss: 1.7154 - accuracy: 0.3019 - val_loss: 1.8662 - val_accuracy: 0.2857 - lr: 1.4068e-19 - 57ms/epoch - 28ms/step\n",
      "Epoch 376/400\n",
      "2/2 - 0s - loss: 1.6739 - accuracy: 0.4340 - val_loss: 1.8657 - val_accuracy: 0.2857 - lr: 1.2730e-19 - 53ms/epoch - 27ms/step\n",
      "Epoch 377/400\n",
      "2/2 - 0s - loss: 1.7039 - accuracy: 0.3019 - val_loss: 1.8654 - val_accuracy: 0.2857 - lr: 1.1518e-19 - 57ms/epoch - 28ms/step\n",
      "Epoch 378/400\n",
      "2/2 - 0s - loss: 1.6377 - accuracy: 0.4151 - val_loss: 1.8648 - val_accuracy: 0.2857 - lr: 1.0422e-19 - 61ms/epoch - 31ms/step\n",
      "Epoch 379/400\n",
      "2/2 - 0s - loss: 1.6613 - accuracy: 0.3208 - val_loss: 1.8648 - val_accuracy: 0.2857 - lr: 9.4303e-20 - 58ms/epoch - 29ms/step\n",
      "Epoch 380/400\n",
      "2/2 - 0s - loss: 1.7038 - accuracy: 0.2830 - val_loss: 1.8648 - val_accuracy: 0.2857 - lr: 8.5329e-20 - 53ms/epoch - 26ms/step\n",
      "Epoch 381/400\n",
      "2/2 - 0s - loss: 1.6964 - accuracy: 0.2642 - val_loss: 1.8645 - val_accuracy: 0.2857 - lr: 7.7209e-20 - 56ms/epoch - 28ms/step\n",
      "Epoch 382/400\n",
      "2/2 - 0s - loss: 1.6495 - accuracy: 0.4340 - val_loss: 1.8641 - val_accuracy: 0.2857 - lr: 6.9861e-20 - 57ms/epoch - 29ms/step\n",
      "Epoch 383/400\n",
      "2/2 - 0s - loss: 1.7302 - accuracy: 0.2830 - val_loss: 1.8636 - val_accuracy: 0.2857 - lr: 6.3213e-20 - 57ms/epoch - 28ms/step\n",
      "Epoch 384/400\n",
      "2/2 - 0s - loss: 1.6950 - accuracy: 0.2642 - val_loss: 1.8635 - val_accuracy: 0.2857 - lr: 5.7198e-20 - 54ms/epoch - 27ms/step\n",
      "Epoch 385/400\n",
      "2/2 - 0s - loss: 1.6700 - accuracy: 0.3585 - val_loss: 1.8630 - val_accuracy: 0.2857 - lr: 5.1755e-20 - 59ms/epoch - 29ms/step\n",
      "Epoch 386/400\n",
      "2/2 - 0s - loss: 1.6730 - accuracy: 0.3208 - val_loss: 1.8624 - val_accuracy: 0.2857 - lr: 4.6829e-20 - 52ms/epoch - 26ms/step\n",
      "Epoch 387/400\n",
      "2/2 - 0s - loss: 1.6806 - accuracy: 0.4151 - val_loss: 1.8618 - val_accuracy: 0.2857 - lr: 4.2373e-20 - 61ms/epoch - 31ms/step\n",
      "Epoch 388/400\n",
      "2/2 - 0s - loss: 1.6410 - accuracy: 0.3774 - val_loss: 1.8617 - val_accuracy: 0.2857 - lr: 3.8341e-20 - 65ms/epoch - 32ms/step\n",
      "Epoch 389/400\n",
      "2/2 - 0s - loss: 1.6670 - accuracy: 0.3962 - val_loss: 1.8614 - val_accuracy: 0.2857 - lr: 3.4692e-20 - 57ms/epoch - 28ms/step\n",
      "Epoch 390/400\n",
      "2/2 - 0s - loss: 1.7105 - accuracy: 0.2642 - val_loss: 1.8611 - val_accuracy: 0.2857 - lr: 3.1391e-20 - 68ms/epoch - 34ms/step\n",
      "Epoch 391/400\n",
      "2/2 - 0s - loss: 1.7042 - accuracy: 0.3962 - val_loss: 1.8609 - val_accuracy: 0.2857 - lr: 2.8403e-20 - 61ms/epoch - 31ms/step\n",
      "Epoch 392/400\n",
      "2/2 - 0s - loss: 1.6633 - accuracy: 0.3774 - val_loss: 1.8603 - val_accuracy: 0.2857 - lr: 2.5701e-20 - 57ms/epoch - 28ms/step\n",
      "Epoch 393/400\n",
      "2/2 - 0s - loss: 1.7105 - accuracy: 0.2830 - val_loss: 1.8602 - val_accuracy: 0.2857 - lr: 2.3255e-20 - 67ms/epoch - 34ms/step\n",
      "Epoch 394/400\n",
      "2/2 - 0s - loss: 1.6569 - accuracy: 0.3774 - val_loss: 1.8599 - val_accuracy: 0.2857 - lr: 2.1042e-20 - 62ms/epoch - 31ms/step\n",
      "Epoch 395/400\n",
      "2/2 - 0s - loss: 1.6931 - accuracy: 0.3585 - val_loss: 1.8598 - val_accuracy: 0.2857 - lr: 1.9039e-20 - 59ms/epoch - 29ms/step\n",
      "Epoch 396/400\n",
      "2/2 - 0s - loss: 1.6970 - accuracy: 0.3208 - val_loss: 1.8596 - val_accuracy: 0.2857 - lr: 1.7228e-20 - 61ms/epoch - 31ms/step\n",
      "Epoch 397/400\n",
      "2/2 - 0s - loss: 1.6545 - accuracy: 0.4528 - val_loss: 1.8597 - val_accuracy: 0.2857 - lr: 1.5588e-20 - 49ms/epoch - 25ms/step\n",
      "Epoch 398/400\n",
      "2/2 - 0s - loss: 1.7019 - accuracy: 0.3396 - val_loss: 1.8596 - val_accuracy: 0.2857 - lr: 1.4105e-20 - 53ms/epoch - 26ms/step\n",
      "Epoch 399/400\n",
      "2/2 - 0s - loss: 1.6497 - accuracy: 0.4151 - val_loss: 1.8597 - val_accuracy: 0.2857 - lr: 1.2762e-20 - 52ms/epoch - 26ms/step\n",
      "Epoch 400/400\n",
      "2/2 - 0s - loss: 1.6588 - accuracy: 0.4151 - val_loss: 1.8593 - val_accuracy: 0.2857 - lr: 1.1548e-20 - 63ms/epoch - 31ms/step\n",
      "Evaluando modelo: Pasos_Desbaste\n",
      "Epoch 1/400\n",
      "2/2 - 7s - loss: 10.8473 - accuracy: 0.2264 - val_loss: 10.0051 - val_accuracy: 0.1429 - lr: 0.0010 - 7s/epoch - 4s/step\n",
      "Epoch 2/400\n",
      "2/2 - 0s - loss: 10.5954 - accuracy: 0.1887 - val_loss: 10.0069 - val_accuracy: 0.2143 - lr: 0.0010 - 58ms/epoch - 29ms/step\n",
      "Epoch 3/400\n",
      "2/2 - 0s - loss: 10.2817 - accuracy: 0.2453 - val_loss: 9.8649 - val_accuracy: 0.2143 - lr: 0.0010 - 71ms/epoch - 35ms/step\n",
      "Epoch 4/400\n",
      "2/2 - 0s - loss: 9.5278 - accuracy: 0.3774 - val_loss: 9.7627 - val_accuracy: 0.0714 - lr: 0.0010 - 76ms/epoch - 38ms/step\n",
      "Epoch 5/400\n",
      "2/2 - 0s - loss: 9.5382 - accuracy: 0.4340 - val_loss: 9.7438 - val_accuracy: 0.1429 - lr: 0.0010 - 73ms/epoch - 36ms/step\n",
      "Epoch 6/400\n",
      "2/2 - 0s - loss: 9.1108 - accuracy: 0.4528 - val_loss: 9.7309 - val_accuracy: 0.2143 - lr: 0.0010 - 68ms/epoch - 34ms/step\n",
      "Epoch 7/400\n",
      "2/2 - 0s - loss: 8.8778 - accuracy: 0.6038 - val_loss: 9.7634 - val_accuracy: 0.2143 - lr: 0.0010 - 59ms/epoch - 29ms/step\n",
      "Epoch 8/400\n",
      "2/2 - 0s - loss: 9.2314 - accuracy: 0.4340 - val_loss: 9.8345 - val_accuracy: 0.2143 - lr: 0.0010 - 60ms/epoch - 30ms/step\n",
      "Epoch 9/400\n",
      "2/2 - 0s - loss: 8.7380 - accuracy: 0.6415 - val_loss: 9.9051 - val_accuracy: 0.2143 - lr: 0.0010 - 60ms/epoch - 30ms/step\n",
      "Epoch 10/400\n",
      "2/2 - 0s - loss: 8.5242 - accuracy: 0.6226 - val_loss: 9.9360 - val_accuracy: 0.2143 - lr: 0.0010 - 65ms/epoch - 32ms/step\n",
      "Epoch 11/400\n",
      "2/2 - 0s - loss: 8.6704 - accuracy: 0.6038 - val_loss: 9.9688 - val_accuracy: 0.2143 - lr: 9.0484e-04 - 63ms/epoch - 31ms/step\n",
      "Epoch 12/400\n",
      "2/2 - 0s - loss: 8.4637 - accuracy: 0.6415 - val_loss: 9.9911 - val_accuracy: 0.2143 - lr: 8.1873e-04 - 60ms/epoch - 30ms/step\n",
      "Epoch 13/400\n",
      "2/2 - 0s - loss: 8.5173 - accuracy: 0.6604 - val_loss: 9.9582 - val_accuracy: 0.2143 - lr: 7.4082e-04 - 58ms/epoch - 29ms/step\n",
      "Epoch 14/400\n",
      "2/2 - 0s - loss: 8.0071 - accuracy: 0.7736 - val_loss: 9.8980 - val_accuracy: 0.2143 - lr: 6.7032e-04 - 61ms/epoch - 31ms/step\n",
      "Epoch 15/400\n",
      "2/2 - 0s - loss: 8.3029 - accuracy: 0.6604 - val_loss: 9.8463 - val_accuracy: 0.2143 - lr: 6.0653e-04 - 63ms/epoch - 32ms/step\n",
      "Epoch 16/400\n",
      "2/2 - 0s - loss: 7.9692 - accuracy: 0.7170 - val_loss: 9.8097 - val_accuracy: 0.2143 - lr: 2.7441e-04 - 61ms/epoch - 30ms/step\n",
      "Epoch 17/400\n",
      "2/2 - 0s - loss: 8.0628 - accuracy: 0.7358 - val_loss: 9.7995 - val_accuracy: 0.2143 - lr: 2.4829e-04 - 64ms/epoch - 32ms/step\n",
      "Epoch 18/400\n",
      "2/2 - 0s - loss: 8.0358 - accuracy: 0.7736 - val_loss: 9.8010 - val_accuracy: 0.2143 - lr: 2.2466e-04 - 62ms/epoch - 31ms/step\n",
      "Epoch 19/400\n",
      "2/2 - 0s - loss: 8.0003 - accuracy: 0.7358 - val_loss: 9.8041 - val_accuracy: 0.2143 - lr: 2.0328e-04 - 63ms/epoch - 32ms/step\n",
      "Epoch 20/400\n",
      "2/2 - 0s - loss: 8.1017 - accuracy: 0.7170 - val_loss: 9.8123 - val_accuracy: 0.2143 - lr: 1.8394e-04 - 58ms/epoch - 29ms/step\n",
      "Epoch 21/400\n",
      "2/2 - 0s - loss: 7.9542 - accuracy: 0.7547 - val_loss: 9.8246 - val_accuracy: 0.2143 - lr: 1.6644e-04 - 60ms/epoch - 30ms/step\n",
      "Epoch 22/400\n",
      "2/2 - 0s - loss: 8.1450 - accuracy: 0.6981 - val_loss: 9.8287 - val_accuracy: 0.2143 - lr: 1.5060e-04 - 58ms/epoch - 29ms/step\n",
      "Epoch 23/400\n",
      "2/2 - 0s - loss: 8.1064 - accuracy: 0.7170 - val_loss: 9.8369 - val_accuracy: 0.2143 - lr: 1.3627e-04 - 59ms/epoch - 29ms/step\n",
      "Epoch 24/400\n",
      "2/2 - 0s - loss: 7.9467 - accuracy: 0.7547 - val_loss: 9.8453 - val_accuracy: 0.2143 - lr: 1.2330e-04 - 60ms/epoch - 30ms/step\n",
      "Epoch 25/400\n",
      "2/2 - 0s - loss: 8.0787 - accuracy: 0.6981 - val_loss: 9.8514 - val_accuracy: 0.2143 - lr: 1.1156e-04 - 60ms/epoch - 30ms/step\n",
      "Epoch 26/400\n",
      "2/2 - 0s - loss: 7.8993 - accuracy: 0.8113 - val_loss: 9.8571 - val_accuracy: 0.2143 - lr: 5.0474e-05 - 82ms/epoch - 41ms/step\n",
      "\n",
      "Resultados comparativos de los modelos:\n",
      "\n",
      "            Model  Accuracy  Training Time (s)  Validation Loss\n",
      "1             FCN  0.519481          11.394057         1.346748\n",
      "0             MLP  0.506494           4.204066         1.249583\n",
      "3    InceptionFCN  0.415584          21.631125         1.477553\n",
      "4           S2SwA  0.298701          32.885320         1.859348\n",
      "2          ResNet  0.272727           8.461275         9.012907\n",
      "5  Pasos_Desbaste  0.168831           9.023436         9.730947\n",
      "\n",
      "El mejor modelo es: FCN con una precisión de 0.5195 y un tiempo de entrenamiento de 11.39 segundos.\n"
     ]
    }
   ],
   "source": [
    "# Definir una lista de modelos a evaluar\n",
    "models_to_evaluate = [\n",
    "    (\"MLP\", create_mlp),\n",
    "    (\"FCN\", create_fcn_model),\n",
    "    (\"ResNet\", create_resnet_model),\n",
    "    (\"InceptionFCN\", create_inceptionfcn_model),\n",
    "    (\"S2SwA\", create_s2swa_model),\n",
    "    (\"CONV_LSTM\", lambda input_shape, num_classes: Model_CONV_LSTM(num_n_deep=[64, 64, 512, 264, num_classes]))\n",
    "]\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "learning_rate_scheduler = LearningRateScheduler(scheduler)\n",
    "\n",
    "# Inicializar el dataframe para almacenar los resultados\n",
    "results_df = pd.DataFrame(columns=[\"Model\", \"Accuracy\", \"Training Time (s)\", \"Validation Loss\"])\n",
    "\n",
    "# Callbacks comunes\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6)\n",
    "\n",
    "# Evaluar cada modelo\n",
    "def evaluate_models(models, X_train, y_train, X_test, y_test, epochs, batch_size):\n",
    "    results = []\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    num_classes = y_train.shape[1]\n",
    "\n",
    "    for model_name, model_fn in models:\n",
    "        print(f\"Evaluando modelo: {model_name}\")\n",
    "        try:\n",
    "            # Crear el modelo\n",
    "            if model_name == \"CONV_LSTM\":\n",
    "                model = model_fn(input_shape, num_classes)\n",
    "                model.build((None, *input_shape))\n",
    "            if model_name == \"S2SwA\":\n",
    "                model = model_fn(input_shape, target_length, n_units=15, num_classes=num_classes, dropout_rate=0.3, l2_reg=1e-3)\n",
    "            else:\n",
    "                model = model_fn(input_shape, num_classes)\n",
    "\n",
    "            # Compilar el modelo\n",
    "            model.compile(Adam(learning_rate=0.001),\n",
    "                          loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "            # Medir el tiempo de entrenamiento\n",
    "            start_time = time.time()\n",
    "            history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=2, callbacks=[early_stopping, reduce_lr, learning_rate_scheduler])\n",
    "            end_time = time.time()\n",
    "\n",
    "            # Evaluar el modelo en el conjunto de prueba\n",
    "            test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "            training_time = end_time - start_time\n",
    "\n",
    "            # Almacenar los resultados\n",
    "            results.append({\n",
    "                \"Model\": model_name,\n",
    "                \"Accuracy\": test_acc,\n",
    "                \"Training Time (s)\": training_time,\n",
    "                \"Validation Loss\": min(history.history['val_loss'])\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluando el modelo {model_name}: {e}\")\n",
    "            results.append({\n",
    "                \"Model\": model_name,\n",
    "                \"Accuracy\": None,\n",
    "                \"Training Time (s)\": None,\n",
    "                \"Validation Loss\": None\n",
    "            })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Ejecutar la evaluación de los modelos\n",
    "results_df = evaluate_models(models_to_evaluate, X_train, y_train, X_test, y_test, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "# Ordenar por la mejor precisión\n",
    "results_df = results_df.sort_values(by=[\"Accuracy\", \"Training Time (s)\"], ascending=[False, True])\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"\\nResultados comparativos de los modelos:\\n\")\n",
    "print(results_df)\n",
    "\n",
    "# Resaltar el mejor modelo\n",
    "best_model = results_df.iloc[0]\n",
    "print(f\"\\nEl mejor modelo es: {best_model['Model']} con una precisión de {best_model['Accuracy']:.4f} y un tiempo de entrenamiento de {best_model['Training Time (s)']:.2f} segundos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo en el conjunto de prueba\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Asumiendo que el historial del entrenamiento está guardado en 'history'\n",
    "# Graficar el descenso de la pérdida (loss)\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Gráfico de pérdida (train y validation)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Pérdida de entrenamiento')\n",
    "plt.plot(history.history['val_loss'], label='Pérdida de validación')\n",
    "plt.title('Descenso de la pérdida durante el entrenamiento')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.legend()\n",
    "\n",
    "# Gráfico de precisión (train y validation)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Precisión de entrenamiento')\n",
    "plt.plot(history.history['val_accuracy'], label='Precisión de validación')\n",
    "plt.title('Aumento de la precisión durante el entrenamiento')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Precisión')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
